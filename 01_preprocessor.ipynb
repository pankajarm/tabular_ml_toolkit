{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "739ab7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3b66279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp preprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c469e3c1",
   "metadata": {},
   "source": [
    "# PreProcessor\n",
    "\n",
    "> An API to Preprocess train, valid and test dataset for Machine Learning models based on tabular or strucuture data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ce63e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *\n",
    "from nbdev import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc9ff301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from tabular_ml_toolkit.dataframeloader import *\n",
    "from tabular_ml_toolkit.logger import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ee899e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# hide\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler, MinMaxScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb98246b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "class PreProcessor:\n",
    "    \"\"\"\n",
    "    Represent PreProcessor class\n",
    "    \n",
    "    Attributes:\n",
    "    numerical_transformer: Numerical Columns Tranformer\n",
    "    categorical_transformer: Categorical Columns Transformer\n",
    "    preprocessor: Preprocessor for Columns Tranformer\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.columns_transfomer = None\n",
    "        self.transformer_type = None\n",
    "        self.target_cols_transformer = None\n",
    "        self.target_cols_pl = None\n",
    "        self.cat_cols_pl = None\n",
    "        self.num_cols_pl = None\n",
    "        \n",
    "    \n",
    "    def __str__(self):\n",
    "        \"\"\"Returns human readable string reprsentation\"\"\"\n",
    "        attr_str = \"numerical_transformer, categorical_transformer,columns_transfomer\"\n",
    "        return \"PreProcessor object with attributes:\" + attr_str\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n",
    "    \n",
    "    # PreProcessor Pipeline core methods\n",
    "    \n",
    "    # Create preprocessing pipeline for numerical data\n",
    "    def create_num_cols_pp_pl(self, num_cols__imputer, num_cols__scaler):\n",
    "        self.num_cols_pl = Pipeline(steps=[('imputer', num_cols__imputer), ('scaler',  num_cols__scaler)],\n",
    "                                   memory=\"pipeline_cache_dir\")\n",
    "        \n",
    "    # Create Preprocessing pipeline for categorical data\n",
    "    def create_cat_cols_pp_pl(self, cat_cols__imputer, cat_cols__encoder):\n",
    "        self.cat_cols_pl = Pipeline(steps=[('imputer', cat_cols__imputer), ('encoder', cat_cols__encoder)],\n",
    "                                   memory=\"pipeline_cache_dir\")\n",
    "    \n",
    "    # Create Preprocessing pipeline for target cols\n",
    "    def create_target_cols_pp_pl(self, target_cols__encoder):\n",
    "        self.target_cols_pl = Pipeline(steps=[('encoder', target_cols__encoder)],\n",
    "                                      memory=\"pipeline_cache_dir\")\n",
    "    \n",
    "    # Bundle preprocessing pipelines based upon types of columns\n",
    "    def preprocess_all_cols(self, dataframeloader, problem_type=\"regression\",\n",
    "                            num_cols__imputer=SimpleImputer(strategy='constant'),\n",
    "                            num_cols__scaler=StandardScaler(),\n",
    "                            cat_cols__imputer=SimpleImputer(strategy='constant'),\n",
    "                            cat_cols__encoder=OneHotEncoder(handle_unknown='ignore'),\n",
    "                            target_cols__encoder=LabelEncoder()):\n",
    "                            #cat_cols__encoder=OrdinalEncoder(handle_unknown='use_encoded_value',\n",
    "                                                             #unknown_value=np.nan)):\n",
    "        \n",
    "        #if problem type classification encode target\n",
    "        # encode target based upon problem type\n",
    "        if \"classification\" in problem_type:\n",
    "            logger.info(\"PreProcessing will include target(s) encoding!\")\n",
    "            #now just call fit tranform on y\n",
    "            dataframeloader.y = target_cols__encoder.fit_transform(dataframeloader.y)\n",
    "            #logger.info(\"Encoded dataframeloader.y:\", dataframeloader.y)\n",
    "        \n",
    "        #TODO: REALLY NOT HAPPY WITH THIS DETERMINISTIC REPEATED FLOW\n",
    "        # change preprocessor according to type of column found\n",
    "        if len(dataframeloader.categorical_cols) < 1:\n",
    "            logger.info(\"categorical columns are None, Preprocessing will done accordingly!\")\n",
    "            # create scikit-learn pipelines instance\n",
    "            self.create_num_cols_pp_pl(num_cols__imputer, num_cols__scaler)\n",
    "            #now setup columns tranformer\n",
    "            self.columns_transfomer = ColumnTransformer(\n",
    "                transformers=[\n",
    "                    ('num_cols', self.num_cols_pl,\n",
    "                     dataframeloader.numerical_cols)\n",
    "                ])\n",
    "                \n",
    "            \n",
    "        elif len(dataframeloader.numerical_cols) < 1:\n",
    "            logger.info(\"numerical columns are None, Preprocessing will done accordingly!\")\n",
    "            # create sklearn pipelines instance\n",
    "            self.create_cat_cols_pp_pl(cat_cols__imputer, cat_cols__encoder)\n",
    "            #now setup columns tranformer\n",
    "            self.columns_transfomer = ColumnTransformer(\n",
    "                transformers=[\n",
    "                    ('cat_cols', self.cat_cols_pl,\n",
    "                     dataframeloader.categorical_cols)\n",
    "                ])\n",
    "                \n",
    "        \n",
    "        else:\n",
    "            # create scikit-learn pipelines instance\n",
    "            logger.info(\"Both Numerical & Categorical columns found, Preprocessing will done accordingly!\")\n",
    "            self.create_num_cols_pp_pl(num_cols__imputer, num_cols__scaler)\n",
    "            self.create_cat_cols_pp_pl(cat_cols__imputer, cat_cols__encoder)\n",
    "            #now setup columns tranformer\n",
    "            self.columns_transfomer = ColumnTransformer(\n",
    "                transformers=[\n",
    "                    ('num_cols', self.num_cols_pl,\n",
    "                     dataframeloader.numerical_cols),\n",
    "                    ('cat_cols', self.cat_cols_pl,\n",
    "                     dataframeloader.categorical_cols)\n",
    "                ])\n",
    "\n",
    "        \n",
    "        # now setup final tranfomer type      \n",
    "        self.transformer_type = self.columns_transfomer\n",
    "        #logger.info(f\"self.transformer_type: {self.transformer_type}\")\n",
    "        \n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81cf5db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# showdoc(PreProcessor.preprocess_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883dcf04",
   "metadata": {},
   "source": [
    "#### Test PreProcessor with House Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef8d4901",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-28 21:45:17,554 INFO DataFrame Memory usage decreased to 0.58 Mb (35.5% reduction)\n",
      "2021-11-28 21:45:17,602 INFO DataFrame Memory usage decreased to 0.58 Mb (34.8% reduction)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrameLoader object with attributes: X_full, X_test, X(features), y(target), X_train, X_valid, y_train and y_valid"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfl = DataFrameLoader().from_csv(\n",
    "    train_file_path=\"input/home_data/train.csv\",\n",
    "    test_file_path=\"input/home_data/test.csv\",\n",
    "    idx_col=\"Id\", target=\"SalePrice\",\n",
    "    random_state=42)\n",
    "dfl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e07205c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's create train, valid split\n",
    "dfl.create_train_valid(valid_size=0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5faf8831",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-28 21:45:17,728 INFO Both Numerical & Categorical columns found, Preprocessing will done accordingly!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PreProcessor object with attributes:numerical_transformer, categorical_transformer,columns_transfomer"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp = PreProcessor().preprocess_all_cols(dataframeloader=dfl, problem_type=\"regression\")\n",
    "pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8fce59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pp.columns_transfomer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1f6a256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    }
   ],
   "source": [
    "print(len(dfl.numerical_cols))\n",
    "# dfl.numerical_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aed0a0c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(len(dfl.high_card_cat_cols))\n",
    "# dfl.high_card_cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7c480d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "print(len(dfl.low_card_cat_cols))\n",
    "# dfl.low_card_cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "790982f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ColumnTransformer(transformers=[('num_cols',\n",
       "                                 Pipeline(memory='pipeline_cache_dir',\n",
       "                                          steps=[('imputer',\n",
       "                                                  SimpleImputer(strategy='constant')),\n",
       "                                                 ('scaler', StandardScaler())]),\n",
       "                                 ['MSSubClass', 'LotFrontage', 'LotArea',\n",
       "                                  'OverallQual', 'OverallCond', 'YearBuilt',\n",
       "                                  'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1',\n",
       "                                  'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF',\n",
       "                                  '1stFlrSF', '2ndFlrSF', 'LowQ...\n",
       "                                 ['MSZoning', 'Street', 'Alley', 'LotShape',\n",
       "                                  'LandContour', 'Utilities', 'LotConfig',\n",
       "                                  'LandSlope', 'Condition1', 'Condition2',\n",
       "                                  'BldgType', 'HouseStyle', 'RoofStyle',\n",
       "                                  'RoofMatl', 'MasVnrType', 'ExterQual',\n",
       "                                  'ExterCond', 'Foundation', 'BsmtQual',\n",
       "                                  'BsmtCond', 'BsmtExposure', 'BsmtFinType1',\n",
       "                                  'BsmtFinType2', 'Heating', 'HeatingQC',\n",
       "                                  'CentralAir', 'Electrical', 'KitchenQual',\n",
       "                                  'Functional', 'FireplaceQu', ...])])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp.transformer_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1987975d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1460x304 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 115340 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_t = pp.transformer_type.fit_transform(dfl.X, dfl.y)\n",
    "X_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f2d3b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57973ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f314216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bundle preprocessor and model in a pipeline\n",
    "pl = Pipeline(steps=[('preprocessor', pp.transformer_type),\n",
    "                      ('model', model)],memory=\"pipeline_cache_dir\")\n",
    "# pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3fe226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for visualizing pipeline\n",
    "from sklearn import set_config\n",
    "\n",
    "set_config(display=\"diagram\")\n",
    "pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ff6f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing of training data and then fit model \n",
    "pl.fit(dfl.X_train, dfl.y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd7c811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing of validation data and then get predictions\n",
    "preds = pl.predict(dfl.X_valid)\n",
    "\n",
    "print('X_valid MAE:', mean_absolute_error(dfl.y_valid, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9aa318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_valid MAE: 17582.46150684932"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f91f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "# run the script to build \n",
    "\n",
    "from nbdev.export import notebook2script; notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4a0f5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nbdev_env]",
   "language": "python",
   "name": "conda-env-nbdev_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
