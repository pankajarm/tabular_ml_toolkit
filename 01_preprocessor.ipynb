{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "739ab7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3b66279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp PreProcessor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c469e3c1",
   "metadata": {},
   "source": [
    "# PreProcessor\n",
    "\n",
    "> An API to Preprocess train, valid and test dataset for Machine Learning models based on tabular or strucuture data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ce63e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *\n",
    "from nbdev import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc9ff301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from tabular_ml_toolkit.DataFrameLoader import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee899e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# hide\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb98246b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "class PreProcessor:\n",
    "    \"\"\"\n",
    "    Represent PreProcessor class\n",
    "    \n",
    "    Attributes:\n",
    "    numerical_transformer: Numerical Columns Tranformer\n",
    "    categorical_transformer: Categorical Columns Transformer\n",
    "    preprocessor: Preprocessor for Columns Tranformer\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.numerical_transformer = None\n",
    "        self.categorical_transformer = None\n",
    "        self.columns_transfomer = None\n",
    "        self.transformer_type = None\n",
    "        self.OHE_categorical_transformer = None\n",
    "        self.ORE_categorical_transformer = None\n",
    "#         self.numerical_cols = None\n",
    "#         self.low_card_cat_cols = None\n",
    "#         self.high_card_cat_cols = None\n",
    "#         self.final_cols = None\n",
    "    \n",
    "    def __str__(self):\n",
    "        \"\"\"Returns human readable string reprsentation\"\"\"\n",
    "        attr_str = \"numerical_transformer, categorical_transformer,columns_transfomer\"\n",
    "        return \"PreProcessor object with attributes:\" + attr_str\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n",
    "    \n",
    "    # PreProcessor core methods\n",
    "    \n",
    "    # Preprocessing for numerical data\n",
    "    def preprocess_numerical_data(self):\n",
    "        self.numerical_transformer = Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='constant')),\n",
    "            ('scaler',  StandardScaler())\n",
    "        ])\n",
    "        \n",
    "    # Preprocessing for categorical data\n",
    "    def preprocess_OHE_categorical_data(self):\n",
    "        self.OHE_categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "        ])   \n",
    "\n",
    "    def preprocess_OE_categorical_data(self):\n",
    "        self.OE_categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('ordinal', OrdinalEncoder())\n",
    "        ])       \n",
    "    \n",
    "    #TO-DO\n",
    "#     def reduce_dims(self):\n",
    "#         pass\n",
    "    \n",
    "    # Bundle preprocessing for numerical and categorical data\n",
    "    def preprocess_all_cols_for_training(self, dataframeloader):\n",
    "        # create scikit-learn pipelines instances\n",
    "        self.preprocess_numerical_data()\n",
    "        self.preprocess_OHE_categorical_data()\n",
    "        self.preprocess_OE_categorical_data()\n",
    "        # convert to Scikit-learn ColumnTranfomer\n",
    "        self.columns_transfomer = ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('num', self.numerical_transformer, dataframeloader.numerical_cols),\n",
    "                ('low_cad_cat', self.OHE_categorical_transformer,\n",
    "                 dataframeloader.low_card_cat_cols),\n",
    "                ('high_cad_cat', self.OE_categorical_transformer,\n",
    "                 dataframeloader.high_card_cat_cols)\n",
    "            ])\n",
    "        self.transformer_type = self.columns_transfomer\n",
    "        return self\n",
    "    \n",
    "    # Bundle preprocessing for cv_cols\n",
    "    def preprocess_cols_for_cv(self, cv_cols_type, dataframeloader):\n",
    "        \n",
    "        # change column types and preprocessor according to cv_cols provided\n",
    "        if cv_cols_type == \"all\":\n",
    "            # create scikit-learn pipelines instances\n",
    "            self.preprocess_numerical_data()\n",
    "            self.preprocess_OHE_categorical_data()\n",
    "            # convert to Scikit-learn ColumnTranfomer\n",
    "            self.columns_transfomer = ColumnTransformer(\n",
    "                transformers=[\n",
    "                    ('num', self.numerical_transformer, dataframeloader.numerical_cols),\n",
    "                    ('low_cad_cat', self.OHE_categorical_transformer,\n",
    "                     dataframeloader.low_card_cat_cols)\n",
    "                ])\n",
    "            self.transformer_type = self.columns_transfomer\n",
    "        \n",
    "        elif cv_cols_type == \"num\":\n",
    "            self.preprocess_numerical_data()\n",
    "            self.transformer_type = self.numerical_transformer\n",
    "        \n",
    "        elif cv_cols_type == \"cat\":\n",
    "            # create scikit-learn pipelines instances\n",
    "            self.preprocess_OHE_categorical_data()\n",
    "            # convert all categorical columns to OrdinalEncoder with Scikit-learn ColumnTranfomer\n",
    "            self.columns_transfomer = ColumnTransformer(\n",
    "                transformers=[\n",
    "                    ('low_cad_cat', self.OHE_categorical_transformer,\n",
    "                     dataframeloader.low_card_cat_cols)\n",
    "                    # REMOVING HIGH CARDINALITY COLUMNS BECAUSE OF NOT ENOUGH REPRESENTATION\n",
    "                    # OF CARDINALITY DURING K-FOLD SPLIT OF DATA\n",
    "                ])\n",
    "            self.transformer_type = self.columns_transfomer\n",
    "        else:\n",
    "            raise ValueError(\"Bad cv_cols_type, Only 'num','cat','all' are allowed!\")\n",
    "        \n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81cf5db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# showdoc(PreProcessor.preprocess_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883dcf04",
   "metadata": {},
   "source": [
    "#### Test PreProcessor with House Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8d4901",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfl = DataFrameLoader().from_csv(\n",
    "    train_file_path=\"input/home_data/train.csv\",\n",
    "    test_file_path=\"input/home_data/test.csv\",\n",
    "    idx_col=\"Id\", target=\"SalePrice\",\n",
    "    random_state=42, valid_size=0.2)\n",
    "dfl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5faf8831",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = PreProcessor().preprocess_all_cols_for_training(dataframeloader=dfl)\n",
    "pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8fce59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.columns_transfomer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f6a256",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(dfl.numerical_cols))\n",
    "dfl.numerical_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed0a0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(dfl.high_card_cat_cols))\n",
    "dfl.high_card_cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c480d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(dfl.low_card_cat_cols))\n",
    "dfl.low_card_cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57973ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f314216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bundle preprocessor and model in a pipeline\n",
    "pl = Pipeline(steps=[('preprocessor', pp.columns_transfomer),\n",
    "                      ('model', model)\n",
    "                     ])\n",
    "pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3fe226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for visualizing pipeline\n",
    "from sklearn import set_config\n",
    "\n",
    "set_config(display=\"diagram\")\n",
    "pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ff6f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing of training data and then fit model \n",
    "pl.fit(dfl.X_train, dfl.y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd7c811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing of validation data and then get predictions\n",
    "preds = pl.predict(dfl.X_valid)\n",
    "\n",
    "print('X_valid MAE:', mean_absolute_error(dfl.y_valid, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9aa318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_valid MAE: 17582.46150684932"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f91f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "# run the script to build \n",
    "\n",
    "from nbdev.export import notebook2script; notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4a0f5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
