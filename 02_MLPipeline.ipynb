{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp MLPipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Pipeline\n",
    "\n",
    "> An API to create training pipeline for machine learning models on tabular or strucuture data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *\n",
    "from nbdev import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from tabular_ml_toolkit.DataFrameLoader import *\n",
    "from tabular_ml_toolkit.PreProcessor import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# hide\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, roc_auc_score,accuracy_score\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, StratifiedKFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "class MLPipeline:\n",
    "    \"\"\"\n",
    "    Represent MLPipeline class\n",
    "    \n",
    "    Attributes:\\n\n",
    "    pipeline: An MLPipeline instance \\n\n",
    "    dataframeloader: A DataFrameLoader instance \\n\n",
    "    preprocessor: A PreProcessor Instance \\n\n",
    "    model: The given Model\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.pipeline = None\n",
    "        self.dataframeloader = None\n",
    "        self.preprocessor = None\n",
    "        self.model = None\n",
    "        self.scikit_pipeline = None\n",
    "        self.transformer_type = None\n",
    "    \n",
    "    def __str__(self):\n",
    "        \"\"\"Returns human readable string reprsentation\"\"\"\n",
    "        attr_str = (\"pipeline, dataframeloader, preprocessor, model\")\n",
    "        return (\"Training Pipeline object with attributes:\"+attr_str)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n",
    "    \n",
    "#     def __lt__(self):\n",
    "#         \"\"\"returns: boolean\"\"\"\n",
    "#         return True\n",
    "    \n",
    "    # core methods\n",
    "    \n",
    "    # Bundle preprocessing and modeling code in a training pipeline\n",
    "    def bundle_preproessor_model(self, transformer_type, model):\n",
    "        self.scikit_pipeline = Pipeline(\n",
    "            steps=[('preprocessor', transformer_type),\n",
    "                   ('model', model)])\n",
    "    \n",
    "    # Core methods for Simple Training\n",
    "    def prepare_data_for_training(self, train_file_path:str,\n",
    "                                  test_file_path:str,\n",
    "                                  idx_col:str, target:str,\n",
    "                                  random_state:int,\n",
    "                                  valid_size:float,\n",
    "                                  model:object):\n",
    "        self.model = model\n",
    "        # call DataFrameLoader module\n",
    "        self.dataframeloader = DataFrameLoader().from_csv(\n",
    "            train_file_path=train_file_path,\n",
    "            test_file_path=test_file_path,\n",
    "            idx_col=idx_col,target=target,\n",
    "            random_state=random_state,valid_size=valid_size)\n",
    "        # call PreProcessor module\n",
    "        self.preprocessor = PreProcessor().preprocess_all_cols_for_training(\n",
    "            dataframeloader=self.dataframeloader)\n",
    "        \n",
    "        # call bundle method\n",
    "        self.bundle_preproessor_model(transformer_type=self.preprocessor.transformer_type,\n",
    "                                     model = model)\n",
    "        return self\n",
    "    \n",
    "    \n",
    "    # Core methods for Cross Validation\n",
    "    def prepare_data_for_cv(self, train_file_path:str, test_file_path:str,\n",
    "                                          idx_col:str, target:str, model:object,\n",
    "                                          random_state:int, cv_cols_type:str):\n",
    "        self.model = model\n",
    "        \n",
    "        # call DataFrameLoader module\n",
    "        self.dataframeloader = DataFrameLoader().from_csv(\n",
    "            train_file_path=train_file_path,\n",
    "            test_file_path=test_file_path,\n",
    "            idx_col=idx_col, target=target,\n",
    "            random_state=random_state,\n",
    "            cv_cols_type=cv_cols_type)\n",
    "        \n",
    "        # call PreProcessor module\n",
    "        self.preprocessor = PreProcessor().preprocess_cols_for_cv(\n",
    "            cv_cols_type = cv_cols_type,\n",
    "            dataframeloader=self.dataframeloader)\n",
    "        \n",
    "        # call bundle method\n",
    "        self.bundle_preproessor_model(transformer_type=self.preprocessor.transformer_type,\n",
    "                                     model = model)\n",
    "        return self\n",
    "        \n",
    "    \n",
    "    def do_cross_validation(self,estimator:object, cv:int, scoring:str):\n",
    "        scores = cross_val_score(\n",
    "            estimator=estimator,\n",
    "            X=self.dataframeloader.X_cv,\n",
    "            y=self.dataframeloader.y,\n",
    "            scoring=scoring,\n",
    "            cv=cv)\n",
    "        # Multiply by -1 since sklearn calculates *negative* scoring for some of the metrics\n",
    "        if \"neg_\" in scoring:\n",
    "            scores = -1 * scores\n",
    "        return scores\n",
    "        \n",
    "    # Core methods for GridSearch\n",
    "    def do_grid_search(self, estimator:object, param_grid:object, cv:int, scoring:str):\n",
    "        \n",
    "        # create GridSeachCV instance\n",
    "        grid_search = GridSearchCV(estimator=estimator,\n",
    "                                   param_grid=param_grid,\n",
    "                                   cv=cv,\n",
    "                                   scoring=scoring)\n",
    "        # now call fit\n",
    "        grid_search.fit(self.dataframeloader.X_cv, self.dataframeloader.y)\n",
    "        return grid_search\n",
    "    \n",
    "    # core method for K-Fold training\n",
    "    def prepare_data_for_k_fold(self, train_file_path:str, test_file_path:str,\n",
    "                                          idx_col:str, target:str, model:object,\n",
    "                                          random_state:int):\n",
    "        \n",
    "        return self.prepare_data_for_cv(train_file_path,\n",
    "                                        test_file_path,\n",
    "                                        idx_col,\n",
    "                                        target,\n",
    "                                        model,\n",
    "                                        random_state,\n",
    "                                        cv_cols_type=\"all\")\n",
    "    \n",
    "    # do k-fold training\n",
    "    def do_k_fold_training(self, n_splits:int, metrics:object):\n",
    "        \n",
    "        #create stratified K Folds instance\n",
    "        k_fold = StratifiedKFold(n_splits=n_splits,\n",
    "                             random_state=48,\n",
    "                             shuffle=True)\n",
    "        \n",
    "        # list contains metrics score for each fold\n",
    "        metrics_score = []\n",
    "        n=0\n",
    "        for train_idx, valid_idx in k_fold.split(self.dataframeloader.X_cv, self.dataframeloader.y):\n",
    "            # create X_train\n",
    "            self.dataframeloader.X_train = self.dataframeloader.X_cv.iloc[train_idx]\n",
    "            # create X_valid\n",
    "            self.dataframeloader.X_valid = self.dataframeloader.X_cv.iloc[valid_idx] \n",
    "            # create y_train\n",
    "            self.dataframeloader.y_train = self.dataframeloader.y.iloc[train_idx]\n",
    "            # create y_valid\n",
    "            self.dataframeloader.y_valid = self.dataframeloader.y.iloc[valid_idx]\n",
    "            \n",
    "            # fit\n",
    "            self.scikit_pipeline.fit(self.dataframeloader.X_train, self.dataframeloader.y_train)\n",
    "            \n",
    "            #evaluate metrics based upon input\n",
    "            if \"proba\" in metrics.__globals__:\n",
    "                metrics_score.append(metrics(self.dataframeloader.y_valid,\n",
    "                                               self.scikit_pipeline.predict_proba(self.dataframeloader.X_valid)[:,1]))\n",
    "            else:\n",
    "                metrics_score.append(metrics(self.dataframeloader.y_valid,\n",
    "                                               self.scikit_pipeline.predict(self.dataframeloader.X_valid)))\n",
    "            \n",
    "            print(f\"fold: {n+1} , {str(metrics.__name__)}: {metrics_score[n]}\")\n",
    "            # increment fold counter label\n",
    "            n += 1\n",
    "        return k_fold\n",
    "            \n",
    "    def do_k_fold_prediction(self, k_fold:object):\n",
    "        # create preds dataframe\n",
    "        preds = np.zeros(self.dataframeloader.X_test_cv.shape[0])\n",
    "        for _ in range(k_fold.n_splits):\n",
    "            # predict\n",
    "            preds += self.scikit_pipeline.predict(self.dataframeloader.X_test_cv) / k_fold.n_splits\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(MLPipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(MLPipeline.prepare_data_for_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build MLPipeline Class with House Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*You can use MLPipeline to train any model. Here we are using RandomForestRegressor from Scikit-Learn, on  [Melbourne Home Sale price data](https://www.kaggle.com/estrotococo/home-data-for-ml-course)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_absolute_error.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_absolute_error.__globals__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roc_auc_score.__globals__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy_score.__globals__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create scikit-learn ml model\n",
    "scikit_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# createm ml pipeline for scikit-learn model\n",
    "sci_ml_pl = MLPipeline().prepare_data_for_training(\n",
    "    train_file_path= \"input/home_data/train.csv\",\n",
    "    test_file_path= \"input/home_data/test.csv\",\n",
    "    idx_col=\"Id\",\n",
    "    target=\"SalePrice\",\n",
    "    model=scikit_model,\n",
    "    random_state=42,\n",
    "    valid_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sci_ml_pl.dataframeloader.X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sci_ml_pl.dataframeloader.y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(sci_ml_pl.dataframeloader.final_cols))\n",
    "sci_ml_pl.dataframeloader.final_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(sci_ml_pl.dataframeloader.low_card_cat_cols))\n",
    "sci_ml_pl.dataframeloader.low_card_cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(sci_ml_pl.dataframeloader.high_card_cat_cols))\n",
    "# sci_ml_pl.dataframeloader.high_card_cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(sci_ml_pl.dataframeloader.numerical_cols))\n",
    "# sci_ml_pl.dataframeloader.numerical_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Now fit and predict\n",
    "sci_ml_pl.scikit_pipeline.fit(sci_ml_pl.dataframeloader.X_train, sci_ml_pl.dataframeloader.y_train)\n",
    "\n",
    "preds = sci_ml_pl.scikit_pipeline.predict(sci_ml_pl.dataframeloader.X_valid)\n",
    "print('X_valid MAE:', mean_absolute_error(sci_ml_pl.dataframeloader.y_valid, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's do Cross Validation for Scikit Model on our MLPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create scikit-learn ml model\n",
    "scikit_model = RandomForestRegressor(n_estimators=200, random_state=42)\n",
    "# createm ml pipeline for scikit-learn model\n",
    "sci_ml_pl = MLPipeline().prepare_data_for_cv(train_file_path= \"input/home_data/train.csv\",\n",
    "                                             test_file_path= \"input/home_data/test.csv\",\n",
    "                                             idx_col=\"Id\", target=\"SalePrice\",\n",
    "                                             model=scikit_model,random_state=42,\n",
    "                                             cv_cols_type = \"all\") #cv_cols_type = all|num|cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(sci_ml_pl.dataframeloader.cv_cols))\n",
    "# sci_ml_pl.dataframeloader.cv_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sci_ml_pl.dataframeloader.X_cv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for visualizing pipeline\n",
    "from sklearn import set_config\n",
    "\n",
    "set_config(display=\"diagram\")\n",
    "sci_ml_pl.scikit_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now fit and predict\n",
    "scores = sci_ml_pl.do_cross_validation(estimator=sci_ml_pl.scikit_pipeline, cv=10,\n",
    "                                    scoring='neg_mean_absolute_error')\n",
    "print(\"scores:\", scores)\n",
    "print(\"Average MAE score:\", scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's do Grid Search for HyperParameters Tunning for Scikit Model on our MLPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create blanket scikit-learn ml model\n",
    "\n",
    "scikit_model = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# createm ml pipeline for scikit-learn model\n",
    "sci_ml_pl = MLPipeline().prepare_data_for_cv(train_file_path= \"input/home_data/train.csv\",\n",
    "                                             test_file_path= \"input/home_data/test.csv\",\n",
    "                                             idx_col=\"Id\",\n",
    "                                             target=\"SalePrice\",\n",
    "                                             model=scikit_model,\n",
    "                                             random_state=42,\n",
    "                                             cv_cols_type = \"all\") #cv_cols_type = all|num|cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "#     \"preprocessor__num__imputer__strategy\": [\"mean\", \"median\"],\n",
    "    \"model__max_depth\": [80,100,110],\n",
    "    'model__max_features': [2, 3],\n",
    "    'model__min_samples_leaf': [3,4,5],\n",
    "    'model__min_samples_split': [8,10,12],\n",
    "    \"model__n_estimators\": [100,200,1000]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = sci_ml_pl.do_grid_search(estimator=sci_ml_pl.scikit_pipeline,\n",
    "                                       param_grid=param_grid,\n",
    "                                       cv=5,\n",
    "                                       scoring='neg_mean_absolute_error')\n",
    "\n",
    "print(\"Best params:\")\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Internal CV MAE score: {-1*(grid_search.best_score_):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's Use K-Fold Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create scikit-learn ml model\n",
    "scikit_model = RandomForestRegressor(n_estimators=200, random_state=42)\n",
    "\n",
    "# createm ml pipeline for scikit-learn model\n",
    "sci_ml_pl = MLPipeline().prepare_data_for_k_fold(\n",
    "    train_file_path= \"input/home_data/train.csv\",\n",
    "    test_file_path= \"input/home_data/test.csv\",\n",
    "    idx_col=\"Id\",\n",
    "    target=\"SalePrice\",\n",
    "    model=scikit_model,\n",
    "    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sci_ml_pl.dataframeloader.X_cv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sci_ml_pl.dataframeloader.y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(sci_ml_pl.dataframeloader.final_cols))\n",
    "# sci_ml_pl.dataframeloader.final_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_fold = sci_ml_pl.do_k_fold_training(estimator=sci_ml_pl.scikit_pipeline, n_splits=5, metrics=mean_absolute_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = sci_ml_pl.do_k_fold_prediction(k_fold=k_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(preds))\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's Use XGBosst on MLPipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*You can also use MLPipeline with XGBoost model, Make sure to install XGBooost depending upon your OS.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*After that all steps remains same. Here is example using XGBRegressor with [Melbourne Home Sale price data](https://www.kaggle.com/estrotococo/home-data-for-ml-course)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best way to install xgboost if you are on macosx and windows machine is using conda\n",
    "# !conda install -c conda-forge xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "# create xgb ml model\n",
    "xgb_model = XGBRegressor(n_estimators=250,learning_rate=0.05, random_state=42)\n",
    "\n",
    "# createm ml pipeline for xgb model\n",
    "xgb_ml_pl = MLPipeline().prepare_data_for_training(\n",
    "    train_file_path= \"input/home_data/train.csv\",\n",
    "    test_file_path= \"input/home_data/test.csv\",\n",
    "    idx_col=\"Id\",\n",
    "    target=\"SalePrice\",\n",
    "    model=xgb_model,\n",
    "    random_state=42,\n",
    "    valid_size=0.2)\n",
    "\n",
    "# Now fit and predict\n",
    "xgb_ml_pl.scikit_pipeline.fit(xgb_ml_pl.dataframeloader.X_train, xgb_ml_pl.dataframeloader.y_train)\n",
    "preds = xgb_ml_pl.scikit_pipeline.predict(xgb_ml_pl.dataframeloader.X_valid)\n",
    "print('X_valid MAE:', mean_absolute_error(xgb_ml_pl.dataframeloader.y_valid, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's do Cross Validation for XGB Model on our MLPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# createm ml pipeline for scikit-learn model\n",
    "xgb_ml_pl = MLPipeline().prepare_data_for_cv(train_file_path= \"input/home_data/train.csv\",\n",
    "                                             test_file_path= \"input/home_data/test.csv\",\n",
    "                                             idx_col=\"Id\", target=\"SalePrice\",\n",
    "                                             model=xgb_model,random_state=42,\n",
    "                                             cv_cols_type = \"all\") #cv_cols_type = all|num|cat\n",
    "# Now fit and predict\n",
    "scores = xgb_ml_pl.do_cross_validation(estimator=xgb_ml_pl.scikit_pipeline, cv=5,\n",
    "                                    scoring='neg_mean_absolute_error')\n",
    "print(\"scores:\", scores)\n",
    "print(\"Average MAE score:\", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "# run the script to build \n",
    "\n",
    "from nbdev.export import notebook2script; notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
