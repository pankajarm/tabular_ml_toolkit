{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp tmlt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Pipeline\n",
    "\n",
    "> An API to create super fast training pipeline for machine learning models based on tabular or strucuture data\n",
    "\n",
    "> It comes with model parallelism and cutting edge hyperparameter tuning techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *\n",
    "from nbdev import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from tabular_ml_toolkit.dataframeloader import *\n",
    "from tabular_ml_toolkit.preprocessor import *\n",
    "from tabular_ml_toolkit.logger import *\n",
    "from tabular_ml_toolkit.optuna_objective import *\n",
    "from tabular_ml_toolkit.utility import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# hide\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, log_loss, f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, StratifiedKFold\n",
    "# for Optuna\n",
    "import optuna\n",
    "#for XGB\n",
    "import xgboost\n",
    "\n",
    "# for finding n_jobs in all sklearn estimators\n",
    "from sklearn.utils import all_estimators\n",
    "import inspect\n",
    "\n",
    "# Just to compare fit times\n",
    "import time\n",
    "\n",
    "# for os specific settings\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "class TMLT:\n",
    "    \"\"\"\n",
    "    Represent Tabular ML Toolkit class\n",
    "    \n",
    "    Attributes:\\n\n",
    "    spl: A Scikit MLPipeline instance \\n\n",
    "    dfl: A DataFrameLoader instance \\n\n",
    "    pp: A PreProcessor instance \\n\n",
    "    model: The given Model\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.dfl = None\n",
    "        self.pp = None\n",
    "        self.model = None\n",
    "        self.spl = None\n",
    "        self.transformer_type = None\n",
    "        self.problem_type = None\n",
    "        self.has_n_jobs = check_has_n_jobs()\n",
    "        self.IDEAL_CPU_CORES = find_ideal_cpu_cores()\n",
    "        \n",
    "    \n",
    "    def __str__(self):\n",
    "        \"\"\"Returns human readable string reprsentation\"\"\"\n",
    "        attr_str = (\"spl, dfl, pp, model\")\n",
    "        return (\"Training Pipeline object with attributes:\"+attr_str)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n",
    "                \n",
    "    ## All Core Methods ##\n",
    "    \n",
    "    # Bundle preprocessing and modeling code in a training pipeline\n",
    "    def create_final_sklearn_pipeline(self, transformer_type, model):\n",
    "        self.spl = Pipeline(\n",
    "            steps=[('preprocessor', transformer_type),\n",
    "                   ('model', model)])\n",
    "        return self.spl\n",
    "    \n",
    "    # Main Method to create, load, preprocessed data based upon problem type\n",
    "    def prepare_data_for_training(self, train_file_path:str,\n",
    "                                  idx_col:str, target:str,\n",
    "                                  random_state:int,\n",
    "                                  model:object,\n",
    "                                  test_file_path:str=None,\n",
    "                                  problem_type=\"regression\",\n",
    "                                  nrows=None):\n",
    "        #set problem type\n",
    "        self.problem_type = problem_type\n",
    "        # check if given model supports n_jobs aka cpu core based Parallelism\n",
    "        estimator_name = model.__class__.__name__\n",
    "        # logger.info(estimator_name)\n",
    "        # logger.info((self.has_n_jobs)\n",
    "        if estimator_name in self.has_n_jobs :\n",
    "            # In order to OS not to kill the job, leave one processor out \n",
    "            model.n_jobs = self.IDEAL_CPU_CORES\n",
    "            self.model = model\n",
    "        else:\n",
    "            print(f\"{estimator_name} doesn't support parallelism yet! Training will continue on a single thread.\")\n",
    "            self.model = model\n",
    "        \n",
    "        # call DataFrameLoader module\n",
    "        self.dfl = DataFrameLoader().from_csv(\n",
    "            train_file_path=train_file_path,\n",
    "            test_file_path=test_file_path,\n",
    "            idx_col=idx_col,\n",
    "            target=target,\n",
    "            random_state=random_state,\n",
    "            nrows=nrows)\n",
    "        \n",
    "        # call PreProcessor module\n",
    "        self.pp = PreProcessor().preprocess_all_cols(dataframeloader=self.dfl, problem_type=self.problem_type)\n",
    "        \n",
    "        # call create final sklearn pipelien method\n",
    "        self.spl = self.create_final_sklearn_pipeline(transformer_type=self.pp.transformer_type,\n",
    "                                     model = model)\n",
    "        # return tmlt\n",
    "        return self\n",
    "    \n",
    "    # Force to update the preprocessor in pipeline\n",
    "    def update_preprocessor(self,\n",
    "                            num_cols__imputer=SimpleImputer(strategy='median'),\n",
    "                            num_cols__scaler=StandardScaler(),\n",
    "                            cat_cols__imputer=SimpleImputer(strategy='constant'),\n",
    "                            cat_cols__encoder=OneHotEncoder(handle_unknown='ignore')):\n",
    "        # change preprocessor\n",
    "        self.pp = PreProcessor().preprocess_all_cols(self.dfl,\n",
    "                                                     num_cols__imputer=num_cols__imputer,\n",
    "                                                     num_cols__scaler=num_cols__scaler,\n",
    "                                                     cat_cols__imputer=cat_cols__imputer,\n",
    "                                                     cat_cols__encoder=cat_cols__encoder)\n",
    "        # recall create final sklearn pipelien method\n",
    "        self.spl = self.create_final_sklearn_pipeline(transformer_type=self.pp.transformer_type,\n",
    "                                     model = self.model)\n",
    "        \n",
    "    \n",
    "    # Force to update the model in pipeline\n",
    "    def update_model(self, model:object):\n",
    "        #change model\n",
    "        self.model = model\n",
    "        # recall create final sklearn pipelien method\n",
    "        self.spl = self.create_final_sklearn_pipeline(transformer_type=self.pp.transformer_type,\n",
    "                                     model = self.model)\n",
    "    \n",
    "    # cross validation\n",
    "    def do_cross_validation(self, cv:int, scoring:str):\n",
    "        scores = cross_val_score(\n",
    "            estimator=self.spl,\n",
    "            X=self.dfl.X,\n",
    "            y=self.dfl.y,\n",
    "            scoring=scoring,\n",
    "            cv=cv)\n",
    "        # Multiply by -1 since sklearn calculates *negative* scoring for some of the metrics\n",
    "        if \"neg_\" in scoring:\n",
    "            scores = -1 * scores\n",
    "        return scores\n",
    "        \n",
    "    # GridSearch\n",
    "    def do_grid_search(self, param_grid:object, cv:int,\n",
    "                       scoring:str, n_jobs=None):\n",
    "        \n",
    "        if n_jobs is None:\n",
    "            n_jobs = self.IDEAL_CPU_CORES\n",
    "        \n",
    "        # create GridSeachCV instance\n",
    "        grid_search = GridSearchCV(estimator=self.spl,\n",
    "                                   param_grid=param_grid,\n",
    "                                   cv=cv,\n",
    "                                   scoring=scoring,\n",
    "                                   n_jobs=n_jobs)\n",
    "        # now call fit\n",
    "        grid_search.fit(self.dfl.X, self.dfl.y)\n",
    "        return grid_search\n",
    "    \n",
    "    # do k-fold training\n",
    "    # test_preds_metric has to be a single sklearn metrics object type such as mean_absoulte_error, acccuracy\n",
    "    def do_kfold_training(self, n_splits:int, test_preds_metric=None, random_state=42):\n",
    "        \n",
    "        \"\"\"\n",
    "            This methods returns kfold_metrics_results and test_preds by doing kfold training\n",
    "            test_preds_metric=None by default, takes only single SKLearn Metrics for your test dataset\n",
    "            n_splits=5 by default, takes only int value\n",
    "            random_sate=42, takes only int value\n",
    "\n",
    "        \"\"\" \n",
    "        \n",
    "        #fetch problem type params\n",
    "        _, val_preds_metrics, _, _ = fetch_params_for_problem_type(self.problem_type)\n",
    "        \n",
    "        #create stratified K Folds instance\n",
    "        kfold = StratifiedKFold(n_splits=n_splits,\n",
    "                             random_state=random_state,\n",
    "                             shuffle=True)\n",
    "        \n",
    "        # check for test dataset before prediction\n",
    "        test_preds = None\n",
    "        if self.dfl.X_test is not None:\n",
    "            test_preds = np.zeros(self.dfl.X_test.shape[0])\n",
    "        \n",
    "        # list contains metrics results for each fold\n",
    "        kfold_metrics_results = []\n",
    "        n=0\n",
    "        for train_idx, valid_idx in kfold.split(self.dfl.X, self.dfl.y):\n",
    "            # create X_train\n",
    "            self.dfl.X_train = self.dfl.X.iloc[train_idx]\n",
    "            # create X_valid\n",
    "            self.dfl.X_valid = self.dfl.X.iloc[valid_idx]\n",
    "            # create y_train\n",
    "            self.dfl.y_train = self.dfl.y[train_idx]\n",
    "            # create y_valid\n",
    "            self.dfl.y_valid = self.dfl.y[valid_idx]\n",
    "            \n",
    "            # fit\n",
    "            #TODO use early_stopping_rounds = True for XGBoost based Sklearn Pipeline\n",
    "            self.spl.fit(self.dfl.X_train, self.dfl.y_train)\n",
    "            \n",
    "            \n",
    "            #TO-DO instead of single metrics use list of metrics and calculate mean using dict\n",
    "            metric_result = {}\n",
    "            for metric in val_preds_metrics:\n",
    "                if (\"log_loss\" in str(metric.__name__)) or (\"roc_auc_score\" in str(metric.__name__)):\n",
    "                    #logger.info(\"Predicting Probablities!\")\n",
    "                    preds_probs = self.spl.predict_proba(self.dfl.X_valid)[:, 1]\n",
    "                    metric_result[str(metric.__name__)] = metric(self.dfl.y_valid, preds_probs)\n",
    "\n",
    "                else:\n",
    "                    #logger.info(\"Predicting Score!\")\n",
    "                    preds = self.spl.predict(self.dfl.X_valid)\n",
    "                    metric_result[str(metric.__name__)] = metric(self.dfl.y_valid, preds)\n",
    "\n",
    "            #now show value of all the given metrics\n",
    "            for metric_name, metric_value in metric_result.items():\n",
    "                logger.info(f\"fold: {n+1} {metric_name} : {metric_value}\")\n",
    "            \n",
    "            #now append each kfold metric_result dict to list\n",
    "            kfold_metrics_results.append(metric_result)\n",
    "            \n",
    "            \n",
    "            # for test preds\n",
    "            if self.dfl.X_test is not None and test_preds_metric is not None:\n",
    "                if (\"log_loss\" in str(test_preds_metric.__name__)) or (\"roc_auc_score\" in str(test_preds_metric.__name__)):\n",
    "                    logger.info(\"Predicting Test Preds Probablities!\")\n",
    "                    test_preds += self.spl.predict_proba(self.dfl.X_test)[:,1] / kfold.n_splits\n",
    "                else:\n",
    "                    test_preds += self.spl.predict(self.dfl.X_test) / kfold.n_splits\n",
    "            elif self.dfl.X_test is None:\n",
    "                logger.warn(f\"Trying to do Test Predictions but No Test Dataset Provided!\")\n",
    "            \n",
    "            # In order to better GC, del X_train, X_valid, y_train, y_valid df after each fold is done,\n",
    "            # they will recreate again next time k-fold is called\n",
    "            unused_df_lst = [self.dfl.X_train, self.dfl.X_valid, self.dfl.y_train, self.dfl.y_valid]\n",
    "            del unused_df_lst\n",
    "            \n",
    "            # increment fold counter label\n",
    "            n += 1\n",
    "        \n",
    "        #logger.info(f\"kfold_metrics_results: {kfold_metrics_results} \")\n",
    "        mean_metrics_results = kfold_dict_mean(kfold_metrics_results)\n",
    "        logger.info(f\" Mean Metrics Results from all Folds are: {mean_metrics_results}\")\n",
    "        \n",
    "        return mean_metrics_results, test_preds\n",
    "    \n",
    "    # Do optuna bases study optimization for hyperparmaeter search\n",
    "    def do_xgb_optuna_optimization(self, optuna_db_path:str, use_gpu=False, opt_trials=100,\n",
    "                                   opt_timeout=360):\n",
    "        \"\"\"\n",
    "            This methods returns and do optuna bases study optimization for hyperparmaeter search\n",
    "            optuna_db_path is output directory you want to use for storing sql db used for optuna\n",
    "            use_gpu=False by default, make it True if running on gpu machine\n",
    "            opt_trials=100 by default, change it based upon need\n",
    "            opt_timeout=360 by default, timeout value in seconds\n",
    "\n",
    "        \"\"\"       \n",
    "            \n",
    "        # get params based on problem type\n",
    "        xgb_model, val_preds_metrics, eval_metric, direction = fetch_params_for_problem_type(self.problem_type)\n",
    "        \n",
    "        # Load the dataset in advance for reusing it each trial execution.\n",
    "        objective = Optuna_Objective(dfl=self.dfl, tmlt=self,\n",
    "                                     val_preds_metrics=val_preds_metrics,\n",
    "                                     xgb_model=xgb_model,\n",
    "                                     xgb_eval_metric=eval_metric,\n",
    "                                     use_gpu=use_gpu)\n",
    "        # create sql db in optuna db path\n",
    "        db_path = os.path.join(optuna_db_path, \"params.db\")\n",
    "        \n",
    "        # now create study\n",
    "        logger.info(f\"Optimization Direction is: {direction}\")\n",
    "        study = optuna.create_study(\n",
    "            direction=direction,\n",
    "            study_name=\"tmlt_autoxgb\",\n",
    "            storage=f\"sqlite:///{db_path}\",\n",
    "            load_if_exists=True,\n",
    "        )\n",
    "        study.optimize(objective, n_trials=opt_trials, timeout=opt_timeout)\n",
    "        return study\n",
    "\n",
    "    \n",
    "    # helper methods for users before updating preprocessor in pipeline\n",
    "    def get_preprocessor_best_params_from_grid_search(self, grid_search_object:object):\n",
    "        pp_best_params = {}\n",
    "        for k in grid_search_object.best_params_:\n",
    "            #print(k)\n",
    "            if 'preprocessor' in k:\n",
    "                key = k.split('__')[1] + \"__\" + k.split('__')[2] \n",
    "                pp_best_params[key] = grid_search_object.best_params_[k]\n",
    "        return pp_best_params\n",
    "    \n",
    "    # helper methods for users before updating model in pipeline\n",
    "    def get_model_best_params_from_grid_search(self, grid_search_object:object):\n",
    "        model_best_params = {}\n",
    "        for k in grid_search_object.best_params_:\n",
    "            #print(k)\n",
    "            if 'model' in k:\n",
    "                key = k.split('__')[1]\n",
    "                model_best_params[key] = grid_search_object.best_params_[k]\n",
    "        return model_best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h2 id=\"TMLT\" class=\"doc_header\"><code>class</code> <code>TMLT</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h2>\n",
       "\n",
       "> <code>TMLT</code>()\n",
       "\n",
       "Represent Tabular ML Toolkit class\n",
       "\n",
       "Attributes:\n",
       "\n",
       "spl: A Scikit MLPipeline instance \n",
       "\n",
       "dfl: A DataFrameLoader instance \n",
       "\n",
       "pp: A PreProcessor instance \n",
       "\n",
       "model: The given Model"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TMLT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"TMLT.prepare_data_for_training\" class=\"doc_header\"><code>TMLT.prepare_data_for_training</code><a href=\"__main__.py#L43\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>TMLT.prepare_data_for_training</code>(**`train_file_path`**:`str`, **`idx_col`**:`str`, **`target`**:`str`, **`random_state`**:`int`, **`model`**:`object`, **`test_file_path`**:`str`=*`None`*, **`problem_type`**=*`'regression'`*, **`nrows`**=*`None`*)\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TMLT.prepare_data_for_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"TMLT.do_xgb_optuna_optimization\" class=\"doc_header\"><code>TMLT.do_xgb_optuna_optimization</code><a href=\"__main__.py#L226\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>TMLT.do_xgb_optuna_optimization</code>(**`optuna_db_path`**:`str`, **`use_gpu`**=*`False`*, **`opt_trials`**=*`100`*, **`opt_timeout`**=*`360`*)\n",
       "\n",
       "This methods returns and do optuna bases study optimization for hyperparmaeter search\n",
       "optuna_db_path is output directory you want to use for storing sql db used for optuna\n",
       "use_gpu=False by default, make it True if running on gpu machine\n",
       "opt_trials=100 by default, change it based upon need\n",
       "opt_timeout=360 by default, timeout value in seconds"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TMLT.do_xgb_optuna_optimization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_dataframeloader.ipynb.\n",
      "Converted 01_preprocessor.ipynb.\n",
      "Converted 02_tmlt.ipynb.\n",
      "Converted 04_optuna_objective.ipynb.\n",
      "Converted 13_Kaggle_TPS_Tutorial.ipynb.\n",
      "Converted BAK_index.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted logger.ipynb.\n",
      "Converted utility.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "# run the script to build \n",
    "\n",
    "from nbdev.export import notebook2script; notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nbdev_env",
   "language": "python",
   "name": "nbdev_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
