{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp Kaggle_TPS_Challenge_Nov_2021_XGB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle TPS Challenge (Nov 2021)\n",
    "\n",
    "> A Tutorial to showcase usage of Tabular_ML_Toolkit library on Kaggle TPS Challenge Nov 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *\n",
    "from nbdev import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabular_ml_toolkit.MLPipeline import *\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score,accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build MLPipeline Class with Kaggle TPS Challenge data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*You can use MLPipeline to quickly train any model which supports scikit-lear fit and transform methods.\n",
    "\n",
    "For example, Here we are using LogisticRegression from Scikit-Learn, on  [Kaggle TPS Challenge (Nov 2021) data](https://www.kaggle.com/c/tabular-playground-series-nov-2021/data)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset file names and Paths\n",
    "DIRECTORY_PATH = \"/Users/pankajmathur/kaggle_datasets/tps_nov_2021/\"\n",
    "TRAIN_FILE = \"train.csv\"\n",
    "TEST_FILE = \"test.csv\"\n",
    "SAMPLE_SUB_FILE = \"sample_submission.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's Use XGBosst on MLPipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*You can also use MLPipeline with XGBoost model, Make sure to install XGBooost depending upon your OS.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*For example, Here we are using LogisticRegression from Scikit-Learn, on  [Kaggle TPS Challenge (Nov 2021) data](https://www.kaggle.com/c/tabular-playground-series-nov-2021/data)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best way to install xgboost if you are on macosx and windows machine is using conda\n",
    "# !conda install -c conda-forge xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set xgb_params\n",
    "xgb_params = {\n",
    "    'n_estimators': 1000,\n",
    "    'learning_rate': 0.01,\n",
    "    'max_depth': 9,\n",
    "    'booster': 'gbtree',\n",
    "    'eval_metric': 'auc',\n",
    "#     'tree_method': 'gpu_hist',\n",
    "#     'predictor': 'gpu_predictor',\n",
    "    'use_label_encoder': False,\n",
    "    'random_state': 42\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "# create xgb Classifier model\n",
    "xgb_model = XGBClassifier(**xgb_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# createm ml pipeline for xgb model\n",
    "xgb_ml_pl = MLPipeline().prepare_data_for_training(\n",
    "    train_file_path= DIRECTORY_PATH + TRAIN_FILE,\n",
    "    test_file_path= DIRECTORY_PATH + TEST_FILE,\n",
    "    idx_col=\"id\",\n",
    "    target=\"target\",\n",
    "    model=xgb_model,\n",
    "    random_state=42,\n",
    "    valid_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick check on dataframe shapes\n",
    "print(f\"X_train shape is {xgb_ml_pl.dataframeloader.X_train.shape}\" )\n",
    "print(f\"X_valid shape is {xgb_ml_pl.dataframeloader.X_valid.shape}\" )\n",
    "print(f\"y_train shape is {xgb_ml_pl.dataframeloader.y_train.shape}\")\n",
    "print(f\"y_valid shape is {xgb_ml_pl.dataframeloader.y_valid.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit & Predict\n",
    "xgb_ml_pl.scikit_pipeline.fit(xgb_ml_pl.dataframeloader.X_train,\n",
    "                              xgb_ml_pl.dataframeloader.y_train)\n",
    "preds = xgb_ml_pl.scikit_pipeline.predict(xgb_ml_pl.dataframeloader.X_valid)\n",
    "preds_probs = xgb_ml_pl.scikit_pipeline.predict_proba(xgb_ml_pl.dataframeloader.X_valid)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick check on predictions and predictions probabilities shape\n",
    "print(f\"preds shape is {preds.shape}\" )\n",
    "print(f\"preds_probs shape is {preds_probs.shape}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics\n",
    "auc = roc_auc_score(xgb_ml_pl.dataframeloader.y_valid, preds_probs)\n",
    "acc = accuracy_score(xgb_ml_pl.dataframeloader.y_valid, preds)\n",
    "\n",
    "print(f\"AUC is : {auc} while Accuracy is : {acc} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's do Cross Validation for XGB Model on our MLPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # createm ml pipeline for scikit-learn model\n",
    "# xgb_ml_pl = MLPipeline().prepare_data_for_cv(train_file_path= \"input/home_data/train.csv\",\n",
    "#                                              test_file_path= \"input/home_data/test.csv\",\n",
    "#                                              idx_col=\"Id\", target=\"SalePrice\",\n",
    "#                                              model=xgb_model,random_state=42,\n",
    "#                                              cv_cols_type = \"all\") #cv_cols_type = all|num|cat\n",
    "# # Now fit and predict\n",
    "# scores = xgb_ml_pl.cross_validation(estimator=xgb_ml_pl.scikit_pipeline, cv=5,\n",
    "#                                     scoring='neg_mean_absolute_error')\n",
    "# print(\"scores:\", scores)\n",
    "# print(\"Average MAE score:\", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # hide\n",
    "# # run the script to build \n",
    "\n",
    "# from nbdev.export import notebook2script; notebook2script()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Kaggle Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds_probs = sci_ml_pl.scikit_pipeline.predict_proba(sci_ml_pl.dataframeloader.X_test)[:,1]\n",
    "print(f\"X_train shape is {sci_ml_pl.dataframeloader.X_test.shape}\" )\n",
    "print(f\"test_preds_probs shape is {test_preds_probs.shape}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv(DIRECTORY_PATH + SAMPLE_SUB_FILE)\n",
    "sub['target'] = test_preds_probs\n",
    "sub.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
