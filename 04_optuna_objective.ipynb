{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "babe0d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1663c905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp optuna_objective"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f832f4",
   "metadata": {},
   "source": [
    "# Optuna Objective\n",
    "\n",
    "> An API to create Optuna Ojbective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "088dd527",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *\n",
    "from nbdev import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a92858f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from tabular_ml_toolkit.dataframeloader import *\n",
    "from tabular_ml_toolkit.preprocessor import *\n",
    "from tabular_ml_toolkit.logger import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e40504c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# hide\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, log_loss, f1_score, precision_score, recall_score\n",
    "# for Optuna\n",
    "import optuna\n",
    "#for XGB\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "\n",
    "\n",
    "# for displaying diagram of pipelines \n",
    "from sklearn import set_config\n",
    "set_config(display=\"diagram\")\n",
    "\n",
    "# for finding n_jobs in all sklearn estimators\n",
    "from sklearn.utils import all_estimators\n",
    "import inspect\n",
    "\n",
    "# Just to compare fit times\n",
    "import time\n",
    "\n",
    "# for os specific settings\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78618889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "class Optuna_Objective:\n",
    "    \"\"\"\n",
    "    Represent Optuna Objective class\n",
    "    \n",
    "    Attributes:\\n\n",
    "    pl: A tmlt instance \\n\n",
    "    dfl: A DataFrameLoader instance \\n\n",
    "    pp: A PreProcessor Instance \\n\n",
    "    model: The given Model\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dfl, tmlt, val_preds_metrics, xgb_model, xgb_eval_metric, use_gpu):\n",
    "        self.X = dfl.X\n",
    "        self.y = dfl.y\n",
    "        self.use_gpu = use_gpu\n",
    "        self.tmlt = tmlt\n",
    "        self.xgb_model = xgb_model\n",
    "        self.trial = None\n",
    "        self.xgb_eval_metric = xgb_eval_metric\n",
    "        self.val_preds_metrics = val_preds_metrics\n",
    "\n",
    "    def __call__(self, trial):\n",
    "        self.trial = trial\n",
    "        \n",
    "        #get_params here\n",
    "        xgb_params = self.get_xgb_params(self.trial, use_gpu=self.use_gpu)\n",
    "        early_stopping_rounds = xgb_params[\"early_stopping_rounds\"]\n",
    "        del xgb_params[\"early_stopping_rounds\"]\n",
    "\n",
    "        # create xgb ml model\n",
    "        model = self.xgb_model(\n",
    "            random_state=42,\n",
    "            eval_metric=self.xgb_eval_metric,\n",
    "            use_label_encoder=False,\n",
    "            **xgb_params,\n",
    "        )\n",
    "        # update the model on pipeline\n",
    "        self.tmlt.update_model(model)\n",
    "        \n",
    "        #create train valid datasets for simple training\n",
    "        self.tmlt.dfl.create_train_valid(valid_size=0.2)\n",
    "        # Now fit\n",
    "        logger.info(\"Training Started!\")\n",
    "        self.tmlt.spl.fit(self.tmlt.dfl.X_train, self.tmlt.dfl.y_train)\n",
    "        logger.info(\"Training Ended!\")\n",
    "        \n",
    "        \n",
    "        # choose predict type based upon metrics type\n",
    "        #TO-DO instead of single metrics use list of metrics and calculate mean using dict\n",
    "        metric_result = {}\n",
    "        for metric in self.val_preds_metrics:\n",
    "            if (\"log_loss\" in str(metric.__name__)) or (\"roc_auc_score\" in str(metric.__name__)):\n",
    "                #logger.info(\"Predicting Probablities!\")\n",
    "                preds_probs = self.tmlt.spl.predict_proba(self.tmlt.dfl.X_valid)[:, 1]\n",
    "                metric_result[str(metric.__name__)] = metric(self.tmlt.dfl.y_valid, preds_probs)\n",
    "\n",
    "            else:\n",
    "                #logger.info(\"Predicting Score!\")\n",
    "                preds = self.tmlt.spl.predict(self.tmlt.dfl.X_valid)\n",
    "                metric_result[str(metric.__name__)] = metric(self.tmlt.dfl.y_valid, preds)\n",
    "        \n",
    "        #now show value of all the given metrics\n",
    "        for metric_name, metric_value in metric_result.items():\n",
    "            logger.info(f\"{metric_name}: {metric_value}\")\n",
    "        \n",
    "        # choose return result for Optuna Optimization based upon metric type\n",
    "        if self.xgb_eval_metric == \"logloss\":\n",
    "            return metric_result[\"log_loss\"]\n",
    "        elif self.xgb_eval_metric == \"mlogloss\":\n",
    "            return metric_result[\"log_loss\"]\n",
    "        elif self.xgb_eval_metric == \"rmse\":\n",
    "            return metric_result[\"mean_squared_error\"]\n",
    "        else:\n",
    "            return None        \n",
    "        \n",
    "    \n",
    "    def __str__(self):\n",
    "        \"\"\"Returns human readable string reprsentation\"\"\"\n",
    "        attr_str = (\"X, y, task, use_gpu, tmlt, xgb_model\")\n",
    "        return (\"Optuna Objective object with attributes:\"+attr_str)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n",
    "\n",
    "    #helper methods\n",
    "    #Method to get xgb_params\n",
    "    def get_xgb_params(self, trial, use_gpu):\n",
    "        params = {\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-2, 0.25, log=True),\n",
    "            \"n_estimators\": trial.suggest_categorical(\"n_estimators\", [7000, 15000, 20000]),\n",
    "            \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 1e-8, 100.0, log=True),\n",
    "            \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 1e-8, 100.0, log=True),\n",
    "            \"subsample\": trial.suggest_float(\"subsample\", 0.1, 1.0),\n",
    "            \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.1, 1.0),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 1, 9),\n",
    "            \"early_stopping_rounds\": trial.suggest_int(\"early_stopping_rounds\", 100, 500),\n",
    "        }\n",
    "        if use_gpu:\n",
    "            params[\"tree_method\"] = \"gpu_hist\"\n",
    "            params[\"gpu_id\"] = 0\n",
    "            params[\"predictor\"] = \"gpu_predictor\"\n",
    "        else:\n",
    "            params[\"tree_method\"] = trial.suggest_categorical(\"tree_method\", [\"exact\", \"approx\", \"hist\"])\n",
    "            params[\"booster\"] = trial.suggest_categorical(\"booster\", [\"gbtree\", \"gblinear\"])\n",
    "            if params[\"booster\"] == \"gbtree\":\n",
    "                params[\"gamma\"] = trial.suggest_float(\"gamma\", 1e-8, 1.0, log=True)\n",
    "                params[\"grow_policy\"] = trial.suggest_categorical(\"grow_policy\", [\"depthwise\", \"lossguide\"])\n",
    "\n",
    "        return params\n",
    "                \n",
    "    # core methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30a16564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_dataframeloader.ipynb.\n",
      "Converted 01_preprocessor.ipynb.\n",
      "Converted 02_tmlt.ipynb.\n",
      "Converted 04_optuna_objective.ipynb.\n",
      "Converted 13_Kaggle_TPS_Tutorial.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted logger.ipynb.\n",
      "Converted utility.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "# run the script to build \n",
    "\n",
    "from nbdev.export import notebook2script; notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f1ca3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nbdev_env]",
   "language": "python",
   "name": "conda-env-nbdev_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
