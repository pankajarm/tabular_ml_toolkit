{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "003211d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fcaace4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp optuna_objective"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854ff9c2",
   "metadata": {},
   "source": [
    "# Optuna Objective\n",
    "\n",
    "> An API to create Optuna Ojbective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dca35a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *\n",
    "from nbdev import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "734b9ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from tabular_ml_toolkit.dataframeloader import *\n",
    "from tabular_ml_toolkit.preprocessor import *\n",
    "from tabular_ml_toolkit.logger import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76539283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# hide\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, roc_auc_score,accuracy_score\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, StratifiedKFold\n",
    "# for Optuna\n",
    "import optuna\n",
    "#for XGB\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "\n",
    "\n",
    "# for displaying diagram of pipelines \n",
    "from sklearn import set_config\n",
    "set_config(display=\"diagram\")\n",
    "\n",
    "# for finding n_jobs in all sklearn estimators\n",
    "from sklearn.utils import all_estimators\n",
    "import inspect\n",
    "\n",
    "# Just to compare fit times\n",
    "import time\n",
    "\n",
    "# for os specific settings\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e08df954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "class Optuna_Objective:\n",
    "    \"\"\"\n",
    "    Represent Optuna Objective class\n",
    "    \n",
    "    Attributes:\\n\n",
    "    pipeline: An MLPipeline instance \\n\n",
    "    dfl: A DataFrameLoader instance \\n\n",
    "    pp: A PreProcessor Instance \\n\n",
    "    model: The given Model\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dfl, tmlt, task, xgb_eval_metric, kfold_splits, kfold_metrics, use_gpu):\n",
    "        self.X = dfl.X\n",
    "        self.y = dfl.y\n",
    "        self.task = task\n",
    "        self.use_gpu = use_gpu\n",
    "        self.tmlt = tmlt\n",
    "        self.xgb_model = None\n",
    "        self.trial = None\n",
    "        self.xgb_eval_metric = xgb_eval_metric\n",
    "        self.kfold_splits = kfold_splits\n",
    "        self.kfold_metrics = kfold_metrics\n",
    "\n",
    "    def __call__(self, trial):\n",
    "        x, y = self.X, self.y\n",
    "        self.trial = trial\n",
    "        \n",
    "        #get_params here\n",
    "        self.xgb_params = self.get_xgb_params(self.trial, use_gpu=self.use_gpu)\n",
    "        early_stopping_rounds = self.xgb_params[\"early_stopping_rounds\"]\n",
    "        del self.xgb_params[\"early_stopping_rounds\"]\n",
    "\n",
    "        # get xgb model based on task type\n",
    "        if self.task == \"regression\":\n",
    "            self.xgb_model = XGBRegressor(eval_metric=self.xgb_eval_metric,random_state=42,\n",
    "                                          use_label_encoder=False,**self.xgb_params)\n",
    "        if self.task == \"classification\":\n",
    "            self.xgb_model = XGBClassifier(eval_metric=self.xgb_eval_metric,random_state=42,\n",
    "                                           use_label_encoder=False,**self.xgb_params)\n",
    "\n",
    "        # update the model here on tmlt pipeline\n",
    "        self.tmlt.update_model(self.xgb_model)\n",
    "\n",
    "        #rest remains same\n",
    "        score, _ = self.tmlt.do_k_fold_training(n_splits=self.kfold_splits, metrics=self.kfold_metrics)\n",
    "        metrics_mean_score = np.mean(score)\n",
    "        return metrics_mean_score\n",
    "                \n",
    "        \n",
    "    \n",
    "    def __str__(self):\n",
    "        \"\"\"Returns human readable string reprsentation\"\"\"\n",
    "        attr_str = (\"X, y, task, use_gpu, tmlt, xgb_model\")\n",
    "        return (\"Training Pipeline object with attributes:\"+attr_str)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n",
    "\n",
    "    #helper methods\n",
    "    #Method to get xgb_params\n",
    "    def get_xgb_params(self, trial, use_gpu):\n",
    "        params = {\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-2, 0.25, log=True),\n",
    "            \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 1e-8, 100.0, log=True),\n",
    "            \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 1e-8, 100.0, log=True),\n",
    "            \"subsample\": trial.suggest_float(\"subsample\", 0.1, 1.0),\n",
    "            \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.1, 1.0),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 1, 9),\n",
    "            \"early_stopping_rounds\": trial.suggest_int(\"early_stopping_rounds\", 100, 500),\n",
    "            \"n_estimators\": trial.suggest_categorical(\"n_estimators\", [7000, 15000, 20000]),\n",
    "        }\n",
    "        if use_gpu:\n",
    "            params[\"tree_method\"] = \"gpu_hist\"\n",
    "            params[\"gpu_id\"] = 0\n",
    "            params[\"predictor\"] = \"gpu_predictor\"\n",
    "        else:\n",
    "            params[\"tree_method\"] = trial.suggest_categorical(\"tree_method\", [\"exact\", \"approx\", \"hist\"])\n",
    "            params[\"booster\"] = trial.suggest_categorical(\"booster\", [\"gbtree\", \"gblinear\"])\n",
    "            if params[\"booster\"] == \"gbtree\":\n",
    "                params[\"gamma\"] = trial.suggest_float(\"gamma\", 1e-8, 1.0, log=True)\n",
    "                params[\"grow_policy\"] = trial.suggest_categorical(\"grow_policy\", [\"depthwise\", \"lossguide\"])\n",
    "\n",
    "        return params\n",
    "                \n",
    "    # core methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31bc8830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_dataframeloader.ipynb.\n",
      "Converted 01_preprocessor.ipynb.\n",
      "Converted 02_mlpipeline.ipynb.\n",
      "Converted 03_tutorial.ipynb.\n",
      "Converted 04_optuna_objective.ipynb.\n",
      "Converted 07_kaggle_tps_tutorial.ipynb.\n",
      "Converted 08_optuna_tutorial.ipynb.\n",
      "Converted do_optuna_opt_tutorial.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted logger.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "# run the script to build \n",
    "\n",
    "from nbdev.export import notebook2script; notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b857063",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
