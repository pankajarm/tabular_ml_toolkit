{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "babe0d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1663c905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp xgb_optuna_objective"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f832f4",
   "metadata": {},
   "source": [
    "# XGB Optuna Objective\n",
    "\n",
    "> An API to create Optuna Ojbective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "088dd527",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *\n",
    "from nbdev import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a92858f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from tabular_ml_toolkit.dataframeloader import *\n",
    "from tabular_ml_toolkit.preprocessor import *\n",
    "from tabular_ml_toolkit.logger import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e40504c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# hide\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, log_loss, f1_score, precision_score, recall_score\n",
    "# for Optuna\n",
    "import optuna\n",
    "#for XGB\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "\n",
    "\n",
    "# for displaying diagram of pipelines \n",
    "from sklearn import set_config\n",
    "set_config(display=\"diagram\")\n",
    "\n",
    "# for finding n_jobs in all sklearn estimators\n",
    "from sklearn.utils import all_estimators\n",
    "import inspect\n",
    "\n",
    "# Just to compare fit times\n",
    "import time\n",
    "\n",
    "# for os specific settings\n",
    "import os\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78618889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "class XGB_Optuna_Objective:\n",
    "    \"\"\"\n",
    "    Represent XGB Optuna Objective class\n",
    "    \n",
    "    Attributes:\\n\n",
    "    trial: optuna trial object \\n\n",
    "    use_gpu: list of prediction metrics\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, X_train_np, y_train_np, X_valid_np, y_valid_np, xgb_model_type,\n",
    "                 val_preds_metrics, xgb_eval_metric, use_gpu, verbose):\n",
    "        \n",
    "        #attributes\n",
    "        self.X_train_np = X_train_np\n",
    "        self.y_train_np = y_train_np\n",
    "        self.X_valid_np = X_valid_np\n",
    "        self.y_valid_np = y_valid_np\n",
    "        self.val_preds_metrics = val_preds_metrics\n",
    "        self.xgb_eval_metric = xgb_eval_metric\n",
    "        self.xgb_model_type = xgb_model_type\n",
    "        self.use_gpu = use_gpu\n",
    "        self.verbose = verbose\n",
    "        self.trial = None\n",
    "\n",
    "    def __call__(self, trial):\n",
    "        self.trial = trial\n",
    "        \n",
    "        #get_params here\n",
    "        xgb_params = self.get_xgb_params(self.trial, use_gpu=self.use_gpu)\n",
    "        early_stopping_rounds = xgb_params[\"early_stopping_rounds\"]\n",
    "        del xgb_params[\"early_stopping_rounds\"]\n",
    "        #xgb_params.update({'verbose':self.verbose})\n",
    "        \n",
    "        logger.info(f\"final params {xgb_params}\")\n",
    "        \n",
    "        # create xgb ml model\n",
    "        model = self.xgb_model_type(\n",
    "            random_state=42,\n",
    "            eval_set=[(self.X_valid_np, self.y_valid_np)],\n",
    "            eval_metric=self.xgb_eval_metric,\n",
    "            use_label_encoder=False,\n",
    "            #early_stopping_rounds=early_stopping_rounds,\n",
    "            **xgb_params,\n",
    "        )\n",
    "    \n",
    "        # Now fit\n",
    "        logger.info(\"Training Started!\")\n",
    "        model.fit(self.X_train_np, self.y_train_np, verbose=True)\n",
    "        logger.info(\"Training Ended!\")\n",
    "        \n",
    "        gc.collect()\n",
    "        # choose predict type based upon metrics type\n",
    "        #TO-DO instead of single metrics use list of metrics and calculate mean using dict\n",
    "        metric_result = {}\n",
    "        metric = self.val_preds_metrics\n",
    "        if (\"log_loss\" in str(metric.__name__)) or (\"roc_auc_score\" in str(metric.__name__)):\n",
    "            #logger.info(\"Predicting Probablities!\")\n",
    "            preds_probs = model.predict_proba(self.X_valid_np)[:, 1]\n",
    "            metric_result[str(metric.__name__)] = metric(self.y_valid_np, self.preds_probs)\n",
    "\n",
    "        else:\n",
    "            #logger.info(\"Predicting Score!\")\n",
    "            preds = model.predict(self.X_valid_np)\n",
    "            metric_result[str(metric.__name__)] = metric(self.y_valid_np, preds)\n",
    "        \n",
    "        #now show value of all the given metrics\n",
    "        for metric_name, metric_value in metric_result.items():\n",
    "            logger.info(f\"{metric_name}: {metric_value}\")\n",
    "        \n",
    "        # choose return result for Optuna Optimization based upon metric type\n",
    "        if self.xgb_eval_metric == \"logloss\":\n",
    "            return metric_result[\"log_loss\"]\n",
    "        elif self.xgb_eval_metric == \"mlogloss\":\n",
    "            return metric_result[\"accuracy_score\"]\n",
    "        elif self.xgb_eval_metric == \"rmse\":\n",
    "            return metric_result[\"mean_absolute_error\"]\n",
    "        elif self.xgb_eval_metric == \"auc\":\n",
    "            return metric_result[\"roc_auc_score\"]\n",
    "        else:\n",
    "            return None        \n",
    "        \n",
    "    \n",
    "    def __str__(self):\n",
    "        \"\"\"Returns human readable string reprsentation\"\"\"\n",
    "        attr_str = (\"X_train_np, X_valid_np, y_train_np, y_valid_np, use_gpu, verbose\")\n",
    "        return (\"Optuna Objective object with attributes:\"+attr_str)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n",
    "\n",
    "    #helper methods\n",
    "    #Method to get xgb_params\n",
    "    def get_xgb_params(self, trial, use_gpu):\n",
    "        params = {\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-2, 0.25, log=True),\n",
    "            \"n_estimators\": trial.suggest_categorical(\"n_estimators\", [100, 500, 1000]),\n",
    "            \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 1e-8, 100.0, log=True),\n",
    "            \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 1e-8, 100.0, log=True),\n",
    "            \"subsample\": trial.suggest_float(\"subsample\", 0.1, 1.0),\n",
    "            \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.1, 1.0),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 1, 9),\n",
    "            \"early_stopping_rounds\": trial.suggest_int(\"early_stopping_rounds\", 100, 500),\n",
    "        }\n",
    "        if use_gpu:\n",
    "            params[\"tree_method\"] = \"gpu_hist\"\n",
    "            params[\"gpu_id\"] = 0\n",
    "            params[\"predictor\"] = \"gpu_predictor\"\n",
    "        else:\n",
    "            params[\"tree_method\"] = trial.suggest_categorical(\"tree_method\", [\"exact\", \"approx\", \"hist\"])\n",
    "            params[\"booster\"] = trial.suggest_categorical(\"booster\", [\"gbtree\", \"gblinear\"])\n",
    "            if params[\"booster\"] == \"gbtree\":\n",
    "                params[\"gamma\"] = trial.suggest_float(\"gamma\", 1e-8, 1.0, log=True)\n",
    "                params[\"grow_policy\"] = trial.suggest_categorical(\"grow_policy\", [\"depthwise\", \"lossguide\"])\n",
    "\n",
    "        return params\n",
    "                \n",
    "    # core methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30a16564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_dataframeloader.ipynb.\n",
      "Converted 01_preprocessor.ipynb.\n",
      "Converted 02_tmlt.ipynb.\n",
      "Converted 04_xgb_optuna_objective.ipynb.\n",
      "Converted Kaggle_TPS_Dec_ENSEMBLE_Clean.ipynb.\n",
      "Converted Kaggle_TPS_Dec_Tutorial-Meta.ipynb.\n",
      "Converted Kaggle_TPS_Dec_Tutorial_XGB.ipynb.\n",
      "Converted Kaggle_TPS_Nov_Tutorial.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted logger.ipynb.\n",
      "Converted utility.ipynb.\n",
      "Converted xgb_tabular_ml_toolkit.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "# run the script to build \n",
    "\n",
    "from nbdev.export import notebook2script; notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f1ca3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nbdev",
   "language": "python",
   "name": "nbdev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
