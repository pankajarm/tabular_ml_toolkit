{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp Kaggle_TPS_Challenge_Nov_2021_SCIKIT_LEARN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle TPS Challenge (Nov 2021)\n",
    "\n",
    "> A Tutorial to showcase usage of Tabular_ML_Toolkit library on Kaggle TPS Challenge Nov 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *\n",
    "from nbdev import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabular_ml_toolkit.MLPipeline import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build MLPipeline Class with Kaggle TPS Challenge data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*You can use MLPipeline to quickly train any model which supports scikit-lear fit and transform methods.\n",
    "\n",
    "For example, Here we are using LogisticRegression from Scikit-Learn, on  [Kaggle TPS Challenge (Nov 2021) data](https://www.kaggle.com/c/tabular-playground-series-nov-2021/data)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset file names and Paths\n",
    "DIRECTORY_PATH = \"/Users/pankajmathur/kaggle_datasets/tps_nov_2021/\"\n",
    "TRAIN_FILE = \"train.csv\"\n",
    "TEST_FILE = \"test.csv\"\n",
    "SAMPLE_SUB_FILE = \"sample_submission.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create scikit-learn ml model\n",
    "# scikit_model = LogisticRegression(solver='liblinear', random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # createm ml pipeline for scikit-learn model\n",
    "# sci_ml_pl = MLPipeline().prepare_data_for_training(\n",
    "#     train_file_path= DIRECTORY_PATH + TRAIN_FILE,\n",
    "#     test_file_path= DIRECTORY_PATH + TEST_FILE,\n",
    "#     #make sure to use right index and target column\n",
    "#     idx_col=\"id\",\n",
    "#     target=\"target\",\n",
    "#     model=scikit_model,\n",
    "#     random_state=42,\n",
    "#     valid_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Quick check on dataframe shapes\n",
    "# print(f\"X_train shape is {sci_ml_pl.dataframeloader.X_train.shape}\" )\n",
    "# print(f\"X_valid shape is {sci_ml_pl.dataframeloader.X_valid.shape}\" )\n",
    "# print(f\"y_train shape is {sci_ml_pl.dataframeloader.y_train.shape}\")\n",
    "# print(f\"y_valid shape is {sci_ml_pl.dataframeloader.y_valid.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(sci_ml_pl.dataframeloader.final_cols))\n",
    "# sci_ml_pl.dataframeloader.final_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(sci_ml_pl.dataframeloader.low_card_cat_cols))\n",
    "# sci_ml_pl.dataframeloader.low_card_cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(sci_ml_pl.dataframeloader.high_card_cat_cols))\n",
    "# sci_ml_pl.dataframeloader.high_card_cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(sci_ml_pl.dataframeloader.numerical_cols))\n",
    "# sci_ml_pl.dataframeloader.numerical_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fit & Predict\n",
    "# sci_ml_pl.scikit_pipeline.fit(sci_ml_pl.dataframeloader.X_train, sci_ml_pl.dataframeloader.y_train)\n",
    "# preds = sci_ml_pl.scikit_pipeline.predict(sci_ml_pl.dataframeloader.X_valid)\n",
    "# preds_probs = sci_ml_pl.scikit_pipeline.predict_proba(sci_ml_pl.dataframeloader.X_valid)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # quick check on predictions and predictions probabilities shape\n",
    "# print(f\"preds shape is {preds.shape}\" )\n",
    "# print(f\"preds_probs shape is {preds_probs.shape}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Metrics\n",
    "# auc = roc_auc_score(sci_ml_pl.dataframeloader.y_valid, preds_probs)\n",
    "# acc = accuracy_score(sci_ml_pl.dataframeloader.y_valid, preds)\n",
    "\n",
    "# print(f\"AUC is : {auc} while Accuracy is : {acc} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's do Cross Validation for Scikit Model on our MLPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create scikit-learn ml model\n",
    "# scikit_model = LogisticRegression(solver='liblinear', random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # createm ml pipeline for scikit-learn model\n",
    "# sci_ml_pl = MLPipeline().prepare_data_for_cv(train_file_path= DIRECTORY_PATH + TRAIN_FILE,\n",
    "#                                              test_file_path= DIRECTORY_PATH + TEST_FILE,\n",
    "#                                              idx_col=\"id\",\n",
    "#                                              target=\"target\",\n",
    "#                                              model=scikit_model,\n",
    "#                                              random_state=42,\n",
    "#                                              cv_cols_type = \"all\") #cv_cols_type = all|num|cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Quick check on dataframe shapes\n",
    "# print(len(sci_ml_pl.dataframeloader.cv_cols))\n",
    "# sci_ml_pl.dataframeloader.X_cv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fit & Predict\n",
    "# scores = sci_ml_pl.do_cross_validation(estimator=sci_ml_pl.scikit_pipeline, cv=5,\n",
    "#                                     scoring='roc_auc')\n",
    "# print(\"scores:\", scores)\n",
    "# print(\"Average MAE score:\", scores.mean())\n",
    "# # preds = sci_ml_pl.scikit_pipeline.predict(sci_ml_pl.dataframeloader.X_valid)\n",
    "# # preds_probs = sci_ml_pl.scikit_pipeline.predict_proba(sci_ml_pl.dataframeloader.X_valid)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's do K-Fold Training for Scikit Model on our MLPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create scikit-learn ml model\n",
    "scikit_model = LogisticRegression(solver='liblinear', random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# createm ml pipeline for scikit-learn model\n",
    "sci_ml_pl = MLPipeline().prepare_data_for_k_fold(train_file_path= DIRECTORY_PATH + TRAIN_FILE,\n",
    "                                             test_file_path= DIRECTORY_PATH + TEST_FILE,\n",
    "                                             idx_col=\"id\",\n",
    "                                             target=\"target\",\n",
    "                                             model=scikit_model,\n",
    "                                             random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "# Quick check on dataframe shapes\n",
    "print(len(sci_ml_pl.dataframeloader.cv_cols))\n",
    "# sci_ml_pl.dataframeloader.X_cv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 1 , roc_auc_score: 0.7391650397657262\n",
      "fold: 2 , roc_auc_score: 0.7326477012689827\n",
      "fold: 3 , roc_auc_score: 0.7375102681452796\n",
      "fold: 4 , roc_auc_score: 0.739240317272354\n",
      "fold: 5 , roc_auc_score: 0.7361418197089848\n",
      "fold: 6 , roc_auc_score: 0.7378693659707141\n",
      "fold: 7 , roc_auc_score: 0.7371973875563819\n",
      "fold: 8 , roc_auc_score: 0.737605489427764\n",
      "fold: 9 , roc_auc_score: 0.7382445308505611\n",
      "fold: 10 , roc_auc_score: 0.7378412635681217\n"
     ]
    }
   ],
   "source": [
    "k_fold, metrics_score = sci_ml_pl.do_k_fold_training(n_splits=10, metrics=roc_auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'auc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/yd/85jdd5bx59v81j8xnbhpkb3h0000gq/T/ipykernel_73627/1924717042.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Mean AUC is : {round(np.mean(auc)*100,2)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'auc' is not defined"
     ]
    }
   ],
   "source": [
    "print(f\"Mean AUC is : {round(np.mean(metrics_score)*100,2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Kaggle Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds_probs = sci_ml_pl.do_k_fold_prediction(k_fold=k_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(540000,)\n"
     ]
    }
   ],
   "source": [
    "print(test_preds_probs.shape)\n",
    "# preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/yd/85jdd5bx59v81j8xnbhpkb3h0000gq/T/ipykernel_70118/1622352798.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msub\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDIRECTORY_PATH\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mSAMPLE_SUB_FILE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msub\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0msub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'submission.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'preds' is not defined"
     ]
    }
   ],
   "source": [
    "sub = pd.read_csv(DIRECTORY_PATH + SAMPLE_SUB_FILE)\n",
    "sub['target'] = preds\n",
    "sub.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # hide\n",
    "# # run the script to build \n",
    "\n",
    "# from nbdev.export import notebook2script; notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
