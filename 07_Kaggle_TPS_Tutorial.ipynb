{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started Kaggle TPS Challenge with Tabular ML Toolkit\n",
    "\n",
    "> A Tutorial to showcase usage of tabular_ml_toolkit library on Kaggle TPS Challenge Nov 2021.\n",
    "\n",
    "> tabular_ml_toolkit is a superfast helper library to speedup your machine learning project based on Tabular or Structured data.\n",
    "\n",
    "> It comes with model parallelism and cutting edge hyperparameter tuning techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pip install -U tabular_ml_toolkit`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to Best Use tabular_ml_toolkit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start with your favorite model and then just simply create MLPipeline with one API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*You can use MLPipeline to quickly train any model which supports scikit-lear fit and transform methods.*\n",
    "\n",
    "*For example, Here we are using LogisticRegression from Scikit-Learn, on  [Kaggle TPS Challenge (Nov 2021) data](https://www.kaggle.com/c/tabular-playground-series-nov-2021/data)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pankajmathur/anaconda3/envs/nbdev_env/lib/python3.9/site-packages/redis/connection.py:77: UserWarning: redis-py works best with hiredis. Please consider installing\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from tabular_ml_toolkit.tmlt import *\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.neural_network import BernoulliRBM, MLPClassifier\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# for visualizing pipeline\n",
    "from sklearn import set_config\n",
    "set_config(display=\"diagram\")\n",
    "\n",
    "# just to measure fit performance\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset file names and Paths\n",
    "DIRECTORY_PATH = \"/Users/pankajmathur/kaggle_datasets/tps_nov_2021/\"\n",
    "TRAIN_FILE = \"train.csv\"\n",
    "TEST_FILE = \"test.csv\"\n",
    "SAMPLE_SUB_FILE = \"sample_submission.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create scikit-learn ml model\n",
    "scikit_model = LogisticRegression(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-20 01:10:50,032 INFO 8 cores found, parallel processing is enabled!\n",
      "2021-11-20 01:11:08,458 INFO DataFrame Memory usage decreased to 119.59 Mb (74.4% reduction)\n",
      "2021-11-20 01:11:08,458 INFO No test_file_path given, so training will continue without it!\n",
      "2021-11-20 01:11:10,719 INFO PreProcessing will include target(s) encoding!\n",
      "2021-11-20 01:11:10,735 INFO categorical columns are None, Preprocessing will done accordingly!\n"
     ]
    }
   ],
   "source": [
    "# createm ml pipeline for scikit-learn model\n",
    "tmlt = TMLT().prepare_data_for_training(\n",
    "    train_file_path= DIRECTORY_PATH + TRAIN_FILE,\n",
    "    #test_file_path= DIRECTORY_PATH + TEST_FILE,\n",
    "    #make sure to use right index and target column\n",
    "    idx_col=\"id\",\n",
    "    target=\"target\",\n",
    "    model=scikit_model,\n",
    "    random_state=42,\n",
    "    problem_type=\"classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-90675cc1-0c82-4039-ac76-874b579e7f19 {color: black;background-color: white;}#sk-90675cc1-0c82-4039-ac76-874b579e7f19 pre{padding: 0;}#sk-90675cc1-0c82-4039-ac76-874b579e7f19 div.sk-toggleable {background-color: white;}#sk-90675cc1-0c82-4039-ac76-874b579e7f19 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-90675cc1-0c82-4039-ac76-874b579e7f19 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-90675cc1-0c82-4039-ac76-874b579e7f19 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-90675cc1-0c82-4039-ac76-874b579e7f19 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-90675cc1-0c82-4039-ac76-874b579e7f19 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-90675cc1-0c82-4039-ac76-874b579e7f19 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-90675cc1-0c82-4039-ac76-874b579e7f19 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-90675cc1-0c82-4039-ac76-874b579e7f19 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-90675cc1-0c82-4039-ac76-874b579e7f19 div.sk-estimator:hover {background-color: #d4ebff;}#sk-90675cc1-0c82-4039-ac76-874b579e7f19 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-90675cc1-0c82-4039-ac76-874b579e7f19 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-90675cc1-0c82-4039-ac76-874b579e7f19 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-90675cc1-0c82-4039-ac76-874b579e7f19 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;}#sk-90675cc1-0c82-4039-ac76-874b579e7f19 div.sk-item {z-index: 1;}#sk-90675cc1-0c82-4039-ac76-874b579e7f19 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}#sk-90675cc1-0c82-4039-ac76-874b579e7f19 div.sk-parallel::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-90675cc1-0c82-4039-ac76-874b579e7f19 div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}#sk-90675cc1-0c82-4039-ac76-874b579e7f19 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-90675cc1-0c82-4039-ac76-874b579e7f19 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-90675cc1-0c82-4039-ac76-874b579e7f19 div.sk-parallel-item:only-child::after {width: 0;}#sk-90675cc1-0c82-4039-ac76-874b579e7f19 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;position: relative;}#sk-90675cc1-0c82-4039-ac76-874b579e7f19 div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}#sk-90675cc1-0c82-4039-ac76-874b579e7f19 div.sk-label-container {position: relative;z-index: 2;text-align: center;}#sk-90675cc1-0c82-4039-ac76-874b579e7f19 div.sk-container {display: inline-block;position: relative;}</style><div id=\"sk-90675cc1-0c82-4039-ac76-874b579e7f19\" class\"sk-top-container\"><div class=\"sk-container\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"fec055e2-1d23-4b75-b533-df8bbdc4f431\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"fec055e2-1d23-4b75-b533-df8bbdc4f431\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('num_cols',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer(strategy='constant')),\n",
       "                                                                  ('scaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  ['f0', 'f1', 'f2', 'f3', 'f4',\n",
       "                                                   'f5', 'f6', 'f7', 'f8', 'f9',\n",
       "                                                   'f10', 'f11', 'f12', 'f13',\n",
       "                                                   'f14', 'f15', 'f16', 'f17',\n",
       "                                                   'f18', 'f19', 'f20', 'f21',\n",
       "                                                   'f22', 'f23', 'f24', 'f25',\n",
       "                                                   'f26', 'f27', 'f28', 'f29', ...])])),\n",
       "                ('model', LogisticRegression(n_jobs=7, random_state=42))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"90561050-5d5b-4b6e-b446-072ebf500d06\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"90561050-5d5b-4b6e-b446-072ebf500d06\">preprocessor: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[('num_cols',\n",
       "                                 Pipeline(steps=[('imputer',\n",
       "                                                  SimpleImputer(strategy='constant')),\n",
       "                                                 ('scaler', StandardScaler())]),\n",
       "                                 ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6',\n",
       "                                  'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13',\n",
       "                                  'f14', 'f15', 'f16', 'f17', 'f18', 'f19',\n",
       "                                  'f20', 'f21', 'f22', 'f23', 'f24', 'f25',\n",
       "                                  'f26', 'f27', 'f28', 'f29', ...])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"62e18a34-15c4-45f6-bd45-4c096ef01838\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"62e18a34-15c4-45f6-bd45-4c096ef01838\">num_cols</label><div class=\"sk-toggleable__content\"><pre>['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29', 'f30', 'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37', 'f38', 'f39', 'f40', 'f41', 'f42', 'f43', 'f44', 'f45', 'f46', 'f47', 'f48', 'f49', 'f50', 'f51', 'f52', 'f53', 'f54', 'f55', 'f56', 'f57', 'f58', 'f59', 'f60', 'f61', 'f62', 'f63', 'f64', 'f65', 'f66', 'f67', 'f68', 'f69', 'f70', 'f71', 'f72', 'f73', 'f74', 'f75', 'f76', 'f77', 'f78', 'f79', 'f80', 'f81', 'f82', 'f83', 'f84', 'f85', 'f86', 'f87', 'f88', 'f89', 'f90', 'f91', 'f92', 'f93', 'f94', 'f95', 'f96', 'f97', 'f98', 'f99']</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"2b5d925f-eea3-4870-a784-a01342803c80\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"2b5d925f-eea3-4870-a784-a01342803c80\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy='constant')</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"6641105f-43d2-42d3-a467-06bcc356cd8e\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"6641105f-43d2-42d3-a467-06bcc356cd8e\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"eabb11b9-5755-4197-9ad8-7c1265b2f94e\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"eabb11b9-5755-4197-9ad8-7c1265b2f94e\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(n_jobs=7, random_state=42)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('num_cols',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer(strategy='constant')),\n",
       "                                                                  ('scaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  ['f0', 'f1', 'f2', 'f3', 'f4',\n",
       "                                                   'f5', 'f6', 'f7', 'f8', 'f9',\n",
       "                                                   'f10', 'f11', 'f12', 'f13',\n",
       "                                                   'f14', 'f15', 'f16', 'f17',\n",
       "                                                   'f18', 'f19', 'f20', 'f21',\n",
       "                                                   'f22', 'f23', 'f24', 'f25',\n",
       "                                                   'f26', 'f27', 'f28', 'f29', ...])])),\n",
       "                ('model', LogisticRegression(n_jobs=7, random_state=42))])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmlt.spl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 1, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(tmlt.dfl.y))\n",
    "# print(tmlt.dfl.y.values[10])\n",
    "# print(type(tmlt.dfl.y.values[10]))\n",
    "tmlt.dfl.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmlt.dfl.create_train_valid(valid_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape is (480000, 100)\n",
      "X_valid shape is (120000, 100)\n",
      "y_train shape is (480000,)\n",
      "y_valid shape is (120000,)\n"
     ]
    }
   ],
   "source": [
    "# Quick check on dataframe shapes\n",
    "print(f\"X_train shape is {tmlt.dfl.X_train.shape}\" )\n",
    "print(f\"X_valid shape is {tmlt.dfl.X_valid.shape}\" )\n",
    "print(f\"y_train shape is {tmlt.dfl.y_train.shape}\")\n",
    "print(f\"y_valid shape is {tmlt.dfl.y_valid.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit\n",
    "start = time.time()\n",
    "# Now fit\n",
    "tmlt.spl.fit(tmlt.dfl.X_train, tmlt.dfl.y_train)\n",
    "end = time.time()\n",
    "print(\"Fit Time:\", end - start)\n",
    "\n",
    "#predict\n",
    "preds = tmlt.spl.predict(tmlt.dfl.X_valid)\n",
    "preds_probs = tmlt.spl.predict_proba(tmlt.dfl.X_valid)[:, 1]\n",
    "\n",
    "# Metrics\n",
    "auc = roc_auc_score(tmlt.dfl.y_valid, preds_probs)\n",
    "acc = accuracy_score(tmlt.dfl.y_valid, preds)\n",
    "\n",
    "print(f\"AUC is : {auc} while Accuracy is : {acc} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let's do cross validation to get more clear picture on dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross_validation\n",
    "scores = tmlt.do_cross_validation(cv=5, scoring='roc_auc')\n",
    "print(\"scores:\", scores)\n",
    "print(\"Average auc score:\", scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let's do HyperParams Search using Tune Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmlt.spl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's tune data preprocessing and model hyperparams\n",
    "param_grid = {\n",
    "    \"preprocessor__num_cols__scaler\": [StandardScaler(), MinMaxScaler()],\n",
    "    \"preprocessor__num_cols__imputer\": [SimpleImputer(strategy='median'),\n",
    "                                                 SimpleImputer(strategy='most_frequent')],\n",
    "#     'model__solver': ['lbfgs', 'saga', 'newton-cg', 'sag', 'liblinear'],\n",
    "    'model__max_iter': [100, 1000]\n",
    "}\n",
    "\n",
    "start = time.time()\n",
    "# Now do tune grid search\n",
    "tune_search = tmlt.do_tune_grid_search(param_grid=param_grid,\n",
    "                                       cv=5,\n",
    "                                       scoring='roc_auc',\n",
    "                                      early_stopping=False,\n",
    "                                      time_budget_s=60)\n",
    "end = time.time()\n",
    "print(\"Grid Search Time:\", end - start)\n",
    "\n",
    "print(\"Best params:\")\n",
    "print(tune_search.best_params_)\n",
    "\n",
    "print(f\"Internal CV Metrics score: {(tune_search.best_score_):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now, Let's update the PreProcessor and Model with best params**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_params = tmlt.get_preprocessor_best_params(tune_search)\n",
    "tmlt.update_preprocessor(**pp_params)\n",
    "tmlt.spl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = tmlt.get_model_best_params(tune_search)\n",
    "scikit_model = RandomForestRegressor(**model_params)\n",
    "tmlt.update_model(scikit_model)\n",
    "tmlt.spl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit\n",
    "start = time.time()\n",
    "# Now fit\n",
    "tmlt.spl.fit(tmlt.dfl.X_train, tmlt.dfl.y_train)\n",
    "end = time.time()\n",
    "print(\"Fit Time:\", end - start)\n",
    "\n",
    "#predict\n",
    "preds = tmlt.spl.predict(tmlt.dfl.X_valid)\n",
    "preds_probs = tmlt.spl.predict_proba(tmlt.dfl.X_valid)[:, 1]\n",
    "\n",
    "# Metrics\n",
    "auc = roc_auc_score(tmlt.dfl.y_valid, preds_probs)\n",
    "acc = accuracy_score(tmlt.dfl.y_valid, preds)\n",
    "\n",
    "print(f\"AUC is : {auc} while Accuracy is : {acc} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's Use K-Fold Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check current pipeline\n",
    "tmlt.spl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit and predict\n",
    "sci_model_k_fold, sci_model_metrics_score = tmlt.do_kfold_training(n_splits=5, metrics=roc_auc_score)\n",
    "print(\"mean metrics score:\", np.mean(sci_model_metrics_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Mean metrics_score is : {round(np.mean(metrics_score)*100,2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "sci_model_preds = tmlt.do_k_fold_prediction(k_fold=sci_model_k_fold)\n",
    "\n",
    "print(sci_model_preds.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In background `prepare_data_for_training` and `prepare_data_for_cv`  methods loads your input data into Pandas DataFrame, seprates X(features) and y(target).\n",
    "\n",
    "Then `prepare_data_for_training` methods split X(features) into X_train, y_train, X_valid and y_valid DataFrames.\n",
    "However, `prepare_data_for_cv`  method do not split but let's cross validation split internally X and y DataFrames.\n",
    "\n",
    "Then both methods preprocess all numerical and categorical type data found in these DataFrames using scikit-learn pipelines. Then it bundle preprocessed data with your given model and return an MLPipeline object, this class instance has dataframeloader, preprocessor and scikit-lean pipeline instances, so you can call fit methods on X_train and y_train and predict methods on X_valid or X_test.\n",
    "\n",
    "Please check detail documentation and source code for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*NOTE: If you want to customize data and preprocessing steps you can do so by using `DataFrameLoader` and `PreProessor` classes. Check detail documentations for these classes for more options.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's Use XGBosst on MLPipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*You can also use MLPipeline with XGBoost model, Just make sure to install XGBooost first depending upon your OS.*\n",
    "\n",
    "*After that all steps remains same. Here is example using XGBRegressor with [Melbourne Home Sale price data](https://www.kaggle.com/estrotococo/home-data-for-ml-course)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best way to install xgboost if you are on macosx and windows machine is using conda\n",
    "# !conda install -c conda-forge xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set xgb_params\n",
    "xgb_params = {\n",
    "#     'learning_rate': 0.3,\n",
    "#     'max_depth': 9,\n",
    "#     'booster': 'gbtree',\n",
    "    'eval_metric': 'auc',\n",
    "    'use_label_encoder': False,\n",
    "    'random_state': 42,\n",
    "    # for GPU\n",
    "    #     'tree_method': 'gpu_hist',\n",
    "#     'predictor': 'gpu_predictor'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "# create xgb Classifier model\n",
    "xgb_model = XGBClassifier(**xgb_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update pipeline with xgb model\n",
    "tmlt.update_model(xgb_model)\n",
    "tmlt.spl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit\n",
    "start = time.time()\n",
    "# Now fit\n",
    "tmlt.spl.fit(tmlt.dfl.X_train, tmlt.dfl.y_train)\n",
    "end = time.time()\n",
    "print(\"Fit Time:\", end - start)\n",
    "\n",
    "#predict\n",
    "preds = tmlt.spl.predict(tmlt.dfl.X_valid)\n",
    "preds_probs = tmlt.spl.predict_proba(tmlt.dfl.X_valid)[:, 1]\n",
    "\n",
    "# Metrics\n",
    "auc = roc_auc_score(tmlt.dfl.y_valid, preds_probs)\n",
    "acc = accuracy_score(tmlt.dfl.y_valid, preds)\n",
    "\n",
    "print(f\"AUC is : {auc} while Accuracy is : {acc} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let's do HyperParmas search for XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's tune data preprocessing and model hyperparams\n",
    "param_grid = {\n",
    "#     \"preprocessor__num_cols__scaler\": [StandardScaler(), MinMaxScaler()],\n",
    "#     \"preprocessor__low_card_cat_cols__imputer\": [SimpleImputer(strategy='constant'),\n",
    "#                                                  SimpleImputer(strategy='most_frequent')],\n",
    "    'model__booster': ['gbtree', 'gblinear'],\n",
    "#     'model__max_iter': [100, 1000]\n",
    "}\n",
    "\n",
    "start = time.time()\n",
    "# Now do tune grid search\n",
    "tune_search = tmlt.do_tune_grid_search(param_grid=param_grid,\n",
    "                                       cv=3,\n",
    "                                       scoring='roc_auc',\n",
    "                                      early_stopping=False)\n",
    "end = time.time()\n",
    "print(\"Grid Search Time:\", end - start)\n",
    "\n",
    "print(\"Best params:\")\n",
    "print(tune_search.best_params_)\n",
    "\n",
    "print(f\"Internal CV Metrics score: {(tune_search.best_score_):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed CV score was increased using hyper parameter tunning, let's use best_params to do k-fold training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's Use K-Fold Training for xgb model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set new xgb_params\n",
    "xgb_params = {\n",
    "#     'learning_rate': 0.05,\n",
    "    'booster': 'gbtree',\n",
    "    'eval_metric': 'auc',\n",
    "    'use_label_encoder': False,\n",
    "    'random_state': 42,\n",
    "    # for GPU\n",
    "    #     'tree_method': 'gpu_hist',\n",
    "#     'predictor': 'gpu_predictor'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update pipeline with xgb model\n",
    "tmlt.update_model(xgb_model)\n",
    "tmlt.spl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit and predict\n",
    "xgb_k_fold, xgb_k_metrics_score = tmlt.do_k_fold_training(n_splits=5, metrics=roc_auc_score)\n",
    "print(\"mean metrics score:\", np.mean(xgb_k_metrics_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Mean metrics_score is : {round(np.mean(xgb_k_metrics_score)*100,2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "xgb_preds = tmlt.do_k_fold_prediction(k_fold=xgb_k_fold)\n",
    "\n",
    "print(xgb_preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take weighted average of both k-fold models predictions\n",
    "final_preds = ((0.45 * sci_model_preds) + (0.55* xgb_pred)) / 2\n",
    "print(final_preds.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Kaggle Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv(DIRECTORY_PATH + SAMPLE_SUB_FILE)\n",
    "sub['target'] = final_preds\n",
    "sub.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "# run the script to build \n",
    "\n",
    "from nbdev.export import notebook2script; notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
