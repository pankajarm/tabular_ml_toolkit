{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started Kaggle TPS Challenge with Tabular ML Toolkit\n",
    "\n",
    "> A Tutorial to showcase usage of tabular_ml_toolkit library on Kaggle TPS Challenge Nov 2021.\n",
    "\n",
    "> tabular_ml_toolkit is a superfast helper library to speedup your machine learning project based on Tabular or Structured data.\n",
    "\n",
    "> It comes with model parallelism and cutting edge hyperparameter tuning techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pip install -U tabular_ml_toolkit`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to Best Use tabular_ml_toolkit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start with your favorite model and then just simply create MLPipeline with one API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*You can use MLPipeline to quickly train any model which supports scikit-lear fit and transform methods.*\n",
    "\n",
    "*For example, Here we are using LogisticRegression from Scikit-Learn, on  [Kaggle TPS Challenge (Nov 2021) data](https://www.kaggle.com/c/tabular-playground-series-nov-2021/data)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabular_ml_toolkit.tmlt import *\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# for visualizing pipeline\n",
    "from sklearn import set_config\n",
    "set_config(display=\"diagram\")\n",
    "\n",
    "# just to measure fit performance\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset file names and Paths\n",
    "DIRECTORY_PATH = \"/Users/pamathur/kaggle_datasets/tps_nov_2021/\"\n",
    "TRAIN_FILE = \"train.csv\"\n",
    "TEST_FILE = \"test.csv\"\n",
    "SAMPLE_SUB_FILE = \"sample_submission.csv\"\n",
    "OUTPUT_PATH = \"kaggle_tps_output/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a base xgb classifier model\n",
    "xgb_params = {\n",
    "    'use_label_encoder':False,\n",
    "    'eval_metric':'auc',\n",
    "    'random_state':42,\n",
    "    # for GPU\n",
    "#     'tree_method': 'gpu_hist',\n",
    "#     'predictor': 'gpu_predictor',\n",
    "}\n",
    "\n",
    "xgb_model = XGBClassifier(**xgb_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-22 00:50:06,944 INFO 12 cores found, parallel processing is enabled!\n",
      "2021-11-22 00:50:27,378 INFO DataFrame Memory usage decreased to 119.59 Mb (74.4% reduction)\n",
      "2021-11-22 00:50:27,379 INFO No test_file_path given, so training will continue without it!\n",
      "2021-11-22 00:50:29,827 INFO PreProcessing will include target(s) encoding!\n",
      "2021-11-22 00:50:29,847 INFO categorical columns are None, Preprocessing will done accordingly!\n"
     ]
    }
   ],
   "source": [
    "# createm tmlt for xgb model\n",
    "tmlt = TMLT().prepare_data_for_training(\n",
    "    train_file_path= DIRECTORY_PATH + TRAIN_FILE,\n",
    "    #test_file_path= DIRECTORY_PATH + TEST_FILE,\n",
    "    #make sure to use right index and target column\n",
    "    idx_col=\"id\",\n",
    "    target=\"target\",\n",
    "    model=xgb_model,\n",
    "    random_state=42,\n",
    "    problem_type=\"classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-2779f919-fa51-46b5-84c8-503359944830 {color: black;background-color: white;}#sk-2779f919-fa51-46b5-84c8-503359944830 pre{padding: 0;}#sk-2779f919-fa51-46b5-84c8-503359944830 div.sk-toggleable {background-color: white;}#sk-2779f919-fa51-46b5-84c8-503359944830 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-2779f919-fa51-46b5-84c8-503359944830 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-2779f919-fa51-46b5-84c8-503359944830 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-2779f919-fa51-46b5-84c8-503359944830 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-2779f919-fa51-46b5-84c8-503359944830 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-2779f919-fa51-46b5-84c8-503359944830 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-2779f919-fa51-46b5-84c8-503359944830 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-2779f919-fa51-46b5-84c8-503359944830 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-2779f919-fa51-46b5-84c8-503359944830 div.sk-estimator:hover {background-color: #d4ebff;}#sk-2779f919-fa51-46b5-84c8-503359944830 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-2779f919-fa51-46b5-84c8-503359944830 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-2779f919-fa51-46b5-84c8-503359944830 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-2779f919-fa51-46b5-84c8-503359944830 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;}#sk-2779f919-fa51-46b5-84c8-503359944830 div.sk-item {z-index: 1;}#sk-2779f919-fa51-46b5-84c8-503359944830 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}#sk-2779f919-fa51-46b5-84c8-503359944830 div.sk-parallel::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-2779f919-fa51-46b5-84c8-503359944830 div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}#sk-2779f919-fa51-46b5-84c8-503359944830 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-2779f919-fa51-46b5-84c8-503359944830 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-2779f919-fa51-46b5-84c8-503359944830 div.sk-parallel-item:only-child::after {width: 0;}#sk-2779f919-fa51-46b5-84c8-503359944830 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;position: relative;}#sk-2779f919-fa51-46b5-84c8-503359944830 div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}#sk-2779f919-fa51-46b5-84c8-503359944830 div.sk-label-container {position: relative;z-index: 2;text-align: center;}#sk-2779f919-fa51-46b5-84c8-503359944830 div.sk-container {display: inline-block;position: relative;}</style><div id=\"sk-2779f919-fa51-46b5-84c8-503359944830\" class\"sk-top-container\"><div class=\"sk-container\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"b413440d-deb1-491e-a05e-f925e9a3be04\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"b413440d-deb1-491e-a05e-f925e9a3be04\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('num_cols',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer(strategy='constant')),\n",
       "                                                                  ('scaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  ['f0', 'f1', 'f2', 'f3', 'f4',\n",
       "                                                   'f5', 'f6', 'f7', 'f8', 'f9',\n",
       "                                                   'f10', 'f11', 'f12', 'f13',\n",
       "                                                   'f14', 'f15', 'f16', 'f17',\n",
       "                                                   'f18', 'f19', 'f20', 'f21',\n",
       "                                                   'f22', 'f23', 'f24', 'f25',\n",
       "                                                   'f26', 'f27', 'f28', 'f29', ...])])),\n",
       "                (...\n",
       "                               interaction_constraints=None, learning_rate=None,\n",
       "                               max_delta_step=None, max_depth=None,\n",
       "                               min_child_weight=None, missing=nan,\n",
       "                               monotone_constraints=None, n_estimators=100,\n",
       "                               n_jobs=11, num_parallel_tree=None,\n",
       "                               predictor=None, random_state=42, reg_alpha=None,\n",
       "                               reg_lambda=None, scale_pos_weight=None,\n",
       "                               subsample=None, tree_method=None,\n",
       "                               use_label_encoder=False,\n",
       "                               validate_parameters=None, verbosity=None))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"f5bc899f-e434-4dc1-81c5-319b0f829833\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"f5bc899f-e434-4dc1-81c5-319b0f829833\">preprocessor: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[('num_cols',\n",
       "                                 Pipeline(steps=[('imputer',\n",
       "                                                  SimpleImputer(strategy='constant')),\n",
       "                                                 ('scaler', StandardScaler())]),\n",
       "                                 ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6',\n",
       "                                  'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13',\n",
       "                                  'f14', 'f15', 'f16', 'f17', 'f18', 'f19',\n",
       "                                  'f20', 'f21', 'f22', 'f23', 'f24', 'f25',\n",
       "                                  'f26', 'f27', 'f28', 'f29', ...])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"1f273e9a-8b33-4eae-b209-25819768bd6f\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"1f273e9a-8b33-4eae-b209-25819768bd6f\">num_cols</label><div class=\"sk-toggleable__content\"><pre>['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29', 'f30', 'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37', 'f38', 'f39', 'f40', 'f41', 'f42', 'f43', 'f44', 'f45', 'f46', 'f47', 'f48', 'f49', 'f50', 'f51', 'f52', 'f53', 'f54', 'f55', 'f56', 'f57', 'f58', 'f59', 'f60', 'f61', 'f62', 'f63', 'f64', 'f65', 'f66', 'f67', 'f68', 'f69', 'f70', 'f71', 'f72', 'f73', 'f74', 'f75', 'f76', 'f77', 'f78', 'f79', 'f80', 'f81', 'f82', 'f83', 'f84', 'f85', 'f86', 'f87', 'f88', 'f89', 'f90', 'f91', 'f92', 'f93', 'f94', 'f95', 'f96', 'f97', 'f98', 'f99']</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"b0587be5-f8e2-4d8e-8e0f-99b8dc10bb84\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"b0587be5-f8e2-4d8e-8e0f-99b8dc10bb84\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy='constant')</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"09b26faf-7b67-49a5-a5e9-ab4fb30f32c4\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"09b26faf-7b67-49a5-a5e9-ab4fb30f32c4\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"297f5b27-d5b1-4885-a7a7-11d7b1941ee2\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"297f5b27-d5b1-4885-a7a7-11d7b1941ee2\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
       "              colsample_bynode=None, colsample_bytree=None,\n",
       "              enable_categorical=False, eval_metric='auc', gamma=None,\n",
       "              gpu_id=None, importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=11, num_parallel_tree=None,\n",
       "              predictor=None, random_state=42, reg_alpha=None, reg_lambda=None,\n",
       "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
       "              use_label_encoder=False, validate_parameters=None,\n",
       "              verbosity=None)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('num_cols',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer(strategy='constant')),\n",
       "                                                                  ('scaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  ['f0', 'f1', 'f2', 'f3', 'f4',\n",
       "                                                   'f5', 'f6', 'f7', 'f8', 'f9',\n",
       "                                                   'f10', 'f11', 'f12', 'f13',\n",
       "                                                   'f14', 'f15', 'f16', 'f17',\n",
       "                                                   'f18', 'f19', 'f20', 'f21',\n",
       "                                                   'f22', 'f23', 'f24', 'f25',\n",
       "                                                   'f26', 'f27', 'f28', 'f29', ...])])),\n",
       "                (...\n",
       "                               interaction_constraints=None, learning_rate=None,\n",
       "                               max_delta_step=None, max_depth=None,\n",
       "                               min_child_weight=None, missing=nan,\n",
       "                               monotone_constraints=None, n_estimators=100,\n",
       "                               n_jobs=11, num_parallel_tree=None,\n",
       "                               predictor=None, random_state=42, reg_alpha=None,\n",
       "                               reg_lambda=None, scale_pos_weight=None,\n",
       "                               subsample=None, tree_method=None,\n",
       "                               use_label_encoder=False,\n",
       "                               validate_parameters=None, verbosity=None))])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmlt.spl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(type(tmlt.dfl.y))\n",
    "# # print(tmlt.dfl.y.values[10])\n",
    "# # print(type(tmlt.dfl.y.values[10]))\n",
    "# tmlt.dfl.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmlt.dfl.create_train_valid(valid_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Quick check on dataframe shapes\n",
    "# print(f\"X_train shape is {tmlt.dfl.X_train.shape}\" )\n",
    "# print(f\"X_valid shape is {tmlt.dfl.X_valid.shape}\" )\n",
    "# print(f\"y_train shape is {tmlt.dfl.y_train.shape}\")\n",
    "# print(f\"y_valid shape is {tmlt.dfl.y_valid.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fit\n",
    "# start = time.time()\n",
    "# # Now fit\n",
    "# tmlt.spl.fit(tmlt.dfl.X_train, tmlt.dfl.y_train)\n",
    "# end = time.time()\n",
    "# print(\"Fit Time:\", end - start)\n",
    "\n",
    "# #predict\n",
    "# preds = tmlt.spl.predict(tmlt.dfl.X_valid)\n",
    "# preds_probs = tmlt.spl.predict_proba(tmlt.dfl.X_valid)[:, 1]\n",
    "\n",
    "# # Metrics\n",
    "# auc = roc_auc_score(tmlt.dfl.y_valid, preds_probs)\n",
    "# acc = accuracy_score(tmlt.dfl.y_valid, preds)\n",
    "\n",
    "# print(f\"AUC is : {auc} while Accuracy is : {acc} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's do Optuna based HyperParameter search to get best params for fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-22 00:50:29,928 INFO direction is: minimize\n",
      "\u001b[32m[I 2021-11-22 00:50:30,046]\u001b[0m A new study created in RDB with name: tmlt_autoxgb\u001b[0m\n",
      "2021-11-22 00:50:30,777 INFO Training Started\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:50:33] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1634712680264/work/src/learner.cc:576: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "study = tmlt.do_xgb_optuna_optimization(metrics=log_loss, output_dir_path=OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(study.best_trial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### now update the model with best params from study and then update the sklearn pipeline with new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb_params =  study.best_trial.params\n",
    "# xgb_model = XGBRegressor(**xgb_params)\n",
    "# tmlt.update_model(xgb_model)\n",
    "# tmlt.spl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's Use K-Fold Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check current pipeline\n",
    "tmlt.spl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Fold fit and predict on test dataset\n",
    "xgb_model_metrics_score, xgb_model_test_preds= tmlt.do_kfold_training(n_splits=5, metrics=roc_auc_score)\n",
    "print(xgb_model_test_preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # take weighted average of both k-fold models predictions\n",
    "# final_preds = ((0.45 * sci_model_preds) + (0.55* xgb_pred)) / 2\n",
    "# print(final_preds.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Kaggle Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub = pd.read_csv(DIRECTORY_PATH + SAMPLE_SUB_FILE)\n",
    "# sub['target'] = final_preds\n",
    "# sub.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "# run the script to build \n",
    "\n",
    "from nbdev.export import notebook2script; notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nbdev_env]",
   "language": "python",
   "name": "conda-env-nbdev_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
