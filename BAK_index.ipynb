{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import *\n",
    "from nbdev import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tabular ML Toolkit\n",
    "\n",
    "> A super fast helper library to jumpstart your machine learning project based on tabular or structured data.\n",
    "\n",
    "> It comes with model parallelism and cutting edge hyperparameter tuning techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pip install -U tabular_ml_toolkit`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start with your favorite model and then just simply create MLPipeline with one API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*For example, Here we are using RandomForestRegressor from Scikit-Learn, on  [Melbourne Home Sale price data](https://www.kaggle.com/estrotococo/home-data-for-ml-course)*\n",
    "\n",
    "\n",
    "*No need to install scikit-learn as it comes preinstall with Tabular_ML_Toolkit*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabular_ml_toolkit.tmlt import *\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import numpy as np\n",
    "# just to measure fit time\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset file names and Paths\n",
    "DIRECTORY_PATH = \"https://raw.githubusercontent.com/psmathur/tabular_ml_toolkit/master/input/home_data/\"\n",
    "TRAIN_FILE = \"train.csv\"\n",
    "TEST_FILE = \"test.csv\"\n",
    "SAMPLE_SUB_FILE = \"sample_submission.csv\"\n",
    "#Make sure to create this output directory next to this notebook\n",
    "OUTPUT_PATH = \"tutorial_output/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-20 21:20:06,045 INFO 12 cores found, parallel processing is enabled!\n",
      "2021-11-20 21:20:06,576 INFO DataFrame Memory usage decreased to 0.58 Mb (35.5% reduction)\n",
      "2021-11-20 21:20:06,980 INFO DataFrame Memory usage decreased to 0.58 Mb (34.8% reduction)\n",
      "2021-11-20 21:20:07,008 INFO Both Numerical & Categorical columns found, Preprocessing will done accordingly!\n"
     ]
    }
   ],
   "source": [
    "# create xgb ml model\n",
    "xgb_model = XGBRegressor(random_state=42)\n",
    "\n",
    "# createm ml pipeline for scikit-learn model\n",
    "tmlt = TMLT().prepare_data_for_training(\n",
    "    train_file_path= DIRECTORY_PATH+TRAIN_FILE,\n",
    "    test_file_path= DIRECTORY_PATH+TEST_FILE,\n",
    "    idx_col=\"Id\", target=\"SalePrice\",\n",
    "    model=xgb_model,\n",
    "    random_state=42,\n",
    "    problem_type=\"regression\")\n",
    "\n",
    "# visualize scikit-pipeline\n",
    "# tmlt.spl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-20 21:20:07,013 INFO direction is: minimize\n",
      "\u001b[32m[I 2021-11-20 21:20:07,129]\u001b[0m A new study created in RDB with name: tmlt_autoxgb\u001b[0m\n",
      "/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:20:07] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1634712680264/work/src/learner.cc:576: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-20 21:20:11,393 INFO fold: 1 , mean_absolute_error: 35790.80912885274\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:20:11] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1634712680264/work/src/learner.cc:576: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-20 21:20:17,146 INFO fold: 2 , mean_absolute_error: 33405.666309931505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:20:17] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1634712680264/work/src/learner.cc:576: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-20 21:20:22,751 INFO fold: 3 , mean_absolute_error: 39933.20020869007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:20:22] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1634712680264/work/src/learner.cc:576: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-20 21:20:27,901 INFO fold: 4 , mean_absolute_error: 35007.23145869007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:20:27] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1634712680264/work/src/learner.cc:576: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-20 21:20:33,069 INFO fold: 5 , mean_absolute_error: 37255.71524507705\n",
      "2021-11-20 21:20:33,070 INFO  mean metrics score: 36278.524470248296\n",
      "\u001b[32m[I 2021-11-20 21:20:33,109]\u001b[0m Trial 0 finished with value: 36278.524470248296 and parameters: {'learning_rate': 0.06837917669134744, 'reg_lambda': 10.464291360599324, 'reg_alpha': 3.881790940186402e-08, 'subsample': 0.6307472664806286, 'colsample_bytree': 0.7793929777473942, 'max_depth': 7, 'early_stopping_rounds': 403, 'n_estimators': 15000, 'tree_method': 'approx', 'booster': 'gblinear'}. Best is trial 0 with value: 36278.524470248296.\u001b[0m\n",
      "/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:20:33] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1634712680264/work/src/learner.cc:576: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-20 21:20:35,475 INFO fold: 1 , mean_absolute_error: 19432.099475599316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:20:35] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1634712680264/work/src/learner.cc:576: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-20 21:20:37,915 INFO fold: 2 , mean_absolute_error: 17706.260675299658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:20:37] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1634712680264/work/src/learner.cc:576: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-20 21:20:40,171 INFO fold: 3 , mean_absolute_error: 17637.29025979238\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:20:40] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1634712680264/work/src/learner.cc:576: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-20 21:20:42,608 INFO fold: 4 , mean_absolute_error: 16144.116933326199\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:20:42] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1634712680264/work/src/learner.cc:576: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-20 21:20:45,684 INFO fold: 5 , mean_absolute_error: 17603.451713666524\n",
      "2021-11-20 21:20:45,685 INFO  mean metrics score: 17704.643811536815\n",
      "\u001b[32m[I 2021-11-20 21:20:45,710]\u001b[0m Trial 1 finished with value: 17704.643811536815 and parameters: {'learning_rate': 0.013251610183817672, 'reg_lambda': 0.05070997103744175, 'reg_alpha': 6.5596377189764485, 'subsample': 0.24997325724596772, 'colsample_bytree': 0.26866824835445197, 'max_depth': 1, 'early_stopping_rounds': 143, 'n_estimators': 7000, 'tree_method': 'exact', 'booster': 'gblinear'}. Best is trial 1 with value: 17704.643811536815.\u001b[0m\n",
      "/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "2021-11-20 21:21:39,657 INFO fold: 1 , mean_absolute_error: 18901.152236729453\n",
      "2021-11-20 21:22:35,102 INFO fold: 2 , mean_absolute_error: 14733.510019798801\n",
      "2021-11-20 21:23:27,829 INFO fold: 3 , mean_absolute_error: 14491.222201412671\n",
      "2021-11-20 21:24:22,652 INFO fold: 4 , mean_absolute_error: 13826.06889447774\n",
      "2021-11-20 21:25:17,423 INFO fold: 5 , mean_absolute_error: 15390.086740154109\n",
      "2021-11-20 21:25:17,424 INFO  mean metrics score: 15468.408018514552\n",
      "\u001b[32m[I 2021-11-20 21:25:17,451]\u001b[0m Trial 2 finished with value: 15468.408018514552 and parameters: {'learning_rate': 0.011129207646131652, 'reg_lambda': 0.30050997361951176, 'reg_alpha': 52.967728527588584, 'subsample': 0.5258942705414594, 'colsample_bytree': 0.936441228462284, 'max_depth': 9, 'early_stopping_rounds': 323, 'n_estimators': 20000, 'tree_method': 'hist', 'booster': 'gbtree', 'gamma': 0.00016954628965916405, 'grow_policy': 'depthwise'}. Best is trial 2 with value: 15468.408018514552.\u001b[0m\n",
      "/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "2021-11-20 21:25:25,968 INFO fold: 1 , mean_absolute_error: 19026.759765625\n",
      "2021-11-20 21:25:36,473 INFO fold: 2 , mean_absolute_error: 15440.874344499143\n",
      "2021-11-20 21:25:46,801 INFO fold: 3 , mean_absolute_error: 15666.027357127568\n",
      "2021-11-20 21:25:55,522 INFO fold: 4 , mean_absolute_error: 14021.183526862158\n",
      "2021-11-20 21:26:04,050 INFO fold: 5 , mean_absolute_error: 16386.93759364298\n",
      "2021-11-20 21:26:04,050 INFO  mean metrics score: 16108.356517551369\n",
      "\u001b[32m[I 2021-11-20 21:26:04,071]\u001b[0m Trial 3 finished with value: 16108.356517551369 and parameters: {'learning_rate': 0.0503226358564826, 'reg_lambda': 1.1229913666738015e-06, 'reg_alpha': 71.68561238121049, 'subsample': 0.4160637987544571, 'colsample_bytree': 0.6832322539639468, 'max_depth': 2, 'early_stopping_rounds': 146, 'n_estimators': 15000, 'tree_method': 'hist', 'booster': 'gbtree', 'gamma': 4.335629380031712e-05, 'grow_policy': 'depthwise'}. Best is trial 2 with value: 15468.408018514552.\u001b[0m\n",
      "/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "2021-11-20 21:26:41,623 INFO fold: 1 , mean_absolute_error: 19008.612973565923\n",
      "2021-11-20 21:27:20,727 INFO fold: 2 , mean_absolute_error: 15020.97230843322\n",
      "2021-11-20 21:27:58,353 INFO fold: 3 , mean_absolute_error: 14508.753290881848\n",
      "2021-11-20 21:28:36,371 INFO fold: 4 , mean_absolute_error: 14030.747806078767\n",
      "2021-11-20 21:29:12,872 INFO fold: 5 , mean_absolute_error: 14856.748876284246\n",
      "2021-11-20 21:29:12,873 INFO  mean metrics score: 15485.1670510488\n",
      "\u001b[32m[I 2021-11-20 21:29:12,902]\u001b[0m Trial 4 finished with value: 15485.1670510488 and parameters: {'learning_rate': 0.010816847804170051, 'reg_lambda': 5.4599775001054915e-06, 'reg_alpha': 4.6438120639609614e-08, 'subsample': 0.6130640487597314, 'colsample_bytree': 0.8642728092544076, 'max_depth': 6, 'early_stopping_rounds': 168, 'n_estimators': 15000, 'tree_method': 'hist', 'booster': 'gbtree', 'gamma': 1.9097138154879084e-05, 'grow_policy': 'depthwise'}. Best is trial 2 with value: 15468.408018514552.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FrozenTrial(number=2, values=[15468.408018514552], datetime_start=datetime.datetime(2021, 11, 20, 21, 20, 45, 716981), datetime_complete=datetime.datetime(2021, 11, 20, 21, 25, 17, 425720), params={'booster': 'gbtree', 'colsample_bytree': 0.936441228462284, 'early_stopping_rounds': 323, 'gamma': 0.00016954628965916405, 'grow_policy': 'depthwise', 'learning_rate': 0.011129207646131652, 'max_depth': 9, 'n_estimators': 20000, 'reg_alpha': 52.967728527588584, 'reg_lambda': 0.30050997361951176, 'subsample': 0.5258942705414594, 'tree_method': 'hist'}, distributions={'booster': CategoricalDistribution(choices=('gbtree', 'gblinear')), 'colsample_bytree': UniformDistribution(high=1.0, low=0.1), 'early_stopping_rounds': IntUniformDistribution(high=500, low=100, step=1), 'gamma': LogUniformDistribution(high=1.0, low=1e-08), 'grow_policy': CategoricalDistribution(choices=('depthwise', 'lossguide')), 'learning_rate': LogUniformDistribution(high=0.25, low=0.01), 'max_depth': IntUniformDistribution(high=9, low=1, step=1), 'n_estimators': CategoricalDistribution(choices=(7000, 15000, 20000)), 'reg_alpha': LogUniformDistribution(high=100.0, low=1e-08), 'reg_lambda': LogUniformDistribution(high=100.0, low=1e-08), 'subsample': UniformDistribution(high=1.0, low=0.1), 'tree_method': CategoricalDistribution(choices=('exact', 'approx', 'hist'))}, user_attrs={}, system_attrs={}, intermediate_values={}, trial_id=3, state=TrialState.COMPLETE, value=None)\n"
     ]
    }
   ],
   "source": [
    "study = tmlt.do_xgb_optuna_optimization(xgb_eval_metric=\"rmse\",\n",
    "                                        kfold_metrics=mean_absolute_error,\n",
    "                                        output_dir_path=OUTPUT_PATH)\n",
    "print(study.best_trial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update XGB Model with best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-7ac9813a-95f2-488d-b083-60033d6b103f {color: black;background-color: white;}#sk-7ac9813a-95f2-488d-b083-60033d6b103f pre{padding: 0;}#sk-7ac9813a-95f2-488d-b083-60033d6b103f div.sk-toggleable {background-color: white;}#sk-7ac9813a-95f2-488d-b083-60033d6b103f label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-7ac9813a-95f2-488d-b083-60033d6b103f div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-7ac9813a-95f2-488d-b083-60033d6b103f div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-7ac9813a-95f2-488d-b083-60033d6b103f input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-7ac9813a-95f2-488d-b083-60033d6b103f div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-7ac9813a-95f2-488d-b083-60033d6b103f div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-7ac9813a-95f2-488d-b083-60033d6b103f input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-7ac9813a-95f2-488d-b083-60033d6b103f div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-7ac9813a-95f2-488d-b083-60033d6b103f div.sk-estimator:hover {background-color: #d4ebff;}#sk-7ac9813a-95f2-488d-b083-60033d6b103f div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-7ac9813a-95f2-488d-b083-60033d6b103f div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-7ac9813a-95f2-488d-b083-60033d6b103f div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-7ac9813a-95f2-488d-b083-60033d6b103f div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;}#sk-7ac9813a-95f2-488d-b083-60033d6b103f div.sk-item {z-index: 1;}#sk-7ac9813a-95f2-488d-b083-60033d6b103f div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}#sk-7ac9813a-95f2-488d-b083-60033d6b103f div.sk-parallel::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-7ac9813a-95f2-488d-b083-60033d6b103f div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}#sk-7ac9813a-95f2-488d-b083-60033d6b103f div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-7ac9813a-95f2-488d-b083-60033d6b103f div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-7ac9813a-95f2-488d-b083-60033d6b103f div.sk-parallel-item:only-child::after {width: 0;}#sk-7ac9813a-95f2-488d-b083-60033d6b103f div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;position: relative;}#sk-7ac9813a-95f2-488d-b083-60033d6b103f div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}#sk-7ac9813a-95f2-488d-b083-60033d6b103f div.sk-label-container {position: relative;z-index: 2;text-align: center;}#sk-7ac9813a-95f2-488d-b083-60033d6b103f div.sk-container {display: inline-block;position: relative;}</style><div id=\"sk-7ac9813a-95f2-488d-b083-60033d6b103f\" class\"sk-top-container\"><div class=\"sk-container\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"acac6412-d6f6-4989-a460-f561f2931932\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"acac6412-d6f6-4989-a460-f561f2931932\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('num_cols',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer(strategy='constant')),\n",
       "                                                                  ('scaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  ['MSSubClass', 'LotFrontage',\n",
       "                                                   'LotArea', 'OverallQual',\n",
       "                                                   'OverallCond', 'YearBuilt',\n",
       "                                                   'YearRemodAdd', 'MasVnrArea',\n",
       "                                                   'BsmtFinSF1', 'BsmtFinSF2',\n",
       "                                                   'BsmtUnfSF', 'TotalBsmtSF',\n",
       "                                                   '1stFlrSF', '2ndFlrSF',\n",
       "                                                   '...\n",
       "                              max_delta_step=None, max_depth=9,\n",
       "                              min_child_weight=None, missing=nan,\n",
       "                              monotone_constraints=None, n_estimators=20000,\n",
       "                              n_jobs=None, num_parallel_tree=None,\n",
       "                              predictor=None, random_state=None,\n",
       "                              reg_alpha=52.967728527588584,\n",
       "                              reg_lambda=0.30050997361951176,\n",
       "                              scale_pos_weight=None,\n",
       "                              subsample=0.5258942705414594, tree_method='hist',\n",
       "                              validate_parameters=None, verbosity=None))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"6c5d8d3d-170e-42e8-978e-024dcbfab38f\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"6c5d8d3d-170e-42e8-978e-024dcbfab38f\">preprocessor: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[('num_cols',\n",
       "                                 Pipeline(steps=[('imputer',\n",
       "                                                  SimpleImputer(strategy='constant')),\n",
       "                                                 ('scaler', StandardScaler())]),\n",
       "                                 ['MSSubClass', 'LotFrontage', 'LotArea',\n",
       "                                  'OverallQual', 'OverallCond', 'YearBuilt',\n",
       "                                  'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1',\n",
       "                                  'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF',\n",
       "                                  '1stFlrSF', '2ndFlrSF', 'LowQualFinSF',\n",
       "                                  'GrLivArea', 'BsmtF...\n",
       "                                 ['MSZoning', 'Street', 'Alley', 'LotShape',\n",
       "                                  'LandContour', 'Utilities', 'LotConfig',\n",
       "                                  'LandSlope', 'Condition1', 'Condition2',\n",
       "                                  'BldgType', 'HouseStyle', 'RoofStyle',\n",
       "                                  'RoofMatl', 'MasVnrType', 'ExterQual',\n",
       "                                  'ExterCond', 'Foundation', 'BsmtQual',\n",
       "                                  'BsmtCond', 'BsmtExposure', 'BsmtFinType1',\n",
       "                                  'BsmtFinType2', 'Heating', 'HeatingQC',\n",
       "                                  'CentralAir', 'Electrical', 'KitchenQual',\n",
       "                                  'Functional', 'FireplaceQu', ...])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"30288365-ced2-4f07-ba4a-29030da86afb\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"30288365-ced2-4f07-ba4a-29030da86afb\">num_cols</label><div class=\"sk-toggleable__content\"><pre>['MSSubClass', 'LotFrontage', 'LotArea', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces', 'GarageYrBlt', 'GarageCars', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal', 'MoSold', 'YrSold']</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"3147094f-b8d2-44b7-b008-0744a098cf98\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"3147094f-b8d2-44b7-b008-0744a098cf98\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy='constant')</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"5abac1f5-a84a-4112-97a6-b43ce0f63a65\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"5abac1f5-a84a-4112-97a6-b43ce0f63a65\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"f3d90a91-fe5e-4905-a694-04f8927b06f7\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"f3d90a91-fe5e-4905-a694-04f8927b06f7\">cat_cols</label><div class=\"sk-toggleable__content\"><pre>['MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'Heating', 'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual', 'Functional', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'PavedDrive', 'PoolQC', 'Fence', 'MiscFeature', 'SaleType', 'SaleCondition', 'Neighborhood', 'Exterior1st', 'Exterior2nd']</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"a5d0321f-b120-41f2-acfa-f597da892ef5\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"a5d0321f-b120-41f2-acfa-f597da892ef5\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy='constant')</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"7bde0065-6937-4643-a772-b6c22dbf1280\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"7bde0065-6937-4643-a772-b6c22dbf1280\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown='ignore')</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"92d7afb0-0a99-4e5f-8b11-614417efe3e5\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"92d7afb0-0a99-4e5f-8b11-614417efe3e5\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster='gbtree', colsample_bylevel=None,\n",
       "             colsample_bynode=None, colsample_bytree=0.936441228462284,\n",
       "             early_stopping_rounds=323, enable_categorical=False,\n",
       "             gamma=0.00016954628965916405, gpu_id=None, grow_policy='depthwise',\n",
       "             importance_type=None, interaction_constraints=None,\n",
       "             learning_rate=0.011129207646131652, max_delta_step=None,\n",
       "             max_depth=9, min_child_weight=None, missing=nan,\n",
       "             monotone_constraints=None, n_estimators=20000, n_jobs=None,\n",
       "             num_parallel_tree=None, predictor=None, random_state=None,\n",
       "             reg_alpha=52.967728527588584, reg_lambda=0.30050997361951176,\n",
       "             scale_pos_weight=None, subsample=0.5258942705414594,\n",
       "             tree_method='hist', validate_parameters=None, verbosity=None)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('num_cols',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer(strategy='constant')),\n",
       "                                                                  ('scaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  ['MSSubClass', 'LotFrontage',\n",
       "                                                   'LotArea', 'OverallQual',\n",
       "                                                   'OverallCond', 'YearBuilt',\n",
       "                                                   'YearRemodAdd', 'MasVnrArea',\n",
       "                                                   'BsmtFinSF1', 'BsmtFinSF2',\n",
       "                                                   'BsmtUnfSF', 'TotalBsmtSF',\n",
       "                                                   '1stFlrSF', '2ndFlrSF',\n",
       "                                                   '...\n",
       "                              max_delta_step=None, max_depth=9,\n",
       "                              min_child_weight=None, missing=nan,\n",
       "                              monotone_constraints=None, n_estimators=20000,\n",
       "                              n_jobs=None, num_parallel_tree=None,\n",
       "                              predictor=None, random_state=None,\n",
       "                              reg_alpha=52.967728527588584,\n",
       "                              reg_lambda=0.30050997361951176,\n",
       "                              scale_pos_weight=None,\n",
       "                              subsample=0.5258942705414594, tree_method='hist',\n",
       "                              validate_parameters=None, verbosity=None))])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_params =  study.best_trial.params\n",
    "xgb_model = XGBRegressor(**xgb_params)\n",
    "tmlt.update_model(xgb_model)\n",
    "tmlt.spl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's do Hyper Parameters Optimization and find the best params for Data PreProcessing\n",
    "\n",
    " Let's give our Grid Search max 6 minute time budget, Because we don't have eternity to wait for hyperparam tunning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/tune_sklearn/tune_basesearch.py:400: UserWarning: max_iters is set > 1 but incremental/partial training is not enabled. To enable partial training, ensure the estimator has `partial_fit` or `warm_start` and set `early_stopping=True`. Automatically setting max_iters=1.\n",
      "  warnings.warn(\n",
      "/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/ray/tune/tune.py:368: UserWarning: The `loggers` argument is deprecated. Please pass the respective `LoggerCallback` classes to the `callbacks` argument instead. See https://docs.ray.io/en/latest/tune/api_docs/logging.html\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_Trainable pid=13878)\u001b[0m [21:29:17] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1634712680264/work/src/learner.cc:576: \n",
      "\u001b[2m\u001b[36m(_Trainable pid=13878)\u001b[0m Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\u001b[2m\u001b[36m(_Trainable pid=13878)\u001b[0m \n",
      "\u001b[2m\u001b[36m(_Trainable pid=13878)\u001b[0m   This could be a false alarm, with some parameters getting used by language bindings but\n",
      "\u001b[2m\u001b[36m(_Trainable pid=13878)\u001b[0m   then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "\u001b[2m\u001b[36m(_Trainable pid=13878)\u001b[0m   but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\u001b[2m\u001b[36m(_Trainable pid=13878)\u001b[0m \n",
      "\u001b[2m\u001b[36m(_Trainable pid=13878)\u001b[0m \n",
      "\u001b[2m\u001b[36m(_Trainable pid=13874)\u001b[0m [21:29:17] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1634712680264/work/src/learner.cc:576: \n",
      "\u001b[2m\u001b[36m(_Trainable pid=13874)\u001b[0m Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\u001b[2m\u001b[36m(_Trainable pid=13874)\u001b[0m \n",
      "\u001b[2m\u001b[36m(_Trainable pid=13874)\u001b[0m   This could be a false alarm, with some parameters getting used by language bindings but\n",
      "\u001b[2m\u001b[36m(_Trainable pid=13874)\u001b[0m   then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "\u001b[2m\u001b[36m(_Trainable pid=13874)\u001b[0m   but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\u001b[2m\u001b[36m(_Trainable pid=13874)\u001b[0m \n",
      "\u001b[2m\u001b[36m(_Trainable pid=13874)\u001b[0m \n",
      "\u001b[2m\u001b[36m(_Trainable pid=13875)\u001b[0m [21:29:17] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1634712680264/work/src/learner.cc:576: \n",
      "\u001b[2m\u001b[36m(_Trainable pid=13875)\u001b[0m Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\u001b[2m\u001b[36m(_Trainable pid=13875)\u001b[0m \n",
      "\u001b[2m\u001b[36m(_Trainable pid=13875)\u001b[0m   This could be a false alarm, with some parameters getting used by language bindings but\n",
      "\u001b[2m\u001b[36m(_Trainable pid=13875)\u001b[0m   then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "\u001b[2m\u001b[36m(_Trainable pid=13875)\u001b[0m   but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\u001b[2m\u001b[36m(_Trainable pid=13875)\u001b[0m \n",
      "\u001b[2m\u001b[36m(_Trainable pid=13875)\u001b[0m \n",
      "\u001b[2m\u001b[36m(_Trainable pid=13879)\u001b[0m [21:29:17] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1634712680264/work/src/learner.cc:576: \n",
      "\u001b[2m\u001b[36m(_Trainable pid=13879)\u001b[0m Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\u001b[2m\u001b[36m(_Trainable pid=13879)\u001b[0m \n",
      "\u001b[2m\u001b[36m(_Trainable pid=13879)\u001b[0m   This could be a false alarm, with some parameters getting used by language bindings but\n",
      "\u001b[2m\u001b[36m(_Trainable pid=13879)\u001b[0m   then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "\u001b[2m\u001b[36m(_Trainable pid=13879)\u001b[0m   but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\u001b[2m\u001b[36m(_Trainable pid=13879)\u001b[0m \n",
      "\u001b[2m\u001b[36m(_Trainable pid=13879)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SIGINT received (e.g. via Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C one more time (or send SIGINT/SIGKILL/SIGTERM) to skip. \n",
      "\u001b[2m\u001b[36m(pid=13874)\u001b[0m 2021-11-20 21:29:57,210\tERROR worker.py:425 -- SystemExit was raised from the worker\n",
      "\u001b[2m\u001b[36m(pid=13874)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=13874)\u001b[0m   File \"python/ray/_raylet.pyx\", line 692, in ray._raylet.task_execution_handler\n",
      "\u001b[2m\u001b[36m(pid=13874)\u001b[0m   File \"python/ray/_raylet.pyx\", line 521, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(pid=13874)\u001b[0m   File \"python/ray/_raylet.pyx\", line 558, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(pid=13874)\u001b[0m   File \"python/ray/_raylet.pyx\", line 565, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(pid=13874)\u001b[0m   File \"python/ray/_raylet.pyx\", line 569, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(pid=13874)\u001b[0m   File \"python/ray/_raylet.pyx\", line 519, in ray._raylet.execute_task.function_executor\n",
      "\u001b[2m\u001b[36m(pid=13874)\u001b[0m   File \"/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/ray/_private/function_manager.py\", line 576, in actor_method_executor\n",
      "\u001b[2m\u001b[36m(pid=13874)\u001b[0m     return method(__ray_actor, *args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=13874)\u001b[0m   File \"/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
      "\u001b[2m\u001b[36m(pid=13874)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(pid=13874)\u001b[0m   File \"/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/ray/tune/trainable.py\", line 224, in train_buffered\n",
      "\u001b[2m\u001b[36m(pid=13874)\u001b[0m     result = self.train()\n",
      "\u001b[2m\u001b[36m(pid=13874)\u001b[0m   File \"/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
      "\u001b[2m\u001b[36m(pid=13874)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(pid=13874)\u001b[0m   File \"/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/ray/tune/trainable.py\", line 283, in train\n",
      "\u001b[2m\u001b[36m(pid=13874)\u001b[0m     result = self.step()\n",
      "\u001b[2m\u001b[36m(pid=13874)\u001b[0m   File \"/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
      "\u001b[2m\u001b[36m(pid=13874)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(pid=13874)\u001b[0m   File \"/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/tune_sklearn/_trainable.py\", line 106, in step\n",
      "\u001b[2m\u001b[36m(pid=13874)\u001b[0m     return self._train()\n",
      "\u001b[2m\u001b[36m(pid=13874)\u001b[0m   File \"/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
      "\u001b[2m\u001b[36m(pid=13874)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(pid=13874)\u001b[0m   File \"/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/tune_sklearn/_trainable.py\", line 237, in _train\n",
      "\u001b[2m\u001b[36m(pid=13874)\u001b[0m     scores = cross_validate(\n",
      "\u001b[2m\u001b[36m(pid=13874)\u001b[0m   File \"/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 267, in cross_validate\n",
      "\u001b[2m\u001b[36m(pid=13874)\u001b[0m     results = parallel(\n",
      "\u001b[2m\u001b[36m(pid=13874)\u001b[0m   File \"/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/joblib/parallel.py\", line 1043, in __call__\n",
      "\u001b[2m\u001b[36m(pid=13874)\u001b[0m     if self.dispatch_one_batch(iterator):\n",
      "\u001b[2m\u001b[36m(pid=13874)\u001b[0m   File \"/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/joblib/parallel.py\", line 861, in dispatch_one_batch\n",
      "\u001b[2m\u001b[36m(pid=13874)\u001b[0m     self._dispatch(tasks)\n",
      "\u001b[2m\u001b[36m(pid=13874)\u001b[0m   File \"/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/joblib/parallel.py\", line 779, in _dispatch\n",
      "\u001b[2m\u001b[36m(pid=13874)\u001b[0m     job = self._backend.apply_async(batch, callback=cb)\n",
      "\u001b[2m\u001b[36m(pid=13874)\u001b[0m   File \"/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "\u001b[2m\u001b[36m(pid=13874)\u001b[0m     result = ImmediateResult(func)\n",
      "\u001b[2m\u001b[36m(pid=13874)\u001b[0m   File \"/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "\u001b[2m\u001b[36m(pid=13874)\u001b[0m     self.results = batch()\n",
      "\u001b[2m\u001b[36m(pid=13874)\u001b[0m   File \"/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "\u001b[2m\u001b[36m(pid=13874)\u001b[0m     return [func(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=13874)\u001b[0m   File \"/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "\u001b[2m\u001b[36m(pid=13874)\u001b[0m     return [func(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=13874)\u001b[0m   File \"/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/sklearn/utils/fixes.py\", line 209, in __call__\n",
      "\u001b[2m\u001b[36m(pid=13874)\u001b[0m     return self.function(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=13874)\u001b[0m   File \"/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "\u001b[2m\u001b[36m(pid=13874)\u001b[0m     estimator.fit(X_train, y_train, **fit_params)\n",
      "\u001b[2m\u001b[36m(pid=13874)\u001b[0m   File \"/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/sklearn/pipeline.py\", line 394, in fit\n",
      "\u001b[2m\u001b[36m(pid=13874)\u001b[0m     self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "\u001b[2m\u001b[36m(pid=13874)\u001b[0m   File \"/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/xgboost/core.py\", line 506, in inner_f\n",
      "\u001b[2m\u001b[36m(pid=13874)\u001b[0m     return f(**kwargs)\n",
      "\u001b[2m\u001b[36m(pid=13874)\u001b[0m   File \"/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/xgboost/sklearn.py\", line 789, in fit\n",
      "\u001b[2m\u001b[36m(pid=13874)\u001b[0m     self._Booster = train(\n",
      "\u001b[2m\u001b[36m(pid=13874)\u001b[0m   File \"/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/xgboost/training.py\", line 188, in train\n",
      "\u001b[2m\u001b[36m(pid=13874)\u001b[0m     bst = _train_internal(params, dtrain,\n",
      "\u001b[2m\u001b[36m(pid=13874)\u001b[0m   File \"/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/xgboost/training.py\", line 81, in _train_internal\n",
      "\u001b[2m\u001b[36m(pid=13874)\u001b[0m     bst.update(dtrain, i, obj)\n",
      "\u001b[2m\u001b[36m(pid=13874)\u001b[0m   File \"/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/xgboost/core.py\", line 1680, in update\n",
      "\u001b[2m\u001b[36m(pid=13874)\u001b[0m     _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "\u001b[2m\u001b[36m(pid=13874)\u001b[0m   File \"/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/ray/worker.py\", line 422, in sigterm_handler\n",
      "\u001b[2m\u001b[36m(pid=13874)\u001b[0m     sys.exit(1)\n",
      "\u001b[2m\u001b[36m(pid=13874)\u001b[0m SystemExit: 1\n",
      "\u001b[2m\u001b[36m(pid=13874)\u001b[0m [2021-11-20 21:29:57,231 C 13874 105229] core_worker.cc:796:  Check failed: _s.ok() Bad status: IOError: Broken pipe\n",
      "\u001b[2m\u001b[36m(pid=13874)\u001b[0m *** StackTrace Information ***\n",
      "\u001b[2m\u001b[36m(pid=13874)\u001b[0m     ray::GetCallTrace()\n",
      "\u001b[2m\u001b[36m(pid=13874)\u001b[0m     ray::SpdLogMessage::Flush()\n",
      "\u001b[2m\u001b[36m(pid=13874)\u001b[0m     ray::SpdLogMessage::~SpdLogMessage()\n",
      "\u001b[2m\u001b[36m(pid=13874)\u001b[0m     ray::RayLog::~RayLog()\n",
      "\u001b[2m\u001b[36m(pid=13874)\u001b[0m     ray::core::CoreWorker::Exit()\n",
      "\u001b[2m\u001b[36m(pid=13874)\u001b[0m     ray::core::CoreWorker::ExecuteTask()\n",
      "\u001b[2m\u001b[36m(pid=13874)\u001b[0m     std::__1::__function::__func<>::operator()()\n",
      "\u001b[2m\u001b[36m(pid=13874)\u001b[0m     std::__1::__function::__func<>::operator()()\n",
      "\u001b[2m\u001b[36m(pid=13874)\u001b[0m     ray::core::InboundRequest::Accept()\n",
      "\u001b[2m\u001b[36m(pid=13874)\u001b[0m     ray::core::ActorSchedulingQueue::ScheduleRequests()\n",
      "\u001b[2m\u001b[36m(pid=13874)\u001b[0m     ray::core::ActorSchedulingQueue::Add()\n",
      "\u001b[2m\u001b[36m(pid=13874)\u001b[0m     ray::core::CoreWorkerDirectTaskReceiver::HandleTask()\n",
      "\u001b[2m\u001b[36m(pid=13874)\u001b[0m     std::__1::__function::__func<>::operator()()\n",
      "\u001b[2m\u001b[36m(pid=13874)\u001b[0m     boost::asio::detail::completion_handler<>::do_complete()\n",
      "\u001b[2m\u001b[36m(pid=13874)\u001b[0m     boost::asio::detail::scheduler::do_run_one()\n",
      "\u001b[2m\u001b[36m(pid=13874)\u001b[0m     boost::asio::detail::scheduler::run()\n",
      "\u001b[2m\u001b[36m(pid=13874)\u001b[0m     boost::asio::io_context::run()\n",
      "\u001b[2m\u001b[36m(pid=13874)\u001b[0m     ray::core::CoreWorkerProcess::RunTaskExecutionLoop()\n",
      "\u001b[2m\u001b[36m(pid=13874)\u001b[0m     __pyx_pw_3ray_7_raylet_10CoreWorker_9run_task_loop()\n",
      "\u001b[2m\u001b[36m(pid=13874)\u001b[0m     method_vectorcall_NOARGS\n",
      "\u001b[2m\u001b[36m(pid=13874)\u001b[0m     call_function\n",
      "\u001b[2m\u001b[36m(pid=13874)\u001b[0m     _PyEval_EvalFrameDefault\n",
      "\u001b[2m\u001b[36m(pid=13874)\u001b[0m     _PyFunction_Vectorcall\n",
      "\u001b[2m\u001b[36m(pid=13874)\u001b[0m     call_function\n",
      "\u001b[2m\u001b[36m(pid=13874)\u001b[0m     _PyEval_EvalFrameDefault\n",
      "\u001b[2m\u001b[36m(pid=13874)\u001b[0m     _PyEval_EvalCode\n",
      "\u001b[2m\u001b[36m(pid=13874)\u001b[0m     pyrun_file\n",
      "\u001b[2m\u001b[36m(pid=13874)\u001b[0m     pyrun_simple_file\n",
      "\u001b[2m\u001b[36m(pid=13874)\u001b[0m     PyRun_SimpleFileExFlags\n",
      "\u001b[2m\u001b[36m(pid=13874)\u001b[0m     pymain_run_file\n",
      "\u001b[2m\u001b[36m(pid=13874)\u001b[0m     pymain_run_python\n",
      "\u001b[2m\u001b[36m(pid=13874)\u001b[0m     Py_RunMain\n",
      "\u001b[2m\u001b[36m(pid=13874)\u001b[0m     pymain_main\n",
      "\u001b[2m\u001b[36m(pid=13874)\u001b[0m     main\n",
      "\u001b[2m\u001b[36m(pid=13874)\u001b[0m     start\n",
      "\u001b[2m\u001b[36m(pid=13874)\u001b[0m     0x0\n",
      "\u001b[2m\u001b[36m(pid=13874)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=13878)\u001b[0m 2021-11-20 21:29:57,209\tERROR worker.py:425 -- SystemExit was raised from the worker\n",
      "\u001b[2m\u001b[36m(pid=13878)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=13878)\u001b[0m   File \"python/ray/_raylet.pyx\", line 692, in ray._raylet.task_execution_handler\n",
      "\u001b[2m\u001b[36m(pid=13878)\u001b[0m   File \"python/ray/_raylet.pyx\", line 521, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(pid=13878)\u001b[0m   File \"python/ray/_raylet.pyx\", line 558, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(pid=13878)\u001b[0m   File \"python/ray/_raylet.pyx\", line 565, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(pid=13878)\u001b[0m   File \"python/ray/_raylet.pyx\", line 569, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(pid=13878)\u001b[0m   File \"python/ray/_raylet.pyx\", line 519, in ray._raylet.execute_task.function_executor\n",
      "\u001b[2m\u001b[36m(pid=13878)\u001b[0m   File \"/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/ray/_private/function_manager.py\", line 576, in actor_method_executor\n",
      "\u001b[2m\u001b[36m(pid=13878)\u001b[0m     return method(__ray_actor, *args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=13878)\u001b[0m   File \"/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
      "\u001b[2m\u001b[36m(pid=13878)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(pid=13878)\u001b[0m   File \"/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/ray/tune/trainable.py\", line 224, in train_buffered\n",
      "\u001b[2m\u001b[36m(pid=13878)\u001b[0m     result = self.train()\n",
      "\u001b[2m\u001b[36m(pid=13878)\u001b[0m   File \"/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
      "\u001b[2m\u001b[36m(pid=13878)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(pid=13878)\u001b[0m   File \"/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/ray/tune/trainable.py\", line 283, in train\n",
      "\u001b[2m\u001b[36m(pid=13878)\u001b[0m     result = self.step()\n",
      "\u001b[2m\u001b[36m(pid=13878)\u001b[0m   File \"/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
      "\u001b[2m\u001b[36m(pid=13878)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(pid=13878)\u001b[0m   File \"/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/tune_sklearn/_trainable.py\", line 106, in step\n",
      "\u001b[2m\u001b[36m(pid=13878)\u001b[0m     return self._train()\n",
      "\u001b[2m\u001b[36m(pid=13878)\u001b[0m   File \"/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
      "\u001b[2m\u001b[36m(pid=13878)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(pid=13878)\u001b[0m   File \"/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/tune_sklearn/_trainable.py\", line 237, in _train\n",
      "\u001b[2m\u001b[36m(pid=13878)\u001b[0m     scores = cross_validate(\n",
      "\u001b[2m\u001b[36m(pid=13878)\u001b[0m   File \"/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 267, in cross_validate\n",
      "\u001b[2m\u001b[36m(pid=13878)\u001b[0m     results = parallel(\n",
      "\u001b[2m\u001b[36m(pid=13878)\u001b[0m   File \"/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/joblib/parallel.py\", line 1043, in __call__\n",
      "\u001b[2m\u001b[36m(pid=13878)\u001b[0m     if self.dispatch_one_batch(iterator):\n",
      "\u001b[2m\u001b[36m(pid=13878)\u001b[0m   File \"/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/joblib/parallel.py\", line 861, in dispatch_one_batch\n",
      "\u001b[2m\u001b[36m(pid=13878)\u001b[0m     self._dispatch(tasks)\n",
      "\u001b[2m\u001b[36m(pid=13878)\u001b[0m   File \"/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/joblib/parallel.py\", line 779, in _dispatch\n",
      "\u001b[2m\u001b[36m(pid=13878)\u001b[0m     job = self._backend.apply_async(batch, callback=cb)\n",
      "\u001b[2m\u001b[36m(pid=13878)\u001b[0m   File \"/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "\u001b[2m\u001b[36m(pid=13878)\u001b[0m     result = ImmediateResult(func)\n",
      "\u001b[2m\u001b[36m(pid=13878)\u001b[0m   File \"/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "\u001b[2m\u001b[36m(pid=13878)\u001b[0m     self.results = batch()\n",
      "\u001b[2m\u001b[36m(pid=13878)\u001b[0m   File \"/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "\u001b[2m\u001b[36m(pid=13878)\u001b[0m     return [func(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=13878)\u001b[0m   File \"/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "\u001b[2m\u001b[36m(pid=13878)\u001b[0m     return [func(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=13878)\u001b[0m   File \"/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/sklearn/utils/fixes.py\", line 209, in __call__\n",
      "\u001b[2m\u001b[36m(pid=13878)\u001b[0m     return self.function(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=13878)\u001b[0m   File \"/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "\u001b[2m\u001b[36m(pid=13878)\u001b[0m     estimator.fit(X_train, y_train, **fit_params)\n",
      "\u001b[2m\u001b[36m(pid=13878)\u001b[0m   File \"/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/sklearn/pipeline.py\", line 394, in fit\n",
      "\u001b[2m\u001b[36m(pid=13878)\u001b[0m     self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "\u001b[2m\u001b[36m(pid=13878)\u001b[0m   File \"/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/xgboost/core.py\", line 506, in inner_f\n",
      "\u001b[2m\u001b[36m(pid=13878)\u001b[0m     return f(**kwargs)\n",
      "\u001b[2m\u001b[36m(pid=13878)\u001b[0m   File \"/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/xgboost/sklearn.py\", line 789, in fit\n",
      "\u001b[2m\u001b[36m(pid=13878)\u001b[0m     self._Booster = train(\n",
      "\u001b[2m\u001b[36m(pid=13878)\u001b[0m   File \"/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/xgboost/training.py\", line 188, in train\n",
      "\u001b[2m\u001b[36m(pid=13878)\u001b[0m     bst = _train_internal(params, dtrain,\n",
      "\u001b[2m\u001b[36m(pid=13878)\u001b[0m   File \"/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/xgboost/training.py\", line 81, in _train_internal\n",
      "\u001b[2m\u001b[36m(pid=13878)\u001b[0m     bst.update(dtrain, i, obj)\n",
      "\u001b[2m\u001b[36m(pid=13878)\u001b[0m   File \"/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/xgboost/core.py\", line 1680, in update\n",
      "\u001b[2m\u001b[36m(pid=13878)\u001b[0m     _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "\u001b[2m\u001b[36m(pid=13878)\u001b[0m   File \"/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/ray/worker.py\", line 422, in sigterm_handler\n",
      "\u001b[2m\u001b[36m(pid=13878)\u001b[0m     sys.exit(1)\n",
      "\u001b[2m\u001b[36m(pid=13878)\u001b[0m SystemExit: 1\n",
      "\u001b[2m\u001b[36m(pid=13878)\u001b[0m [2021-11-20 21:29:57,229 C 13878 105244] core_worker.cc:796:  Check failed: _s.ok() Bad status: IOError: Broken pipe\n",
      "\u001b[2m\u001b[36m(pid=13878)\u001b[0m *** StackTrace Information ***\n",
      "\u001b[2m\u001b[36m(pid=13878)\u001b[0m     ray::GetCallTrace()\n",
      "\u001b[2m\u001b[36m(pid=13878)\u001b[0m     ray::SpdLogMessage::Flush()\n",
      "\u001b[2m\u001b[36m(pid=13878)\u001b[0m     ray::SpdLogMessage::~SpdLogMessage()\n",
      "\u001b[2m\u001b[36m(pid=13878)\u001b[0m     ray::RayLog::~RayLog()\n",
      "\u001b[2m\u001b[36m(pid=13878)\u001b[0m     ray::core::CoreWorker::Exit()\n",
      "\u001b[2m\u001b[36m(pid=13878)\u001b[0m     ray::core::CoreWorker::ExecuteTask()\n",
      "\u001b[2m\u001b[36m(pid=13878)\u001b[0m     std::__1::__function::__func<>::operator()()\n",
      "\u001b[2m\u001b[36m(pid=13878)\u001b[0m     std::__1::__function::__func<>::operator()()\n",
      "\u001b[2m\u001b[36m(pid=13878)\u001b[0m     ray::core::InboundRequest::Accept()\n",
      "\u001b[2m\u001b[36m(pid=13878)\u001b[0m     ray::core::ActorSchedulingQueue::ScheduleRequests()\n",
      "\u001b[2m\u001b[36m(pid=13878)\u001b[0m     ray::core::ActorSchedulingQueue::Add()\n",
      "\u001b[2m\u001b[36m(pid=13878)\u001b[0m     ray::core::CoreWorkerDirectTaskReceiver::HandleTask()\n",
      "\u001b[2m\u001b[36m(pid=13878)\u001b[0m     std::__1::__function::__func<>::operator()()\n",
      "\u001b[2m\u001b[36m(pid=13878)\u001b[0m     boost::asio::detail::completion_handler<>::do_complete()\n",
      "\u001b[2m\u001b[36m(pid=13878)\u001b[0m     boost::asio::detail::scheduler::do_run_one()\n",
      "\u001b[2m\u001b[36m(pid=13878)\u001b[0m     boost::asio::detail::scheduler::run()\n",
      "\u001b[2m\u001b[36m(pid=13878)\u001b[0m     boost::asio::io_context::run()\n",
      "\u001b[2m\u001b[36m(pid=13878)\u001b[0m     ray::core::CoreWorkerProcess::RunTaskExecutionLoop()\n",
      "\u001b[2m\u001b[36m(pid=13878)\u001b[0m     __pyx_pw_3ray_7_raylet_10CoreWorker_9run_task_loop()\n",
      "\u001b[2m\u001b[36m(pid=13878)\u001b[0m     method_vectorcall_NOARGS\n",
      "\u001b[2m\u001b[36m(pid=13878)\u001b[0m     call_function\n",
      "\u001b[2m\u001b[36m(pid=13878)\u001b[0m     _PyEval_EvalFrameDefault\n",
      "\u001b[2m\u001b[36m(pid=13878)\u001b[0m     _PyFunction_Vectorcall\n",
      "\u001b[2m\u001b[36m(pid=13878)\u001b[0m     call_function\n",
      "\u001b[2m\u001b[36m(pid=13878)\u001b[0m     _PyEval_EvalFrameDefault\n",
      "\u001b[2m\u001b[36m(pid=13878)\u001b[0m     _PyEval_EvalCode\n",
      "\u001b[2m\u001b[36m(pid=13878)\u001b[0m     pyrun_file\n",
      "\u001b[2m\u001b[36m(pid=13878)\u001b[0m     pyrun_simple_file\n",
      "\u001b[2m\u001b[36m(pid=13878)\u001b[0m     PyRun_SimpleFileExFlags\n",
      "\u001b[2m\u001b[36m(pid=13878)\u001b[0m     pymain_run_file\n",
      "\u001b[2m\u001b[36m(pid=13878)\u001b[0m     pymain_run_python\n",
      "\u001b[2m\u001b[36m(pid=13878)\u001b[0m     Py_RunMain\n",
      "\u001b[2m\u001b[36m(pid=13878)\u001b[0m     pymain_main\n",
      "\u001b[2m\u001b[36m(pid=13878)\u001b[0m     main\n",
      "\u001b[2m\u001b[36m(pid=13878)\u001b[0m     start\n",
      "\u001b[2m\u001b[36m(pid=13878)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=13879)\u001b[0m 2021-11-20 21:29:57,209\tERROR worker.py:425 -- SystemExit was raised from the worker\n",
      "\u001b[2m\u001b[36m(pid=13879)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=13879)\u001b[0m   File \"python/ray/_raylet.pyx\", line 692, in ray._raylet.task_execution_handler\n",
      "\u001b[2m\u001b[36m(pid=13879)\u001b[0m   File \"python/ray/_raylet.pyx\", line 521, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(pid=13879)\u001b[0m   File \"python/ray/_raylet.pyx\", line 558, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(pid=13879)\u001b[0m   File \"python/ray/_raylet.pyx\", line 565, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(pid=13879)\u001b[0m   File \"python/ray/_raylet.pyx\", line 569, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(pid=13879)\u001b[0m   File \"python/ray/_raylet.pyx\", line 519, in ray._raylet.execute_task.function_executor\n",
      "\u001b[2m\u001b[36m(pid=13879)\u001b[0m   File \"/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/ray/_private/function_manager.py\", line 576, in actor_method_executor\n",
      "\u001b[2m\u001b[36m(pid=13879)\u001b[0m     return method(__ray_actor, *args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=13879)\u001b[0m   File \"/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
      "\u001b[2m\u001b[36m(pid=13879)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(pid=13879)\u001b[0m   File \"/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/ray/tune/trainable.py\", line 224, in train_buffered\n",
      "\u001b[2m\u001b[36m(pid=13879)\u001b[0m     result = self.train()\n",
      "\u001b[2m\u001b[36m(pid=13879)\u001b[0m   File \"/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
      "\u001b[2m\u001b[36m(pid=13879)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(pid=13879)\u001b[0m   File \"/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/ray/tune/trainable.py\", line 283, in train\n",
      "\u001b[2m\u001b[36m(pid=13879)\u001b[0m     result = self.step()\n",
      "\u001b[2m\u001b[36m(pid=13879)\u001b[0m   File \"/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
      "\u001b[2m\u001b[36m(pid=13879)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(pid=13879)\u001b[0m   File \"/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/tune_sklearn/_trainable.py\", line 106, in step\n",
      "\u001b[2m\u001b[36m(pid=13879)\u001b[0m     return self._train()\n",
      "\u001b[2m\u001b[36m(pid=13879)\u001b[0m   File \"/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
      "\u001b[2m\u001b[36m(pid=13879)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(pid=13879)\u001b[0m   File \"/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/tune_sklearn/_trainable.py\", line 237, in _train\n",
      "\u001b[2m\u001b[36m(pid=13879)\u001b[0m     scores = cross_validate(\n",
      "\u001b[2m\u001b[36m(pid=13879)\u001b[0m   File \"/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 267, in cross_validate\n",
      "\u001b[2m\u001b[36m(pid=13879)\u001b[0m     results = parallel(\n",
      "\u001b[2m\u001b[36m(pid=13879)\u001b[0m   File \"/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/joblib/parallel.py\", line 1043, in __call__\n",
      "\u001b[2m\u001b[36m(pid=13879)\u001b[0m     if self.dispatch_one_batch(iterator):\n",
      "\u001b[2m\u001b[36m(pid=13879)\u001b[0m   File \"/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/joblib/parallel.py\", line 861, in dispatch_one_batch\n",
      "\u001b[2m\u001b[36m(pid=13879)\u001b[0m     self._dispatch(tasks)\n",
      "\u001b[2m\u001b[36m(pid=13879)\u001b[0m   File \"/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/joblib/parallel.py\", line 779, in _dispatch\n",
      "\u001b[2m\u001b[36m(pid=13879)\u001b[0m     job = self._backend.apply_async(batch, callback=cb)\n",
      "\u001b[2m\u001b[36m(pid=13879)\u001b[0m   File \"/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "\u001b[2m\u001b[36m(pid=13879)\u001b[0m     result = ImmediateResult(func)\n",
      "\u001b[2m\u001b[36m(pid=13879)\u001b[0m   File \"/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "\u001b[2m\u001b[36m(pid=13879)\u001b[0m     self.results = batch()\n",
      "\u001b[2m\u001b[36m(pid=13879)\u001b[0m   File \"/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "\u001b[2m\u001b[36m(pid=13879)\u001b[0m     return [func(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=13879)\u001b[0m   File \"/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "\u001b[2m\u001b[36m(pid=13879)\u001b[0m     return [func(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=13879)\u001b[0m   File \"/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/sklearn/utils/fixes.py\", line 209, in __call__\n",
      "\u001b[2m\u001b[36m(pid=13879)\u001b[0m     return self.function(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=13879)\u001b[0m   File \"/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "\u001b[2m\u001b[36m(pid=13879)\u001b[0m     estimator.fit(X_train, y_train, **fit_params)\n",
      "\u001b[2m\u001b[36m(pid=13879)\u001b[0m   File \"/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/sklearn/pipeline.py\", line 394, in fit\n",
      "\u001b[2m\u001b[36m(pid=13879)\u001b[0m     self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "\u001b[2m\u001b[36m(pid=13879)\u001b[0m   File \"/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/xgboost/core.py\", line 506, in inner_f\n",
      "\u001b[2m\u001b[36m(pid=13879)\u001b[0m     return f(**kwargs)\n",
      "\u001b[2m\u001b[36m(pid=13879)\u001b[0m   File \"/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/xgboost/sklearn.py\", line 789, in fit\n",
      "\u001b[2m\u001b[36m(pid=13879)\u001b[0m     self._Booster = train(\n",
      "\u001b[2m\u001b[36m(pid=13879)\u001b[0m   File \"/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/xgboost/training.py\", line 188, in train\n",
      "\u001b[2m\u001b[36m(pid=13879)\u001b[0m     bst = _train_internal(params, dtrain,\n",
      "\u001b[2m\u001b[36m(pid=13879)\u001b[0m   File \"/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/xgboost/training.py\", line 81, in _train_internal\n",
      "\u001b[2m\u001b[36m(pid=13879)\u001b[0m     bst.update(dtrain, i, obj)\n",
      "\u001b[2m\u001b[36m(pid=13879)\u001b[0m   File \"/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/xgboost/core.py\", line 1680, in update\n",
      "\u001b[2m\u001b[36m(pid=13879)\u001b[0m     _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "\u001b[2m\u001b[36m(pid=13879)\u001b[0m   File \"/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/ray/worker.py\", line 422, in sigterm_handler\n",
      "\u001b[2m\u001b[36m(pid=13879)\u001b[0m     sys.exit(1)\n",
      "\u001b[2m\u001b[36m(pid=13879)\u001b[0m SystemExit: 1\n",
      "\u001b[2m\u001b[36m(pid=13879)\u001b[0m [2021-11-20 21:29:57,228 C 13879 105259] core_worker.cc:796:  Check failed: _s.ok() Bad status: IOError: Broken pipe\n",
      "\u001b[2m\u001b[36m(pid=13879)\u001b[0m *** StackTrace Information ***\n",
      "\u001b[2m\u001b[36m(pid=13879)\u001b[0m     ray::GetCallTrace()\n",
      "\u001b[2m\u001b[36m(pid=13879)\u001b[0m     ray::SpdLogMessage::Flush()\n",
      "\u001b[2m\u001b[36m(pid=13879)\u001b[0m     ray::SpdLogMessage::~SpdLogMessage()\n",
      "\u001b[2m\u001b[36m(pid=13879)\u001b[0m     ray::RayLog::~RayLog()\n",
      "\u001b[2m\u001b[36m(pid=13879)\u001b[0m     ray::core::CoreWorker::Exit()\n",
      "\u001b[2m\u001b[36m(pid=13879)\u001b[0m     ray::core::CoreWorker::ExecuteTask()\n",
      "\u001b[2m\u001b[36m(pid=13879)\u001b[0m     std::__1::__function::__func<>::operator()()\n",
      "\u001b[2m\u001b[36m(pid=13879)\u001b[0m     std::__1::__function::__func<>::operator()()\n",
      "\u001b[2m\u001b[36m(pid=13879)\u001b[0m     ray::core::InboundRequest::Accept()\n",
      "\u001b[2m\u001b[36m(pid=13879)\u001b[0m     ray::core::ActorSchedulingQueue::ScheduleRequests()\n",
      "\u001b[2m\u001b[36m(pid=13879)\u001b[0m     ray::core::ActorSchedulingQueue::Add()\n",
      "\u001b[2m\u001b[36m(pid=13879)\u001b[0m     ray::core::CoreWorkerDirectTaskReceiver::HandleTask()\n",
      "\u001b[2m\u001b[36m(pid=13879)\u001b[0m     std::__1::__function::__func<>::operator()()\n",
      "\u001b[2m\u001b[36m(pid=13879)\u001b[0m     boost::asio::detail::completion_handler<>::do_complete()\n",
      "\u001b[2m\u001b[36m(pid=13879)\u001b[0m     boost::asio::detail::scheduler::do_run_one()\n",
      "\u001b[2m\u001b[36m(pid=13879)\u001b[0m     boost::asio::detail::scheduler::run()\n",
      "\u001b[2m\u001b[36m(pid=13879)\u001b[0m     boost::asio::io_context::run()\n",
      "\u001b[2m\u001b[36m(pid=13879)\u001b[0m     ray::core::CoreWorkerProcess::RunTaskExecutionLoop()\n",
      "\u001b[2m\u001b[36m(pid=13879)\u001b[0m     __pyx_pw_3ray_7_raylet_10CoreWorker_9run_task_loop()\n",
      "\u001b[2m\u001b[36m(pid=13879)\u001b[0m     method_vectorcall_NOARGS\n",
      "\u001b[2m\u001b[36m(pid=13879)\u001b[0m     call_function\n",
      "\u001b[2m\u001b[36m(pid=13879)\u001b[0m     _PyEval_EvalFrameDefault\n",
      "\u001b[2m\u001b[36m(pid=13879)\u001b[0m     _PyFunction_Vectorcall\n",
      "\u001b[2m\u001b[36m(pid=13879)\u001b[0m     call_function\n",
      "\u001b[2m\u001b[36m(pid=13879)\u001b[0m     _PyEval_EvalFrameDefault\n",
      "\u001b[2m\u001b[36m(pid=13879)\u001b[0m     _PyEval_EvalCode\n",
      "\u001b[2m\u001b[36m(pid=13879)\u001b[0m     pyrun_file\n",
      "\u001b[2m\u001b[36m(pid=13879)\u001b[0m     pyrun_simple_file\n",
      "\u001b[2m\u001b[36m(pid=13879)\u001b[0m     PyRun_SimpleFileExFlags\n",
      "\u001b[2m\u001b[36m(pid=13879)\u001b[0m     pymain_run_file\n",
      "\u001b[2m\u001b[36m(pid=13879)\u001b[0m     pymain_run_python\n",
      "\u001b[2m\u001b[36m(pid=13879)\u001b[0m     Py_RunMain\n",
      "\u001b[2m\u001b[36m(pid=13879)\u001b[0m     pymain_main\n",
      "\u001b[2m\u001b[36m(pid=13879)\u001b[0m     main\n",
      "\u001b[2m\u001b[36m(pid=13879)\u001b[0m     start\n",
      "\u001b[2m\u001b[36m(pid=13879)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=13875)\u001b[0m 2021-11-20 21:29:57,209\tERROR worker.py:425 -- SystemExit was raised from the worker\n",
      "\u001b[2m\u001b[36m(pid=13875)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=13875)\u001b[0m   File \"python/ray/_raylet.pyx\", line 692, in ray._raylet.task_execution_handler\n",
      "\u001b[2m\u001b[36m(pid=13875)\u001b[0m   File \"python/ray/_raylet.pyx\", line 521, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(pid=13875)\u001b[0m   File \"python/ray/_raylet.pyx\", line 558, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(pid=13875)\u001b[0m   File \"python/ray/_raylet.pyx\", line 565, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(pid=13875)\u001b[0m   File \"python/ray/_raylet.pyx\", line 569, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(pid=13875)\u001b[0m   File \"python/ray/_raylet.pyx\", line 519, in ray._raylet.execute_task.function_executor\n",
      "\u001b[2m\u001b[36m(pid=13875)\u001b[0m   File \"/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/ray/_private/function_manager.py\", line 576, in actor_method_executor\n",
      "\u001b[2m\u001b[36m(pid=13875)\u001b[0m     return method(__ray_actor, *args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=13875)\u001b[0m   File \"/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
      "\u001b[2m\u001b[36m(pid=13875)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(pid=13875)\u001b[0m   File \"/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/ray/tune/trainable.py\", line 224, in train_buffered\n",
      "\u001b[2m\u001b[36m(pid=13875)\u001b[0m     result = self.train()\n",
      "\u001b[2m\u001b[36m(pid=13875)\u001b[0m   File \"/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
      "\u001b[2m\u001b[36m(pid=13875)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(pid=13875)\u001b[0m   File \"/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/ray/tune/trainable.py\", line 283, in train\n",
      "\u001b[2m\u001b[36m(pid=13875)\u001b[0m     result = self.step()\n",
      "\u001b[2m\u001b[36m(pid=13875)\u001b[0m   File \"/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
      "\u001b[2m\u001b[36m(pid=13875)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(pid=13875)\u001b[0m   File \"/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/tune_sklearn/_trainable.py\", line 106, in step\n",
      "\u001b[2m\u001b[36m(pid=13875)\u001b[0m     return self._train()\n",
      "\u001b[2m\u001b[36m(pid=13875)\u001b[0m   File \"/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
      "\u001b[2m\u001b[36m(pid=13875)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(pid=13875)\u001b[0m   File \"/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/tune_sklearn/_trainable.py\", line 237, in _train\n",
      "\u001b[2m\u001b[36m(pid=13875)\u001b[0m     scores = cross_validate(\n",
      "\u001b[2m\u001b[36m(pid=13875)\u001b[0m   File \"/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 267, in cross_validate\n",
      "\u001b[2m\u001b[36m(pid=13875)\u001b[0m     results = parallel(\n",
      "\u001b[2m\u001b[36m(pid=13875)\u001b[0m   File \"/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/joblib/parallel.py\", line 1043, in __call__\n",
      "\u001b[2m\u001b[36m(pid=13875)\u001b[0m     if self.dispatch_one_batch(iterator):\n",
      "\u001b[2m\u001b[36m(pid=13875)\u001b[0m   File \"/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/joblib/parallel.py\", line 861, in dispatch_one_batch\n",
      "\u001b[2m\u001b[36m(pid=13875)\u001b[0m     self._dispatch(tasks)\n",
      "\u001b[2m\u001b[36m(pid=13875)\u001b[0m   File \"/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/joblib/parallel.py\", line 779, in _dispatch\n",
      "\u001b[2m\u001b[36m(pid=13875)\u001b[0m     job = self._backend.apply_async(batch, callback=cb)\n",
      "\u001b[2m\u001b[36m(pid=13875)\u001b[0m   File \"/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "\u001b[2m\u001b[36m(pid=13875)\u001b[0m     result = ImmediateResult(func)\n",
      "\u001b[2m\u001b[36m(pid=13875)\u001b[0m   File \"/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "\u001b[2m\u001b[36m(pid=13875)\u001b[0m     self.results = batch()\n",
      "\u001b[2m\u001b[36m(pid=13875)\u001b[0m   File \"/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "\u001b[2m\u001b[36m(pid=13875)\u001b[0m     return [func(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=13875)\u001b[0m   File \"/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "\u001b[2m\u001b[36m(pid=13875)\u001b[0m     return [func(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=13875)\u001b[0m   File \"/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/sklearn/utils/fixes.py\", line 209, in __call__\n",
      "\u001b[2m\u001b[36m(pid=13875)\u001b[0m     return self.function(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=13875)\u001b[0m   File \"/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "\u001b[2m\u001b[36m(pid=13875)\u001b[0m     estimator.fit(X_train, y_train, **fit_params)\n",
      "\u001b[2m\u001b[36m(pid=13875)\u001b[0m   File \"/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/sklearn/pipeline.py\", line 394, in fit\n",
      "\u001b[2m\u001b[36m(pid=13875)\u001b[0m     self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "\u001b[2m\u001b[36m(pid=13875)\u001b[0m   File \"/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/xgboost/core.py\", line 506, in inner_f\n",
      "\u001b[2m\u001b[36m(pid=13875)\u001b[0m     return f(**kwargs)\n",
      "\u001b[2m\u001b[36m(pid=13875)\u001b[0m   File \"/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/xgboost/sklearn.py\", line 789, in fit\n",
      "\u001b[2m\u001b[36m(pid=13875)\u001b[0m     self._Booster = train(\n",
      "\u001b[2m\u001b[36m(pid=13875)\u001b[0m   File \"/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/xgboost/training.py\", line 188, in train\n",
      "\u001b[2m\u001b[36m(pid=13875)\u001b[0m     bst = _train_internal(params, dtrain,\n",
      "\u001b[2m\u001b[36m(pid=13875)\u001b[0m   File \"/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/xgboost/training.py\", line 81, in _train_internal\n",
      "\u001b[2m\u001b[36m(pid=13875)\u001b[0m     bst.update(dtrain, i, obj)\n",
      "\u001b[2m\u001b[36m(pid=13875)\u001b[0m   File \"/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/xgboost/core.py\", line 1680, in update\n",
      "\u001b[2m\u001b[36m(pid=13875)\u001b[0m     _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "\u001b[2m\u001b[36m(pid=13875)\u001b[0m   File \"/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/ray/worker.py\", line 422, in sigterm_handler\n",
      "\u001b[2m\u001b[36m(pid=13875)\u001b[0m     sys.exit(1)\n",
      "\u001b[2m\u001b[36m(pid=13875)\u001b[0m SystemExit: 1\n",
      "\u001b[2m\u001b[36m(pid=13875)\u001b[0m [2021-11-20 21:29:57,228 C 13875 105231] core_worker.cc:796:  Check failed: _s.ok() Bad status: IOError: Broken pipe\n",
      "\u001b[2m\u001b[36m(pid=13875)\u001b[0m *** StackTrace Information ***\n",
      "\u001b[2m\u001b[36m(pid=13875)\u001b[0m     ray::GetCallTrace()\n",
      "\u001b[2m\u001b[36m(pid=13875)\u001b[0m     ray::SpdLogMessage::Flush()\n",
      "\u001b[2m\u001b[36m(pid=13875)\u001b[0m     ray::SpdLogMessage::~SpdLogMessage()\n",
      "\u001b[2m\u001b[36m(pid=13875)\u001b[0m     ray::RayLog::~RayLog()\n",
      "\u001b[2m\u001b[36m(pid=13875)\u001b[0m     ray::core::CoreWorker::Exit()\n",
      "\u001b[2m\u001b[36m(pid=13875)\u001b[0m     ray::core::CoreWorker::ExecuteTask()\n",
      "\u001b[2m\u001b[36m(pid=13875)\u001b[0m     std::__1::__function::__func<>::operator()()\n",
      "\u001b[2m\u001b[36m(pid=13875)\u001b[0m     std::__1::__function::__func<>::operator()()\n",
      "\u001b[2m\u001b[36m(pid=13875)\u001b[0m     ray::core::InboundRequest::Accept()\n",
      "\u001b[2m\u001b[36m(pid=13875)\u001b[0m     ray::core::ActorSchedulingQueue::ScheduleRequests()\n",
      "\u001b[2m\u001b[36m(pid=13875)\u001b[0m     ray::core::ActorSchedulingQueue::Add()\n",
      "\u001b[2m\u001b[36m(pid=13875)\u001b[0m     ray::core::CoreWorkerDirectTaskReceiver::HandleTask()\n",
      "\u001b[2m\u001b[36m(pid=13875)\u001b[0m     std::__1::__function::__func<>::operator()()\n",
      "\u001b[2m\u001b[36m(pid=13875)\u001b[0m     boost::asio::detail::completion_handler<>::do_complete()\n",
      "\u001b[2m\u001b[36m(pid=13875)\u001b[0m     boost::asio::detail::scheduler::do_run_one()\n",
      "\u001b[2m\u001b[36m(pid=13875)\u001b[0m     boost::asio::detail::scheduler::run()\n",
      "\u001b[2m\u001b[36m(pid=13875)\u001b[0m     boost::asio::io_context::run()\n",
      "\u001b[2m\u001b[36m(pid=13875)\u001b[0m     ray::core::CoreWorkerProcess::RunTaskExecutionLoop()\n",
      "\u001b[2m\u001b[36m(pid=13875)\u001b[0m     __pyx_pw_3ray_7_raylet_10CoreWorker_9run_task_loop()\n",
      "\u001b[2m\u001b[36m(pid=13875)\u001b[0m     method_vectorcall_NOARGS\n",
      "\u001b[2m\u001b[36m(pid=13875)\u001b[0m     call_function\n",
      "\u001b[2m\u001b[36m(pid=13875)\u001b[0m     _PyEval_EvalFrameDefault\n",
      "\u001b[2m\u001b[36m(pid=13875)\u001b[0m     _PyFunction_Vectorcall\n",
      "\u001b[2m\u001b[36m(pid=13875)\u001b[0m     call_function\n",
      "\u001b[2m\u001b[36m(pid=13875)\u001b[0m     _PyEval_EvalFrameDefault\n",
      "\u001b[2m\u001b[36m(pid=13875)\u001b[0m     _PyEval_EvalCode\n",
      "\u001b[2m\u001b[36m(pid=13875)\u001b[0m     pyrun_file\n",
      "\u001b[2m\u001b[36m(pid=13875)\u001b[0m     pyrun_simple_file\n",
      "\u001b[2m\u001b[36m(pid=13875)\u001b[0m     PyRun_SimpleFileExFlags\n",
      "\u001b[2m\u001b[36m(pid=13875)\u001b[0m     pymain_run_file\n",
      "\u001b[2m\u001b[36m(pid=13875)\u001b[0m     pymain_run_python\n",
      "\u001b[2m\u001b[36m(pid=13875)\u001b[0m     Py_RunMain\n",
      "\u001b[2m\u001b[36m(pid=13875)\u001b[0m     pymain_main\n",
      "\u001b[2m\u001b[36m(pid=13875)\u001b[0m     main\n",
      "\u001b[2m\u001b[36m(pid=13875)\u001b[0m     start\n",
      "\u001b[2m\u001b[36m(pid=13875)\u001b[0m     0x0\n",
      "\u001b[2m\u001b[36m(pid=13875)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trials did not complete: [_Trainable_f70e6_00000, _Trainable_f70e6_00001, _Trainable_f70e6_00002, _Trainable_f70e6_00003]\n",
      "Experiment has been interrupted, but the most recent state was saved. You can continue running this experiment by passing `resume=True` to `tune.run()`\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/p3/zmg8jfwx0hb9gwzs0w69d7f0rgyjx2/T/ipykernel_13712/3320280270.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Now do tune grid search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m tune_search = tmlt.do_tune_grid_search(param_grid=param_grid,\n\u001b[0m\u001b[1;32m     17\u001b[0m                                        \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                                        \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'neg_mean_absolute_error'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/GitHub/tabular_ml_toolkit/tabular_ml_toolkit/tmlt.py\u001b[0m in \u001b[0;36mdo_tune_grid_search\u001b[0;34m(self, param_grid, scoring, mode, cv, early_stopping, time_budget_s, name, use_gpu, stopper, max_iters, n_jobs)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;31m# now call fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m         \u001b[0mtune_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdfl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdfl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtune_search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/tune_sklearn/tune_basesearch.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, tune_params, **fit_params)\u001b[0m\n\u001b[1;32m    663\u001b[0m             \u001b[0mray_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"local_mode\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mray_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mray_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 665\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtune_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/tune_sklearn/tune_basesearch.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, groups, tune_params, **fit_params)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0manalysis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tune_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresources_per_trial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtune_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv_results_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_format_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manalysis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m         \u001b[0mmetric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metric_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/tune_sklearn/tune_basesearch.py\u001b[0m in \u001b[0;36m_format_results\u001b[0;34m(self, n_splits, out)\u001b[0m\n\u001b[1;32m    877\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 879\u001b[0;31m             _store(\n\u001b[0m\u001b[1;32m    880\u001b[0m                 \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m                 \u001b[0;34m\"test_%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/tune_sklearn/tune_basesearch.py\u001b[0m in \u001b[0;36m_store\u001b[0;34m(results, key_name, array, n_splits, n_candidates, weights, splits, rank)\u001b[0m\n\u001b[1;32m    862\u001b[0m                                             key_name)] = array[:, split_i]\n\u001b[1;32m    863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 864\u001b[0;31m             \u001b[0marray_means\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    865\u001b[0m             \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mean_%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mkey_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_means\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m             \u001b[0;31m# Weighted std is not directly available in numpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36maverage\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36maverage\u001b[0;34m(a, axis, weights, returned)\u001b[0m\n\u001b[1;32m    379\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0mavg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m         \u001b[0mscl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mavg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0mwgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "# let's do tune grid search for Data PreProcessing hyperparams tuning\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "# let's tune data preprocessing and model hyperparams\n",
    "param_grid = {\n",
    "    \"preprocessor__num_cols__scaler\": [StandardScaler(), MinMaxScaler()],\n",
    "    \"preprocessor__cat_cols__imputer\": [SimpleImputer(strategy='constant'),\n",
    "                                                 SimpleImputer(strategy='most_frequent')]\n",
    "}\n",
    "\n",
    "start = time.time()\n",
    "# Now do tune grid search\n",
    "tune_search = tmlt.do_tune_grid_search(param_grid=param_grid,\n",
    "                                       cv=5,\n",
    "                                       scoring='neg_mean_absolute_error',\n",
    "                                      early_stopping=False,\n",
    "                                      time_budget_s=360)\n",
    "end = time.time()\n",
    "print(\"Grid Search Time:\", end - start)\n",
    "\n",
    "print(\"Best params:\")\n",
    "print(tune_search.best_params_)\n",
    "\n",
    "print(f\"Internal CV Metrics score: {-1*(tune_search.best_score_):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to customize data and preprocessing steps you can do so by using `DataFrameLoader` and `PreProessor` classes. Please Check other Tutorials and detail documentations for these classes for more options. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Amazing our 5 Fold CV MAE has even reduced further within few minutes of Tuen Grid Search HyperParams tunning!**\n",
    "\n",
    "If we can continue doing hyperparmas tunning, may be we can even do better, You can also try early_stopping, take that as challenge!\n",
    "\n",
    "###### Let's use our newly found params for a 10 k-fold training and test predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Update PreProcessor on tmlt with best params found from tune grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_params = tmlt.get_preprocessor_best_params(tune_search)\n",
    "\n",
    "# Update pipeline with updated preprocessor\n",
    "tmlt.update_preprocessor(**pp_params)\n",
    "tmlt.spl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Update Model on tmlt with best params found from tune grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-fold training\n",
    "xgb_model_metrics_score, xgb_model_test_preds = tmlt.do_kfold_training(n_splits=10,\n",
    "                                                                          metrics=mean_absolute_error,\n",
    "                                                                          random_state=42)\n",
    "# Check test dataset prediction shape\n",
    "print(xgb_model_test_preds.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Yay, we have much better MAE with 10 K-Fold**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nbdev_env]",
   "language": "python",
   "name": "conda-env-nbdev_env-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
