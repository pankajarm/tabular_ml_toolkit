{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started Kaggle TPS Challenge with Tabular ML Toolkit\n",
    "\n",
    "> A Tutorial to showcase usage of tabular_ml_toolkit (tmlt) library on Kaggle TPS Challenge Nov 2021.\n",
    "\n",
    "> tabular_ml_toolkit is a helper library to jumpstart your machine learning project based on Tabular or Structured data.\n",
    "\n",
    "> It comes with model parallelism and cutting edge hyperparameter search techniques.\n",
    "\n",
    "> Under the hood TMLT uses optuna, xgboost and scikit-learn pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pip install -U tabular_ml_toolkit`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to Best Use tabular_ml_toolkit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start with your favorite model and then just simply create **tmlt** with one API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Here we are using XGBClassifier, on  [Kaggle TPS Challenge (Nov 2021) data](https://www.kaggle.com/c/tabular-playground-series-nov-2021/data)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabular_ml_toolkit.tmlt import *\n",
    "from xgboost import XGBClassifier\n",
    "import numpy as np\n",
    "import gc\n",
    "import pandas as pd\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, accuracy_score, log_loss, balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset file names and Paths\n",
    "DIRECTORY_PATH = \"/home/pankaj/kaggle_datasets/tpc_dec_2021/\"\n",
    "TRAIN_FILE = \"train.csv\"\n",
    "TEST_FILE = \"test.csv\"\n",
    "SAMPLE_SUB_FILE = \"sample_submission.csv\"\n",
    "OUTPUT_PATH = \"kaggle_tps_dec_output/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Just point tmlt in the direction of your data\n",
    "\n",
    "#### Let it know what are idx and target columns in your tabular data\n",
    "\n",
    "#### what kind of problem type you are trying to resolve?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-19 20:02:52,232 INFO 8 cores found, model and data parallel processing should worked!\n",
      "2021-12-19 20:03:08,765 INFO DataFrame Memory usage decreased to 274.66 Mb (83.9% reduction)\n",
      "2021-12-19 20:03:11,789 INFO DataFrame Memory usage decreased to 67.71 Mb (83.9% reduction)\n",
      "2021-12-19 20:03:12,090 INFO The least class label is :5 and value count is: 1\n",
      "2021-12-19 20:03:12,094 INFO The Original X shape is: (4000000, 55)\n",
      "2021-12-19 20:03:12,208 INFO The X shape after least class duplicates appends is: (4000021, 55)\n",
      "2021-12-19 20:03:13,889 INFO PreProcessing will include target(s) encoding!\n",
      "2021-12-19 20:03:14,000 INFO categorical columns are None, Preprocessing will done accordingly!\n"
     ]
    }
   ],
   "source": [
    "# create tmlt\n",
    "tmlt = TMLT().prepare_data(\n",
    "    train_file_path= DIRECTORY_PATH + TRAIN_FILE,\n",
    "    test_file_path= DIRECTORY_PATH + TEST_FILE,\n",
    "    #make sure to use right index and target columns\n",
    "    idx_col=\"Id\",\n",
    "    target=\"Cover_Type\",\n",
    "    random_state=42,\n",
    "    problem_type=\"multi_class_classification\",\n",
    "#     nrows=4000\n",
    ")\n",
    "\n",
    "\n",
    "# tmlt supports only below task type:\n",
    "    # \"binary_classification\"\n",
    "    # \"multi_label_classification\"\n",
    "    # \"multi_class_classification\"\n",
    "    # \"regression\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(4000021, 54)\n",
      "<class 'numpy.ndarray'>\n",
      "(4000021,)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(1000000, 54)\n"
     ]
    }
   ],
   "source": [
    "print(type(tmlt.dfl.X))\n",
    "print(tmlt.dfl.X.shape)\n",
    "print(type(tmlt.dfl.y))\n",
    "print(tmlt.dfl.y.shape)\n",
    "print(type(tmlt.dfl.X_test))\n",
    "print(tmlt.dfl.X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Horizontal_Distance_To_Hydrology</th>\n",
       "      <th>Vertical_Distance_To_Hydrology</th>\n",
       "      <th>Horizontal_Distance_To_Roadways</th>\n",
       "      <th>Hillshade_9am</th>\n",
       "      <th>Hillshade_Noon</th>\n",
       "      <th>Hillshade_3pm</th>\n",
       "      <th>Horizontal_Distance_To_Fire_Points</th>\n",
       "      <th>...</th>\n",
       "      <th>Soil_Type31</th>\n",
       "      <th>Soil_Type32</th>\n",
       "      <th>Soil_Type33</th>\n",
       "      <th>Soil_Type34</th>\n",
       "      <th>Soil_Type35</th>\n",
       "      <th>Soil_Type36</th>\n",
       "      <th>Soil_Type37</th>\n",
       "      <th>Soil_Type38</th>\n",
       "      <th>Soil_Type39</th>\n",
       "      <th>Soil_Type40</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3189</td>\n",
       "      <td>40</td>\n",
       "      <td>8</td>\n",
       "      <td>30</td>\n",
       "      <td>13</td>\n",
       "      <td>3270</td>\n",
       "      <td>206</td>\n",
       "      <td>234</td>\n",
       "      <td>193</td>\n",
       "      <td>4873</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3026</td>\n",
       "      <td>182</td>\n",
       "      <td>5</td>\n",
       "      <td>280</td>\n",
       "      <td>29</td>\n",
       "      <td>3270</td>\n",
       "      <td>233</td>\n",
       "      <td>240</td>\n",
       "      <td>106</td>\n",
       "      <td>5423</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3106</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>351</td>\n",
       "      <td>37</td>\n",
       "      <td>2914</td>\n",
       "      <td>208</td>\n",
       "      <td>234</td>\n",
       "      <td>137</td>\n",
       "      <td>5269</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3022</td>\n",
       "      <td>276</td>\n",
       "      <td>13</td>\n",
       "      <td>192</td>\n",
       "      <td>16</td>\n",
       "      <td>3034</td>\n",
       "      <td>207</td>\n",
       "      <td>238</td>\n",
       "      <td>156</td>\n",
       "      <td>2866</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2906</td>\n",
       "      <td>186</td>\n",
       "      <td>13</td>\n",
       "      <td>266</td>\n",
       "      <td>22</td>\n",
       "      <td>2916</td>\n",
       "      <td>231</td>\n",
       "      <td>231</td>\n",
       "      <td>154</td>\n",
       "      <td>2642</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4000016</th>\n",
       "      <td>2953</td>\n",
       "      <td>114</td>\n",
       "      <td>39</td>\n",
       "      <td>97</td>\n",
       "      <td>111</td>\n",
       "      <td>981</td>\n",
       "      <td>181</td>\n",
       "      <td>209</td>\n",
       "      <td>184</td>\n",
       "      <td>7633</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4000017</th>\n",
       "      <td>2953</td>\n",
       "      <td>114</td>\n",
       "      <td>39</td>\n",
       "      <td>97</td>\n",
       "      <td>111</td>\n",
       "      <td>981</td>\n",
       "      <td>181</td>\n",
       "      <td>209</td>\n",
       "      <td>184</td>\n",
       "      <td>7633</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4000018</th>\n",
       "      <td>2953</td>\n",
       "      <td>114</td>\n",
       "      <td>39</td>\n",
       "      <td>97</td>\n",
       "      <td>111</td>\n",
       "      <td>981</td>\n",
       "      <td>181</td>\n",
       "      <td>209</td>\n",
       "      <td>184</td>\n",
       "      <td>7633</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4000019</th>\n",
       "      <td>2953</td>\n",
       "      <td>114</td>\n",
       "      <td>39</td>\n",
       "      <td>97</td>\n",
       "      <td>111</td>\n",
       "      <td>981</td>\n",
       "      <td>181</td>\n",
       "      <td>209</td>\n",
       "      <td>184</td>\n",
       "      <td>7633</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4000020</th>\n",
       "      <td>2953</td>\n",
       "      <td>114</td>\n",
       "      <td>39</td>\n",
       "      <td>97</td>\n",
       "      <td>111</td>\n",
       "      <td>981</td>\n",
       "      <td>181</td>\n",
       "      <td>209</td>\n",
       "      <td>184</td>\n",
       "      <td>7633</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000021 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Elevation  Aspect  Slope  Horizontal_Distance_To_Hydrology  \\\n",
       "0             3189      40      8                                30   \n",
       "1             3026     182      5                               280   \n",
       "2             3106      13      7                               351   \n",
       "3             3022     276     13                               192   \n",
       "4             2906     186     13                               266   \n",
       "...            ...     ...    ...                               ...   \n",
       "4000016       2953     114     39                                97   \n",
       "4000017       2953     114     39                                97   \n",
       "4000018       2953     114     39                                97   \n",
       "4000019       2953     114     39                                97   \n",
       "4000020       2953     114     39                                97   \n",
       "\n",
       "         Vertical_Distance_To_Hydrology  Horizontal_Distance_To_Roadways  \\\n",
       "0                                    13                             3270   \n",
       "1                                    29                             3270   \n",
       "2                                    37                             2914   \n",
       "3                                    16                             3034   \n",
       "4                                    22                             2916   \n",
       "...                                 ...                              ...   \n",
       "4000016                             111                              981   \n",
       "4000017                             111                              981   \n",
       "4000018                             111                              981   \n",
       "4000019                             111                              981   \n",
       "4000020                             111                              981   \n",
       "\n",
       "         Hillshade_9am  Hillshade_Noon  Hillshade_3pm  \\\n",
       "0                  206             234            193   \n",
       "1                  233             240            106   \n",
       "2                  208             234            137   \n",
       "3                  207             238            156   \n",
       "4                  231             231            154   \n",
       "...                ...             ...            ...   \n",
       "4000016            181             209            184   \n",
       "4000017            181             209            184   \n",
       "4000018            181             209            184   \n",
       "4000019            181             209            184   \n",
       "4000020            181             209            184   \n",
       "\n",
       "         Horizontal_Distance_To_Fire_Points  ...  Soil_Type31  Soil_Type32  \\\n",
       "0                                      4873  ...            0            0   \n",
       "1                                      5423  ...            0            0   \n",
       "2                                      5269  ...            0            0   \n",
       "3                                      2866  ...            0            0   \n",
       "4                                      2642  ...            0            0   \n",
       "...                                     ...  ...          ...          ...   \n",
       "4000016                                7633  ...            0            0   \n",
       "4000017                                7633  ...            0            0   \n",
       "4000018                                7633  ...            0            0   \n",
       "4000019                                7633  ...            0            0   \n",
       "4000020                                7633  ...            0            0   \n",
       "\n",
       "         Soil_Type33  Soil_Type34  Soil_Type35  Soil_Type36  Soil_Type37  \\\n",
       "0                  0            0            0            0            0   \n",
       "1                  0            0            0            0            0   \n",
       "2                  0            0            0            0            0   \n",
       "3                  0            0            0            0            0   \n",
       "4                  0            0            0            0            0   \n",
       "...              ...          ...          ...          ...          ...   \n",
       "4000016            0            0            0            0            0   \n",
       "4000017            0            0            0            0            0   \n",
       "4000018            0            0            0            0            0   \n",
       "4000019            0            0            0            0            0   \n",
       "4000020            0            0            0            0            0   \n",
       "\n",
       "         Soil_Type38  Soil_Type39  Soil_Type40  \n",
       "0                  0            0            0  \n",
       "1                  0            0            0  \n",
       "2                  0            0            0  \n",
       "3                  0            0            0  \n",
       "4                  0            0            0  \n",
       "...              ...          ...          ...  \n",
       "4000016            0            0            0  \n",
       "4000017            0            0            0  \n",
       "4000018            0            0            0  \n",
       "4000019            0            0            0  \n",
       "4000020            0            0            0  \n",
       "\n",
       "[4000021 rows x 54 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmlt.dfl.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 2262087, 0: 1468136, 2: 195712, 6: 62261, 5: 11426, 3: 377, 4: 22}\n",
      "CPU times: user 13 ms, sys: 226 µs, total: 13.2 ms\n",
      "Wall time: 13.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(dict(pd.Series(tmlt.dfl.y).value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# print(Counter(tmlt.dfl.y).items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PreProcess X, y and X_test and apply SMOTEENN combine technique (oversample+undersample) to resample imbalance classses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000021, 54)\n",
      "<class 'numpy.ndarray'>\n",
      "(4000021,)\n",
      "<class 'numpy.ndarray'>\n",
      "(1000000, 54)\n",
      "<class 'numpy.ndarray'>\n",
      "CPU times: user 3.34 s, sys: 656 ms, total: 3.99 s\n",
      "Wall time: 4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_np, y_np, X_test_np = tmlt.pp_fit_transform(tmlt.dfl.X, tmlt.dfl.y, tmlt.dfl.X_test)\n",
    "print(X_np.shape)\n",
    "print(type(X_np))\n",
    "print(y_np.shape)\n",
    "print(type(y_np))\n",
    "print(X_test_np.shape)\n",
    "print(type(X_test_np))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 2262087, 0: 1468136, 2: 195712, 6: 62261, 5: 11426, 3: 377, 4: 22}\n"
     ]
    }
   ],
   "source": [
    "print(dict(pd.Series(y_np).value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### PreProcess train, valid dataset before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.87 s, sys: 75.7 ms, total: 1.94 s\n",
      "Wall time: 1.94 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# create train, valid split to evaulate model on valid dataset\n",
    "X_train_np, X_valid_np,  y_train_np, y_valid_np =  tmlt.dfl.create_train_valid(X_np, y_np, valid_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3200016, 54)\n",
      "<class 'numpy.ndarray'>\n",
      "(3200016,)\n",
      "<class 'numpy.ndarray'>\n",
      "(800005, 54)\n",
      "<class 'numpy.ndarray'>\n",
      "(800005,)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(X_train_np.shape)\n",
    "print(type(X_train_np))\n",
    "print(y_train_np.shape)\n",
    "print(type(y_train_np))\n",
    "print(X_valid_np.shape)\n",
    "print(type(X_valid_np))\n",
    "print(y_valid_np.shape)\n",
    "print(type(y_valid_np))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 1809706, 0: 1174364, 2: 156645, 6: 49832, 5: 9146, 3: 305, 4: 18}\n",
      "{1: 452381, 0: 293772, 2: 39067, 6: 12429, 5: 2280, 3: 72, 4: 4}\n"
     ]
    }
   ],
   "source": [
    "# check for class values see if both train and valid have same class labels\n",
    "print(dict(pd.Series(y_train_np).value_counts()))\n",
    "print(dict(pd.Series(y_valid_np).value_counts()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a base xgb classifier model with your best guess params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb_params = {\n",
    "#     'use_label_encoder': False,\n",
    "#     'learning_rate': 0.22460180743878044,\n",
    "#     'n_estimators': 150,\n",
    "#     'reg_lambda': 3.144893773482e-05,\n",
    "#     'reg_alpha': 0.00023758525471934383,\n",
    "#     'subsample': 0.2640308356915845,\n",
    "#     'colsample_bytree': 0.7501402977241696,\n",
    "#     'max_depth': 7,\n",
    "#     'tree_method': 'gpu_hist',\n",
    "#     'gpu_id': 0,\n",
    "#     'predictor': 'gpu_predictor',\n",
    "#     'early_stopping_rounds': 384\n",
    "# }\n",
    "# xgb_model = XGBClassifier(**xgb_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # Now do model training\n",
    "# xgb_model.fit(X_train_np, y_train_np,\n",
    "#               verbose=True,\n",
    "#               #detect & avoid overfitting\n",
    "#               eval_set=[(X_valid_np, y_valid_np)],\n",
    "#               eval_metric=\"mlogloss\",\n",
    "#               early_stopping_rounds=300\n",
    "#              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# #predict\n",
    "# preds = xgb_model.predict(X_valid_np)\n",
    "# preds_probs = xgb_model.predict_proba(X_valid_np)\n",
    "\n",
    "# # Metrics\n",
    "# auc = roc_auc_score(y_valid_np, preds_probs, multi_class='ovr')\n",
    "# acc = accuracy_score(y_valid_np, preds)\n",
    "# lg_loss = log_loss(y_valid_np, preds_probs)\n",
    "# imbalance classes metrics\n",
    "# bas = balanced_accuracy_score(y_valid_np, preds)\n",
    "\n",
    "# print(f\"AUC is : {auc} , log loss is: {lg_loss}, Accuracy is : {acc} While Balance Accuracy Score is: {bas}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Balance Accuracy Score is: 0.7567083002652698"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### let's train using imbalance BalanceBaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from imblearn.ensemble import BalancedBaggingClassifier\n",
    "# from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "# from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# #model\n",
    "# # bbc_model = BalancedBaggingClassifier(base_estimator=DecisionTreeClassifier(), sampling_strategy='auto',\n",
    "# #                                 replacement=False, random_state=42)\n",
    "\n",
    "# # model = BalancedBaggingClassifier(base_estimator=DecisionTreeClassifier(),\n",
    "# #                                       #sampling_strategy='auto', replacement=False,\n",
    "# #                                       random_state=42)\n",
    "\n",
    "# model = BalancedRandomForestClassifier(n_estimators=1000, random_state=42)\n",
    "\n",
    "# # training\n",
    "# model.fit(X_train_np, y_train_np)\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# #predict\n",
    "# preds = model.predict(X_valid_np)\n",
    "# preds_probs = model.predict_proba(X_valid_np)\n",
    "\n",
    "# # Metrics\n",
    "# auc = roc_auc_score(y_valid_np, preds_probs, multi_class='ovr')\n",
    "# acc = accuracy_score(y_valid_np, preds)\n",
    "# lg_loss = log_loss(y_valid_np, preds_probs)\n",
    "# #imbalance classes metrics\n",
    "# bas = balanced_accuracy_score(y_valid_np, preds)\n",
    "\n",
    "# print(f\"AUC is : {auc} , log loss is: {lg_loss}, Accuracy is : {acc} While Balance Accuracy Score is: {bas}\")\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For n_estimators=100\n",
    "While Balance Accuracy Score is: 0.8467083002652698"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # Get Test Predictions\n",
    "# model_test_preds = model.predict(X_test_np)\n",
    "# print(model_test_preds.shape)\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Meta Ensemble Models Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Base Model 1: linear SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# # OOF training and prediction on both train and test dataset by a given model\n",
    "# #choose model\n",
    "# linear_oof_model = LinearSVC(tol=1e-7, penalty='l2', dual=False, max_iter=2000, random_state=42)\n",
    "\n",
    "# #fit and predict\n",
    "# linear_oof_model_preds, linear_oof_model_test_preds = tmlt.do_oof_kfold_train_preds(n_splits=5,\n",
    "#                                                                                     model=linear_oof_model,\n",
    "#                                                                                     X = X_np,\n",
    "#                                                                                     y = y_np,\n",
    "#                                                                                     X_test = X_test_np)\n",
    "\n",
    "# if linear_oof_model_preds is not None:\n",
    "#     print(linear_oof_model_preds.shape)\n",
    "\n",
    "# if linear_oof_model_test_preds is not None:    \n",
    "#     print(linear_oof_model_test_preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Base Model 2: Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# # OOF training and prediction on both train and test dataset by a given model\n",
    "\n",
    "# #choose model\n",
    "# log_oof_model = LogisticRegression(multi_class='multinomial', solver='lbfg', random_state=42)\n",
    "\n",
    "# #fit and predict\n",
    "# log_oof_model_preds, log_oof_model_test_preds = tmlt.do_oof_kfold_train_preds(n_splits=5,\n",
    "#                                                                                     model=log_oof_model,\n",
    "#                                                                                     X = X_np,\n",
    "#                                                                                     y = y_np,\n",
    "#                                                                                     X_test = X_test_np)\n",
    "# if log_oof_model_preds is not None:\n",
    "#     print(log_oof_model_preds.shape)\n",
    "\n",
    "# if log_oof_model_test_preds is not None:    \n",
    "#     print(log_oof_model_test_preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Base Model 3: SKLearn MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# # OOF training and prediction on both train and test dataset by a given model\n",
    "\n",
    "# #choose model\n",
    "# mlp_oof_model = MLPClassifier(max_iter=1000, early_stopping=True)\n",
    "\n",
    "# #update the model on sklearn pipeline\n",
    "# # tmlt = tmlt.update_model(mlp_oof_model)\n",
    "\n",
    "# # # lets see updated sklearn pipeline with new model\n",
    "# # tmlt.spl\n",
    "\n",
    "# #fit and predict\n",
    "# mlp_oof_model_preds, mlp_oof_model_test_preds = tmlt.do_oof_kfold_train_preds(n_splits=5,\n",
    "#                                                                                     model=mlp_oof_model,\n",
    "#                                                                                     X = X_np,\n",
    "#                                                                                     y = y_np,\n",
    "#                                                                                     X_test = X_test_np)\n",
    "# if mlp_oof_model_preds is not None:\n",
    "#     print(mlp_oof_model_preds.shape)\n",
    "\n",
    "# if mlp_oof_model_test_preds is not None:    \n",
    "#     print(mlp_oof_model_test_preds.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Base Model 4: TabNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_tabnet.tab_model import TabNetClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-19 20:28:46,445 INFO Training Started!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.25043 | val_0_logloss: 0.48621 |  0:00:20s\n",
      "epoch 1  | loss: 0.31447 | val_0_logloss: 0.27513 |  0:00:40s\n",
      "epoch 2  | loss: 0.24494 | val_0_logloss: 0.22531 |  0:01:01s\n",
      "Stop training because you reached max_epochs = 3 with best_epoch = 2 and best_val_0_logloss = 0.22531\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-19 20:30:07,351 INFO Training Finished!\n",
      "2021-12-19 20:30:12,909 INFO fold: 1 OOF Model Metrics: 0.22530653664576633!\n",
      "2021-12-19 20:30:17,018 INFO Training Started!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.22735 | val_0_logloss: 0.20195 |  0:00:20s\n",
      "epoch 1  | loss: 0.18652 | val_0_logloss: 0.17483 |  0:00:40s\n",
      "epoch 2  | loss: 0.16905 | val_0_logloss: 0.16774 |  0:01:00s\n",
      "Stop training because you reached max_epochs = 3 with best_epoch = 2 and best_val_0_logloss = 0.16774\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-19 20:31:34,942 INFO Training Finished!\n",
      "2021-12-19 20:31:40,538 INFO fold: 2 OOF Model Metrics: 0.16773542057211552!\n",
      "2021-12-19 20:31:44,674 INFO Training Started!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.17882 | val_0_logloss: 0.16435 |  0:00:20s\n",
      "epoch 1  | loss: 0.15725 | val_0_logloss: 0.15378 |  0:00:40s\n",
      "epoch 2  | loss: 0.14599 | val_0_logloss: 0.14168 |  0:01:01s\n",
      "Stop training because you reached max_epochs = 3 with best_epoch = 2 and best_val_0_logloss = 0.14168\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-19 20:33:03,108 INFO Training Finished!\n",
      "2021-12-19 20:33:08,735 INFO fold: 3 OOF Model Metrics: 0.14167650704649876!\n",
      "2021-12-19 20:33:12,871 INFO Training Started!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.14903 | val_0_logloss: 0.14054 |  0:00:20s\n",
      "epoch 1  | loss: 0.13449 | val_0_logloss: 0.13128 |  0:00:40s\n",
      "epoch 2  | loss: 0.12812 | val_0_logloss: 0.12455 |  0:01:01s\n",
      "Stop training because you reached max_epochs = 3 with best_epoch = 2 and best_val_0_logloss = 0.12455\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-19 20:34:31,055 INFO Training Finished!\n",
      "2021-12-19 20:34:36,694 INFO fold: 4 OOF Model Metrics: 0.12454858805122924!\n",
      "2021-12-19 20:34:40,854 INFO Training Started!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.14    | val_0_logloss: 0.12935 |  0:00:20s\n",
      "epoch 1  | loss: 0.12309 | val_0_logloss: 0.12216 |  0:00:40s\n",
      "epoch 2  | loss: 0.11894 | val_0_logloss: 0.12147 |  0:01:00s\n",
      "Stop training because you reached max_epochs = 3 with best_epoch = 2 and best_val_0_logloss = 0.12147\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-19 20:35:58,632 INFO Training Finished!\n",
      "2021-12-19 20:36:04,209 INFO fold: 5 OOF Model Metrics: 0.12146745566406761!\n",
      "2021-12-19 20:36:07,736 INFO Mean OOF Model Metrics: 0.15614690159593547!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000021,)\n",
      "(1000000,)\n",
      "CPU times: user 8min 14s, sys: 9.11 s, total: 8min 23s\n",
      "Wall time: 7min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# OOF training and prediction on both train and test dataset by a given model\n",
    "\n",
    "#TOD0: Add tabnet_params and pass through do_oof_kfold_train_preds, keep it optional for non tabnet models\n",
    "# GOTO tmlt update method with tabnet_params\n",
    "tabnet_params = {\n",
    "    'max_epochs': 10,\n",
    "    'patience': 2,\n",
    "    'batch_size': 4096*8*tmlt.IDEAL_CPU_CORES,\n",
    "    'virtual_batch_size' : 512*8*tmlt.IDEAL_CPU_CORES\n",
    "}\n",
    "\n",
    "#choose model\n",
    "tabnet_oof_model = TabNetClassifier(optimizer_params=dict(lr=0.02), verbose=1)\n",
    "\n",
    "#fit and predict\n",
    "tabnet_oof_model_preds, tabnet_oof_model_test_preds = tmlt.do_oof_kfold_train_preds(n_splits=5,\n",
    "                                                                                    model=tabnet_oof_model,\n",
    "                                                                                    X = X_np,\n",
    "                                                                                    y = y_np,\n",
    "                                                                                    X_test = X_test_np,\n",
    "                                                                                    tabnet_params=tabnet_params)\n",
    "gc.collect()\n",
    "\n",
    "if tabnet_oof_model_preds is not None:\n",
    "    print(tabnet_oof_model_preds.shape)\n",
    "\n",
    "if tabnet_oof_model_test_preds is not None:\n",
    "    print(tabnet_oof_model_test_preds.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now add back based models predictions to X and X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # add based model oof predictions back to X and X_test before Meta model training\n",
    "# tmlt.dfl.X[\"linear_preds\"] = linear_oof_model_preds\n",
    "# tmlt.dfl.X_test[\"linear_preds\"] = linear_oof_model_test_preds\n",
    "\n",
    "# print(tmlt.dfl.X.shape)\n",
    "# print(tmlt.dfl.X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # add based model oof predictions back to X and X_test before Meta model training\n",
    "# tmlt.dfl.X[\"log_reg_preds\"] = log_oof_model_preds\n",
    "# tmlt.dfl.X_test[\"log_reg_preds\"] = log_oof_model_test_preds\n",
    "\n",
    "# print(tmlt.dfl.X.shape)\n",
    "# print(tmlt.dfl.X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # add based model oof predictions back to X and X_test before Meta model training\n",
    "# tmlt.dfl.X[\"mlp_preds\"] = mlp_oof_model_preds\n",
    "# tmlt.dfl.X_test[\"mlp_preds\"] = mlp_oof_model_test_preds\n",
    "\n",
    "# print(tmlt.dfl.X.shape)\n",
    "# print(tmlt.dfl.X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000021, 55)\n",
      "(1000000, 55)\n"
     ]
    }
   ],
   "source": [
    "# add based model oof predictions back to X and X_test before Meta model training\n",
    "tmlt.dfl.X[\"tabnet_preds\"] = tabnet_oof_model_preds\n",
    "tmlt.dfl.X_test[\"tabnet_preds\"] = tabnet_oof_model_test_preds\n",
    "\n",
    "print(tmlt.dfl.X.shape)\n",
    "print(tmlt.dfl.X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### now just update the tmlt with this new X and X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-19 20:36:19,655 INFO categorical columns are None, Preprocessing will done accordingly!\n"
     ]
    }
   ],
   "source": [
    "tmlt = tmlt.update_dfl(X=tmlt.dfl.X, y=tmlt.dfl.y, X_test=tmlt.dfl.X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For META Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now PreProcess X_train, X_valid\n",
    "\n",
    "NOTE: Preprocessing gives back numpy arrays for pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000021, 55)\n",
      "<class 'numpy.ndarray'>\n",
      "(4000021,)\n",
      "<class 'numpy.ndarray'>\n",
      "(1000000, 55)\n",
      "<class 'numpy.ndarray'>\n",
      "CPU times: user 21.9 s, sys: 1.68 s, total: 23.6 s\n",
      "Wall time: 23.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_np, y_np, X_test_np = tmlt.pp_fit_transform(tmlt.dfl.X, tmlt.dfl.y, tmlt.dfl.X_test)\n",
    "\n",
    "print(X_np.shape)\n",
    "print(type(X_np))\n",
    "print(y_np.shape)\n",
    "print(type(y_np))\n",
    "print(X_test_np.shape)\n",
    "print(type(X_test_np))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### create train valid dataframes for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3200016, 55)\n",
      "<class 'numpy.ndarray'>\n",
      "(3200016,)\n",
      "<class 'numpy.ndarray'>\n",
      "(800005, 55)\n",
      "<class 'numpy.ndarray'>\n",
      "(800005,)\n",
      "<class 'numpy.ndarray'>\n",
      "CPU times: user 1.89 s, sys: 124 ms, total: 2.01 s\n",
      "Wall time: 2.01 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# create train, valid split to evaulate model on valid dataset\n",
    "X_train_np, X_valid_np,  y_train_np, y_valid_np =  tmlt.dfl.create_train_valid(X_np, y_np, valid_size=0.2)\n",
    "\n",
    "print(X_train_np.shape)\n",
    "print(type(X_train_np))\n",
    "print(y_train_np.shape)\n",
    "print(type(y_train_np))\n",
    "print(X_valid_np.shape)\n",
    "print(type(X_valid_np))\n",
    "print(y_valid_np.shape)\n",
    "print(type(y_valid_np))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "    'use_label_encoder': False,\n",
    "    'learning_rate': 0.22460180743878044,\n",
    "    'n_estimators': 1500,\n",
    "    'reg_lambda': 3.144893773482e-05,\n",
    "    'reg_alpha': 0.00023758525471934383,\n",
    "    'subsample': 0.2640308356915845,\n",
    "    'colsample_bytree': 0.7501402977241696,\n",
    "    'max_depth': 7,\n",
    "    'tree_method': 'gpu_hist',\n",
    "    'gpu_id': 0,\n",
    "    'predictor': 'gpu_predictor',\n",
    "    'early_stopping_rounds': 384\n",
    "}\n",
    "xgb_model = XGBClassifier(**xgb_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:37:35] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "AUC is : 0.9984581458222804 while Accuracy is : 0.9606552459047131 \n",
      "CPU times: user 1min 50s, sys: 829 ms, total: 1min 51s\n",
      "Wall time: 1min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Now do model training\n",
    "xgb_model.fit(X_train_np, y_train_np,\n",
    "              verbose=False,\n",
    "              #detect & avoid overfitting\n",
    "              eval_set=[(X_valid_np, y_valid_np)],\n",
    "              eval_metric=\"mlogloss\",\n",
    "              early_stopping_rounds=300\n",
    "             )\n",
    "\n",
    "#predict\n",
    "preds = xgb_model.predict(X_valid_np)\n",
    "preds_probs = xgb_model.predict_proba(X_valid_np)\n",
    "\n",
    "# Metrics\n",
    "auc = roc_auc_score(y_valid_np, preds_probs, multi_class='ovr')\n",
    "acc = accuracy_score(y_valid_np, preds)\n",
    "\n",
    "print(f\"AUC is : {auc} while Accuracy is : {acc} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000000,)\n",
      "CPU times: user 2.27 s, sys: 83.3 ms, total: 2.36 s\n",
      "Wall time: 989 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Get Test Predictions\n",
    "single_xgb_model_test_preds = xgb_model.predict(X_test_np)\n",
    "print(single_xgb_model_test_preds.shape)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WOW!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For Meta Model, Let's do Optuna based HyperParameter search to get best params for fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # **Just make sure to supply an output directory path so hyperparameter search is saved**\n",
    "# study = tmlt.do_xgb_optuna_optimization(X_train_np, y_train, X_valid_np, y_valid, optuna_db_path=OUTPUT_PATH, opt_timeout=360)\n",
    "# print(study.best_trial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### now update the meta model with best params from study and then update the sklearn pipeline with this new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb_params.update(study.best_trial.params)\n",
    "# xgb_params.update({'n_estimators': 1500})\n",
    "# print(\"xgb_params\", xgb_params)\n",
    "# updated_xgb_model = XGBClassifier(**xgb_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's Use K-Fold Training with best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-19 20:41:15,228 INFO Training Started!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:41:16] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-19 20:45:08,161 INFO Training Finished!\n",
      "2021-12-19 20:45:08,161 INFO Predicting Val Probablities!\n",
      "2021-12-19 20:45:09,887 INFO Predicting Val Score!\n",
      "2021-12-19 20:45:11,630 INFO fold: 1 accuracy_score : 0.9565015218654883\n",
      "2021-12-19 20:45:11,630 INFO Predicting Test Scores!\n",
      "2021-12-19 20:45:14,436 INFO Training Started!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:45:15] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-19 20:49:05,940 INFO Training Finished!\n",
      "2021-12-19 20:49:05,941 INFO Predicting Val Probablities!\n",
      "2021-12-19 20:49:07,656 INFO Predicting Val Score!\n",
      "2021-12-19 20:49:09,386 INFO fold: 2 accuracy_score : 0.9593527032364838\n",
      "2021-12-19 20:49:09,387 INFO Predicting Test Scores!\n",
      "2021-12-19 20:49:12,203 INFO Training Started!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:49:13] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-19 20:53:05,990 INFO Training Finished!\n",
      "2021-12-19 20:53:05,990 INFO Predicting Val Probablities!\n",
      "2021-12-19 20:53:07,708 INFO Predicting Val Score!\n",
      "2021-12-19 20:53:09,440 INFO fold: 3 accuracy_score : 0.9589389553052234\n",
      "2021-12-19 20:53:09,440 INFO Predicting Test Scores!\n",
      "2021-12-19 20:53:12,239 INFO Training Started!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:53:13] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-19 20:57:04,648 INFO Training Finished!\n",
      "2021-12-19 20:57:04,648 INFO Predicting Val Probablities!\n",
      "2021-12-19 20:57:06,357 INFO Predicting Val Score!\n",
      "2021-12-19 20:57:08,078 INFO fold: 4 accuracy_score : 0.9589502052489738\n",
      "2021-12-19 20:57:08,079 INFO Predicting Test Scores!\n",
      "2021-12-19 20:57:10,851 INFO Training Started!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:57:11] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-19 21:01:02,420 INFO Training Finished!\n",
      "2021-12-19 21:01:02,421 INFO Predicting Val Probablities!\n",
      "2021-12-19 21:01:04,114 INFO Predicting Val Score!\n",
      "2021-12-19 21:01:05,835 INFO fold: 5 accuracy_score : 0.9588439557802211\n",
      "2021-12-19 21:01:05,836 INFO Predicting Test Scores!\n",
      "2021-12-19 21:01:08,026 INFO  Mean Metrics Results from all Folds are: {'accuracy_score': 0.9585174682872781}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20min 25s, sys: 6.16 s, total: 20min 31s\n",
      "Wall time: 19min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# k-fold training\n",
    "xgb_model_metrics_score, xgb_model_test_preds = tmlt.do_kfold_training(X_np,\n",
    "                                                                       y_np,\n",
    "                                                                       X_test=X_test_np,\n",
    "                                                                       n_splits=5,\n",
    "                                                                       model=xgb_model)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000000,)\n"
     ]
    }
   ],
   "source": [
    "# predict on test dataset\n",
    "if xgb_model_test_preds is not None:\n",
    "    print(xgb_model_test_preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # take weighted average of both k-fold models predictions\n",
    "# final_preds = ((0.45 * sci_model_preds) + (0.55* xgb_model_test_preds)) / 2\n",
    "# print(final_preds.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Kaggle Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "test_preds = xgb_model_test_preds\n",
    "print(type(test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1.0: 494233, 0.0: 370376, 2.0: 69298, 6.0: 10159, 0.8: 7402, 0.2: 7188, 1.2: 5994, 0.6000000000000001: 5437, 0.4: 5235, 5.0: 2254, 1.7999999999999998: 2174, 2.4: 2105, 4.8: 2096, 1.4: 1965, 3.5999999999999996: 1722, 1.6: 1721, 2.6: 1254, 2.5999999999999996: 1027, 3.8: 949, 4.4: 943, 3.1999999999999997: 919, 1.8: 874, 1.4000000000000001: 860, 1.5999999999999999: 819, 1.2000000000000002: 700, 1.8000000000000003: 578, 4.2: 347, 3.4000000000000004: 211, 3.2: 190, 3.0: 162, 2.2: 120, 2.6000000000000005: 116, 2.1999999999999997: 115, 3.4: 99, 2.8000000000000003: 84, 2.8: 74, 3.6: 56, 1.9999999999999998: 54, 4.0: 46, 2.4000000000000004: 25, 4.6: 7, 3.0000000000000004: 4, 3.8000000000000003: 4, 2.9999999999999996: 4}\n"
     ]
    }
   ],
   "source": [
    "print(f\"{dict(pd.Series(test_preds).value_counts())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., ..., 1., 0., 2.])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.dtype[float64]' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8168/1171399789.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_preds_round\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest_preds_round\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.dtype[float64]' object is not callable"
     ]
    }
   ],
   "source": [
    "test_preds_round = np.around(test_preds).dtype(int)\n",
    "test_preds_round[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1.0: 516591, 0.0: 382799, 2.0: 77883, 6.0: 10159, 5.0: 4357, 3.0: 4144, 4.0: 4067}\n"
     ]
    }
   ],
   "source": [
    "print(f\"{dict(pd.Series(test_preds_round).value_counts())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 2., 2., ..., 2., 1., 3.])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# target encoding changes 1 to 7 classes to 0 to 6\n",
    "test_preds_final = test_preds_round + 1\n",
    "test_preds_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2.0: 516591, 1.0: 382799, 3.0: 77883, 7.0: 10159, 6.0: 4357, 4.0: 4144, 5.0: 4067}\n"
     ]
    }
   ],
   "source": [
    "print(f\"{dict(pd.Series(test_preds_final).value_counts())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sun_dec_19_2109_submission.csv saved!\n"
     ]
    }
   ],
   "source": [
    "submission_file_name = 'sun_dec_19_2109_submission.csv'\n",
    "\n",
    "sub = pd.read_csv(DIRECTORY_PATH + SAMPLE_SUB_FILE)\n",
    "sub['Cover_Type'] = test_preds\n",
    "\n",
    "sub.to_csv(submission_file_name, index=False)\n",
    "print(f\"{submission_file_name} saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nbdev",
   "language": "python",
   "name": "nbdev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
