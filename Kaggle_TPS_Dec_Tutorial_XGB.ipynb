{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started Kaggle TPS Challenge with Tabular ML Toolkit\n",
    "\n",
    "> A Tutorial to showcase usage of tabular_ml_toolkit (tmlt) library on Kaggle TPS Challenge Nov 2021.\n",
    "\n",
    "> tabular_ml_toolkit is a helper library to jumpstart your machine learning project based on Tabular or Structured data.\n",
    "\n",
    "> It comes with model parallelism and cutting edge hyperparameter search techniques.\n",
    "\n",
    "> Under the hood TMLT uses optuna, xgboost and scikit-learn pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pip install -U tabular_ml_toolkit`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to Best Use tabular_ml_toolkit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start with your favorite model and then just simply create **tmlt** with one API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Here we are using XGBClassifier, on  [Kaggle TPS Challenge (Nov 2021) data](https://www.kaggle.com/c/tabular-playground-series-nov-2021/data)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabular_ml_toolkit.tmlt import *\n",
    "from xgboost import XGBClassifier\n",
    "import numpy as np\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, accuracy_score, log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset file names and Paths\n",
    "DIRECTORY_PATH = \"/home/pankaj/kaggle_datasets/tpc_dec_2021/\"\n",
    "TRAIN_FILE = \"train.csv\"\n",
    "TEST_FILE = \"test.csv\"\n",
    "SAMPLE_SUB_FILE = \"sample_submission.csv\"\n",
    "OUTPUT_PATH = \"kaggle_tps_dec_output/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Just point tmlt in the direction of your data\n",
    "\n",
    "#### Let it know what are index and target columns in your tabular data\n",
    "\n",
    "#### what kind of problem type you are trying to resolve?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-18 19:11:22,313 INFO 8 cores found, model and data parallel processing should worked!\n",
      "2021-12-18 19:11:37,395 INFO DataFrame Memory usage decreased to 274.66 Mb (83.9% reduction)\n",
      "2021-12-18 19:11:40,013 INFO DataFrame Memory usage decreased to 67.71 Mb (83.9% reduction)\n",
      "2021-12-18 19:11:40,303 INFO The least class label is :5 and value count is: 1\n",
      "2021-12-18 19:11:40,307 INFO The Original X shape is: (4000000, 55)\n",
      "2021-12-18 19:11:40,422 INFO The X shape after least class duplicates appends is: (4000021, 55)\n",
      "2021-12-18 19:11:42,082 INFO PreProcessing will include target(s) encoding!\n",
      "2021-12-18 19:11:42,190 INFO categorical columns are None, Preprocessing will done accordingly!\n"
     ]
    }
   ],
   "source": [
    "# create tmlt\n",
    "tmlt = TMLT().prepare_data(\n",
    "    train_file_path= DIRECTORY_PATH + TRAIN_FILE,\n",
    "    test_file_path= DIRECTORY_PATH + TEST_FILE,\n",
    "    #make sure to use right index and target columns\n",
    "    idx_col=\"Id\",\n",
    "    target=\"Cover_Type\",\n",
    "    random_state=42,\n",
    "    problem_type=\"multi_class_classification\",\n",
    "#     nrows=4000\n",
    ")\n",
    "\n",
    "\n",
    "# tmlt supports only below task type:\n",
    "    # \"binary_classification\"\n",
    "    # \"multi_label_classification\"\n",
    "    # \"multi_class_classification\"\n",
    "    # \"regression\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(4000021, 54)\n",
      "<class 'numpy.ndarray'>\n",
      "(4000021,)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(1000000, 54)\n"
     ]
    }
   ],
   "source": [
    "print(type(tmlt.dfl.X))\n",
    "print(tmlt.dfl.X.shape)\n",
    "print(type(tmlt.dfl.y))\n",
    "print(tmlt.dfl.y.shape)\n",
    "print(type(tmlt.dfl.X_test))\n",
    "print(tmlt.dfl.X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Horizontal_Distance_To_Hydrology</th>\n",
       "      <th>Vertical_Distance_To_Hydrology</th>\n",
       "      <th>Horizontal_Distance_To_Roadways</th>\n",
       "      <th>Hillshade_9am</th>\n",
       "      <th>Hillshade_Noon</th>\n",
       "      <th>Hillshade_3pm</th>\n",
       "      <th>Horizontal_Distance_To_Fire_Points</th>\n",
       "      <th>...</th>\n",
       "      <th>Soil_Type31</th>\n",
       "      <th>Soil_Type32</th>\n",
       "      <th>Soil_Type33</th>\n",
       "      <th>Soil_Type34</th>\n",
       "      <th>Soil_Type35</th>\n",
       "      <th>Soil_Type36</th>\n",
       "      <th>Soil_Type37</th>\n",
       "      <th>Soil_Type38</th>\n",
       "      <th>Soil_Type39</th>\n",
       "      <th>Soil_Type40</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4000016</th>\n",
       "      <td>2953</td>\n",
       "      <td>114</td>\n",
       "      <td>39</td>\n",
       "      <td>97</td>\n",
       "      <td>111</td>\n",
       "      <td>981</td>\n",
       "      <td>181</td>\n",
       "      <td>209</td>\n",
       "      <td>184</td>\n",
       "      <td>7633</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4000017</th>\n",
       "      <td>2953</td>\n",
       "      <td>114</td>\n",
       "      <td>39</td>\n",
       "      <td>97</td>\n",
       "      <td>111</td>\n",
       "      <td>981</td>\n",
       "      <td>181</td>\n",
       "      <td>209</td>\n",
       "      <td>184</td>\n",
       "      <td>7633</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4000018</th>\n",
       "      <td>2953</td>\n",
       "      <td>114</td>\n",
       "      <td>39</td>\n",
       "      <td>97</td>\n",
       "      <td>111</td>\n",
       "      <td>981</td>\n",
       "      <td>181</td>\n",
       "      <td>209</td>\n",
       "      <td>184</td>\n",
       "      <td>7633</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4000019</th>\n",
       "      <td>2953</td>\n",
       "      <td>114</td>\n",
       "      <td>39</td>\n",
       "      <td>97</td>\n",
       "      <td>111</td>\n",
       "      <td>981</td>\n",
       "      <td>181</td>\n",
       "      <td>209</td>\n",
       "      <td>184</td>\n",
       "      <td>7633</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4000020</th>\n",
       "      <td>2953</td>\n",
       "      <td>114</td>\n",
       "      <td>39</td>\n",
       "      <td>97</td>\n",
       "      <td>111</td>\n",
       "      <td>981</td>\n",
       "      <td>181</td>\n",
       "      <td>209</td>\n",
       "      <td>184</td>\n",
       "      <td>7633</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Elevation  Aspect  Slope  Horizontal_Distance_To_Hydrology  \\\n",
       "4000016       2953     114     39                                97   \n",
       "4000017       2953     114     39                                97   \n",
       "4000018       2953     114     39                                97   \n",
       "4000019       2953     114     39                                97   \n",
       "4000020       2953     114     39                                97   \n",
       "\n",
       "         Vertical_Distance_To_Hydrology  Horizontal_Distance_To_Roadways  \\\n",
       "4000016                             111                              981   \n",
       "4000017                             111                              981   \n",
       "4000018                             111                              981   \n",
       "4000019                             111                              981   \n",
       "4000020                             111                              981   \n",
       "\n",
       "         Hillshade_9am  Hillshade_Noon  Hillshade_3pm  \\\n",
       "4000016            181             209            184   \n",
       "4000017            181             209            184   \n",
       "4000018            181             209            184   \n",
       "4000019            181             209            184   \n",
       "4000020            181             209            184   \n",
       "\n",
       "         Horizontal_Distance_To_Fire_Points  ...  Soil_Type31  Soil_Type32  \\\n",
       "4000016                                7633  ...            0            0   \n",
       "4000017                                7633  ...            0            0   \n",
       "4000018                                7633  ...            0            0   \n",
       "4000019                                7633  ...            0            0   \n",
       "4000020                                7633  ...            0            0   \n",
       "\n",
       "         Soil_Type33  Soil_Type34  Soil_Type35  Soil_Type36  Soil_Type37  \\\n",
       "4000016            0            0            0            0            0   \n",
       "4000017            0            0            0            0            0   \n",
       "4000018            0            0            0            0            0   \n",
       "4000019            0            0            0            0            0   \n",
       "4000020            0            0            0            0            0   \n",
       "\n",
       "         Soil_Type38  Soil_Type39  Soil_Type40  \n",
       "4000016            0            0            0  \n",
       "4000017            0            0            0  \n",
       "4000018            0            0            0  \n",
       "4000019            0            0            0  \n",
       "4000020            0            0            0  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmlt.dfl.X.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 2262087, 0: 1468136, 2: 195712, 6: 62261, 5: 11426, 3: 377, 4: 22}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "print(dict(pd.Series(tmlt.dfl.y).value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### create train valid dataframes for quick preprocessing and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 928 ms, sys: 161 µs, total: 929 ms\n",
      "Wall time: 927 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# create train, valid split to evaulate model on valid dataset\n",
    "X_train, X_valid,  y_train_np, y_valid_np =  tmlt.dfl.create_train_valid(valid_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3200016, 54)\n",
      "(3200016,)\n",
      "(800005, 54)\n",
      "(800005,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train_np.shape)\n",
    "print(X_valid.shape)\n",
    "print(y_valid_np.shape)\n",
    "\n",
    "# print(X_train.columns.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 1809706, 0: 1174364, 2: 156645, 6: 49832, 5: 9146, 3: 305, 4: 18}\n",
      "{1: 452381, 0: 293772, 2: 39067, 6: 12429, 5: 2280, 3: 72, 4: 4}\n"
     ]
    }
   ],
   "source": [
    "# check for class values see if both train and valid have same class labels\n",
    "print(dict(pd.Series(y_train_np).value_counts()))\n",
    "print(dict(pd.Series(y_valid_np).value_counts()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now PreProcess X_train, X_valid\n",
    "\n",
    "NOTE: Preprocessing gives back numpy arrays for pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(3200016, 54)\n",
      "<class 'numpy.ndarray'>\n",
      "(800005, 54)\n",
      "CPU times: user 2.34 s, sys: 464 ms, total: 2.81 s\n",
      "Wall time: 2.81 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_np,  X_valid_np = tmlt.pp_fit_transform(X_train, X_valid)\n",
    "\n",
    "#after getting processed np arrays delete pandas df\n",
    "del [X_train, X_valid]\n",
    "\n",
    "print(type(X_train_np))\n",
    "print(X_train_np.shape)\n",
    "# print(X_train_np)\n",
    "print(type(X_valid_np))\n",
    "print(X_valid_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a base xgb classifier model with your best guess params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb_params = {\n",
    "#     # your best guess params\n",
    "#     'learning_rate':0.2,\n",
    "#     'eval_metric':'mlogloss',\n",
    "#     # must for xgb classifier otherwise warning will be shown\n",
    "#     'use_label_encoder':False,\n",
    "#     # because 42 is the answer for all the randomness in this universe\n",
    "#     'random_state':42,\n",
    "#     #for GPU\n",
    "#     'tree_method': 'gpu_hist',\n",
    "#     'predictor': 'gpu_predictor',\n",
    "# }\n",
    "\n",
    "# xgb_model = XGBClassifier(**xgb_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "    'use_label_encoder': False,\n",
    "    'learning_rate': 0.031717385787086945,\n",
    "    'n_estimators': 700,\n",
    "    'reg_lambda': 0.0818505295760825,\n",
    "    'reg_alpha': 0.003802319140125198,\n",
    "    'subsample': 0.7189482058736735,\n",
    "    'colsample_bytree': 0.5676906823895052,\n",
    "    'max_depth': 4,\n",
    "    'tree_method': 'gpu_hist',\n",
    "    'gpu_id': 0,\n",
    "    'predictor': 'gpu_predictor',\n",
    "}\n",
    "\n",
    "xgb_model = XGBClassifier(**xgb_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # Now do model training\n",
    "# xgb_model.fit(X_train_np, y_train_np,\n",
    "#               verbose=True,\n",
    "#               #detect & avoid overfitting\n",
    "#               eval_set=[(X_valid_np, y_valid_np)],\n",
    "#               eval_metric=\"mlogloss\",\n",
    "#               early_stopping_rounds=300\n",
    "#              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-mlogloss:1.87675\n",
      "[1]\tvalidation_0-mlogloss:1.79388\n",
      "[2]\tvalidation_0-mlogloss:1.73743\n",
      "[3]\tvalidation_0-mlogloss:1.69880\n",
      "[4]\tvalidation_0-mlogloss:1.65096\n",
      "[5]\tvalidation_0-mlogloss:1.61699\n",
      "[6]\tvalidation_0-mlogloss:1.58500\n",
      "[7]\tvalidation_0-mlogloss:1.52524\n",
      "[8]\tvalidation_0-mlogloss:1.49505\n",
      "[9]\tvalidation_0-mlogloss:1.44225\n",
      "[10]\tvalidation_0-mlogloss:1.41825\n",
      "[11]\tvalidation_0-mlogloss:1.36990\n",
      "[12]\tvalidation_0-mlogloss:1.33800\n",
      "[13]\tvalidation_0-mlogloss:1.31350\n",
      "[14]\tvalidation_0-mlogloss:1.29060\n",
      "[15]\tvalidation_0-mlogloss:1.25053\n",
      "[16]\tvalidation_0-mlogloss:1.22203\n",
      "[17]\tvalidation_0-mlogloss:1.18464\n",
      "[18]\tvalidation_0-mlogloss:1.16007\n",
      "[19]\tvalidation_0-mlogloss:1.12589\n",
      "[20]\tvalidation_0-mlogloss:1.10305\n",
      "[21]\tvalidation_0-mlogloss:1.08530\n",
      "[22]\tvalidation_0-mlogloss:1.06283\n",
      "[23]\tvalidation_0-mlogloss:1.03844\n",
      "[24]\tvalidation_0-mlogloss:1.02350\n",
      "[25]\tvalidation_0-mlogloss:1.00498\n",
      "[26]\tvalidation_0-mlogloss:0.99047\n",
      "[27]\tvalidation_0-mlogloss:0.96967\n",
      "[28]\tvalidation_0-mlogloss:0.95169\n",
      "[29]\tvalidation_0-mlogloss:0.93154\n",
      "[30]\tvalidation_0-mlogloss:0.91417\n",
      "[31]\tvalidation_0-mlogloss:0.89738\n",
      "[32]\tvalidation_0-mlogloss:0.88646\n",
      "[33]\tvalidation_0-mlogloss:0.87584\n",
      "[34]\tvalidation_0-mlogloss:0.85376\n",
      "[35]\tvalidation_0-mlogloss:0.84312\n",
      "[36]\tvalidation_0-mlogloss:0.82971\n",
      "[37]\tvalidation_0-mlogloss:0.81616\n",
      "[38]\tvalidation_0-mlogloss:0.80115\n",
      "[39]\tvalidation_0-mlogloss:0.78569\n",
      "[40]\tvalidation_0-mlogloss:0.77253\n",
      "[41]\tvalidation_0-mlogloss:0.75965\n",
      "[42]\tvalidation_0-mlogloss:0.75084\n",
      "[43]\tvalidation_0-mlogloss:0.73820\n",
      "[44]\tvalidation_0-mlogloss:0.72469\n",
      "[45]\tvalidation_0-mlogloss:0.71612\n",
      "[46]\tvalidation_0-mlogloss:0.70529\n",
      "[47]\tvalidation_0-mlogloss:0.68971\n",
      "[48]\tvalidation_0-mlogloss:0.67959\n",
      "[49]\tvalidation_0-mlogloss:0.66956\n",
      "[50]\tvalidation_0-mlogloss:0.65519\n",
      "[51]\tvalidation_0-mlogloss:0.64220\n",
      "[52]\tvalidation_0-mlogloss:0.63524\n",
      "[53]\tvalidation_0-mlogloss:0.62573\n",
      "[54]\tvalidation_0-mlogloss:0.61322\n",
      "[55]\tvalidation_0-mlogloss:0.60134\n",
      "[56]\tvalidation_0-mlogloss:0.59552\n",
      "[57]\tvalidation_0-mlogloss:0.59032\n",
      "[58]\tvalidation_0-mlogloss:0.57895\n",
      "[59]\tvalidation_0-mlogloss:0.57353\n",
      "[60]\tvalidation_0-mlogloss:0.56590\n",
      "[61]\tvalidation_0-mlogloss:0.55825\n",
      "[62]\tvalidation_0-mlogloss:0.55383\n",
      "[63]\tvalidation_0-mlogloss:0.54322\n",
      "[64]\tvalidation_0-mlogloss:0.53648\n",
      "[65]\tvalidation_0-mlogloss:0.52716\n",
      "[66]\tvalidation_0-mlogloss:0.51833\n",
      "[67]\tvalidation_0-mlogloss:0.51097\n",
      "[68]\tvalidation_0-mlogloss:0.50433\n",
      "[69]\tvalidation_0-mlogloss:0.49810\n",
      "[70]\tvalidation_0-mlogloss:0.49014\n",
      "[71]\tvalidation_0-mlogloss:0.48174\n",
      "[72]\tvalidation_0-mlogloss:0.47577\n",
      "[73]\tvalidation_0-mlogloss:0.46967\n",
      "[74]\tvalidation_0-mlogloss:0.46411\n",
      "[75]\tvalidation_0-mlogloss:0.45903\n",
      "[76]\tvalidation_0-mlogloss:0.45172\n",
      "[77]\tvalidation_0-mlogloss:0.44849\n",
      "[78]\tvalidation_0-mlogloss:0.44365\n",
      "[79]\tvalidation_0-mlogloss:0.44059\n",
      "[80]\tvalidation_0-mlogloss:0.43563\n",
      "[81]\tvalidation_0-mlogloss:0.42872\n",
      "[82]\tvalidation_0-mlogloss:0.42261\n",
      "[83]\tvalidation_0-mlogloss:0.41845\n",
      "[84]\tvalidation_0-mlogloss:0.41587\n",
      "[85]\tvalidation_0-mlogloss:0.40979\n",
      "[86]\tvalidation_0-mlogloss:0.40614\n",
      "[87]\tvalidation_0-mlogloss:0.40244\n",
      "[88]\tvalidation_0-mlogloss:0.39860\n",
      "[89]\tvalidation_0-mlogloss:0.39595\n",
      "[90]\tvalidation_0-mlogloss:0.39288\n",
      "[91]\tvalidation_0-mlogloss:0.39057\n",
      "[92]\tvalidation_0-mlogloss:0.38660\n",
      "[93]\tvalidation_0-mlogloss:0.38458\n",
      "[94]\tvalidation_0-mlogloss:0.37967\n",
      "[95]\tvalidation_0-mlogloss:0.37760\n",
      "[96]\tvalidation_0-mlogloss:0.37416\n",
      "[97]\tvalidation_0-mlogloss:0.37099\n",
      "[98]\tvalidation_0-mlogloss:0.36603\n",
      "[99]\tvalidation_0-mlogloss:0.36238\n",
      "[100]\tvalidation_0-mlogloss:0.35937\n",
      "[101]\tvalidation_0-mlogloss:0.35594\n",
      "[102]\tvalidation_0-mlogloss:0.35277\n",
      "[103]\tvalidation_0-mlogloss:0.34890\n",
      "[104]\tvalidation_0-mlogloss:0.34579\n",
      "[105]\tvalidation_0-mlogloss:0.34436\n",
      "[106]\tvalidation_0-mlogloss:0.34128\n",
      "[107]\tvalidation_0-mlogloss:0.33762\n",
      "[108]\tvalidation_0-mlogloss:0.33572\n",
      "[109]\tvalidation_0-mlogloss:0.33440\n",
      "[110]\tvalidation_0-mlogloss:0.33284\n",
      "[111]\tvalidation_0-mlogloss:0.33038\n",
      "[112]\tvalidation_0-mlogloss:0.32801\n",
      "[113]\tvalidation_0-mlogloss:0.32670\n",
      "[114]\tvalidation_0-mlogloss:0.32360\n",
      "[115]\tvalidation_0-mlogloss:0.32130\n",
      "[116]\tvalidation_0-mlogloss:0.31910\n",
      "[117]\tvalidation_0-mlogloss:0.31695\n",
      "[118]\tvalidation_0-mlogloss:0.31456\n",
      "[119]\tvalidation_0-mlogloss:0.31222\n",
      "[120]\tvalidation_0-mlogloss:0.31035\n",
      "[121]\tvalidation_0-mlogloss:0.30889\n",
      "[122]\tvalidation_0-mlogloss:0.30773\n",
      "[123]\tvalidation_0-mlogloss:0.30580\n",
      "[124]\tvalidation_0-mlogloss:0.30292\n",
      "[125]\tvalidation_0-mlogloss:0.30072\n",
      "[126]\tvalidation_0-mlogloss:0.29939\n",
      "[127]\tvalidation_0-mlogloss:0.29673\n",
      "[128]\tvalidation_0-mlogloss:0.29383\n",
      "[129]\tvalidation_0-mlogloss:0.29255\n",
      "[130]\tvalidation_0-mlogloss:0.29062\n",
      "[131]\tvalidation_0-mlogloss:0.28940\n",
      "[132]\tvalidation_0-mlogloss:0.28785\n",
      "[133]\tvalidation_0-mlogloss:0.28605\n",
      "[134]\tvalidation_0-mlogloss:0.28417\n",
      "[135]\tvalidation_0-mlogloss:0.28176\n",
      "[136]\tvalidation_0-mlogloss:0.28079\n",
      "[137]\tvalidation_0-mlogloss:0.27930\n",
      "[138]\tvalidation_0-mlogloss:0.27717\n",
      "[139]\tvalidation_0-mlogloss:0.27556\n",
      "[140]\tvalidation_0-mlogloss:0.27423\n",
      "[141]\tvalidation_0-mlogloss:0.27208\n",
      "[142]\tvalidation_0-mlogloss:0.26997\n",
      "[143]\tvalidation_0-mlogloss:0.26857\n",
      "[144]\tvalidation_0-mlogloss:0.26656\n",
      "[145]\tvalidation_0-mlogloss:0.26523\n",
      "[146]\tvalidation_0-mlogloss:0.26410\n",
      "[147]\tvalidation_0-mlogloss:0.26208\n",
      "[148]\tvalidation_0-mlogloss:0.26079\n",
      "[149]\tvalidation_0-mlogloss:0.25988\n",
      "[150]\tvalidation_0-mlogloss:0.25801\n",
      "[151]\tvalidation_0-mlogloss:0.25676\n",
      "[152]\tvalidation_0-mlogloss:0.25503\n",
      "[153]\tvalidation_0-mlogloss:0.25361\n",
      "[154]\tvalidation_0-mlogloss:0.25249\n",
      "[155]\tvalidation_0-mlogloss:0.25142\n",
      "[156]\tvalidation_0-mlogloss:0.25044\n",
      "[157]\tvalidation_0-mlogloss:0.24928\n",
      "[158]\tvalidation_0-mlogloss:0.24809\n",
      "[159]\tvalidation_0-mlogloss:0.24648\n",
      "[160]\tvalidation_0-mlogloss:0.24492\n",
      "[161]\tvalidation_0-mlogloss:0.24370\n",
      "[162]\tvalidation_0-mlogloss:0.24236\n",
      "[163]\tvalidation_0-mlogloss:0.24139\n",
      "[164]\tvalidation_0-mlogloss:0.24017\n",
      "[165]\tvalidation_0-mlogloss:0.23913\n",
      "[166]\tvalidation_0-mlogloss:0.23787\n",
      "[167]\tvalidation_0-mlogloss:0.23696\n",
      "[168]\tvalidation_0-mlogloss:0.23569\n",
      "[169]\tvalidation_0-mlogloss:0.23486\n",
      "[170]\tvalidation_0-mlogloss:0.23401\n",
      "[171]\tvalidation_0-mlogloss:0.23276\n",
      "[172]\tvalidation_0-mlogloss:0.23205\n",
      "[173]\tvalidation_0-mlogloss:0.23109\n",
      "[174]\tvalidation_0-mlogloss:0.23034\n",
      "[175]\tvalidation_0-mlogloss:0.22973\n",
      "[176]\tvalidation_0-mlogloss:0.22879\n",
      "[177]\tvalidation_0-mlogloss:0.22787\n",
      "[178]\tvalidation_0-mlogloss:0.22688\n",
      "[179]\tvalidation_0-mlogloss:0.22613\n",
      "[180]\tvalidation_0-mlogloss:0.22557\n",
      "[181]\tvalidation_0-mlogloss:0.22442\n",
      "[182]\tvalidation_0-mlogloss:0.22403\n",
      "[183]\tvalidation_0-mlogloss:0.22298\n",
      "[184]\tvalidation_0-mlogloss:0.22242\n",
      "[185]\tvalidation_0-mlogloss:0.22173\n",
      "[186]\tvalidation_0-mlogloss:0.22096\n",
      "[187]\tvalidation_0-mlogloss:0.22021\n",
      "[188]\tvalidation_0-mlogloss:0.21956\n",
      "[189]\tvalidation_0-mlogloss:0.21882\n",
      "[190]\tvalidation_0-mlogloss:0.21785\n",
      "[191]\tvalidation_0-mlogloss:0.21709\n",
      "[192]\tvalidation_0-mlogloss:0.21629\n",
      "[193]\tvalidation_0-mlogloss:0.21553\n",
      "[194]\tvalidation_0-mlogloss:0.21492\n",
      "[195]\tvalidation_0-mlogloss:0.21458\n",
      "[196]\tvalidation_0-mlogloss:0.21395\n",
      "[197]\tvalidation_0-mlogloss:0.21356\n",
      "[198]\tvalidation_0-mlogloss:0.21273\n",
      "[199]\tvalidation_0-mlogloss:0.21216\n",
      "[200]\tvalidation_0-mlogloss:0.21138\n",
      "[201]\tvalidation_0-mlogloss:0.21062\n",
      "[202]\tvalidation_0-mlogloss:0.20984\n",
      "[203]\tvalidation_0-mlogloss:0.20908\n",
      "[204]\tvalidation_0-mlogloss:0.20828\n",
      "[205]\tvalidation_0-mlogloss:0.20756\n",
      "[206]\tvalidation_0-mlogloss:0.20681\n",
      "[207]\tvalidation_0-mlogloss:0.20606\n",
      "[208]\tvalidation_0-mlogloss:0.20529\n",
      "[209]\tvalidation_0-mlogloss:0.20482\n",
      "[210]\tvalidation_0-mlogloss:0.20431\n",
      "[211]\tvalidation_0-mlogloss:0.20380\n",
      "[212]\tvalidation_0-mlogloss:0.20350\n",
      "[213]\tvalidation_0-mlogloss:0.20301\n",
      "[214]\tvalidation_0-mlogloss:0.20262\n",
      "[215]\tvalidation_0-mlogloss:0.20225\n",
      "[216]\tvalidation_0-mlogloss:0.20182\n",
      "[217]\tvalidation_0-mlogloss:0.20142\n",
      "[218]\tvalidation_0-mlogloss:0.20090\n",
      "[219]\tvalidation_0-mlogloss:0.20034\n",
      "[220]\tvalidation_0-mlogloss:0.19986\n",
      "[221]\tvalidation_0-mlogloss:0.19924\n",
      "[222]\tvalidation_0-mlogloss:0.19897\n",
      "[223]\tvalidation_0-mlogloss:0.19843\n",
      "[224]\tvalidation_0-mlogloss:0.19795\n",
      "[225]\tvalidation_0-mlogloss:0.19762\n",
      "[226]\tvalidation_0-mlogloss:0.19719\n",
      "[227]\tvalidation_0-mlogloss:0.19688\n",
      "[228]\tvalidation_0-mlogloss:0.19645\n",
      "[229]\tvalidation_0-mlogloss:0.19590\n",
      "[230]\tvalidation_0-mlogloss:0.19541\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[231]\tvalidation_0-mlogloss:0.19507\n",
      "[232]\tvalidation_0-mlogloss:0.19473\n",
      "[233]\tvalidation_0-mlogloss:0.19438\n",
      "[234]\tvalidation_0-mlogloss:0.19389\n",
      "[235]\tvalidation_0-mlogloss:0.19355\n",
      "[236]\tvalidation_0-mlogloss:0.19333\n",
      "[237]\tvalidation_0-mlogloss:0.19301\n",
      "[238]\tvalidation_0-mlogloss:0.19266\n",
      "[239]\tvalidation_0-mlogloss:0.19243\n",
      "[240]\tvalidation_0-mlogloss:0.19206\n",
      "[241]\tvalidation_0-mlogloss:0.19185\n",
      "[242]\tvalidation_0-mlogloss:0.19157\n",
      "[243]\tvalidation_0-mlogloss:0.19126\n",
      "[244]\tvalidation_0-mlogloss:0.19094\n",
      "[245]\tvalidation_0-mlogloss:0.19061\n",
      "[246]\tvalidation_0-mlogloss:0.19021\n",
      "[247]\tvalidation_0-mlogloss:0.18983\n",
      "[248]\tvalidation_0-mlogloss:0.18942\n",
      "[249]\tvalidation_0-mlogloss:0.18909\n",
      "[250]\tvalidation_0-mlogloss:0.18877\n",
      "[251]\tvalidation_0-mlogloss:0.18849\n",
      "[252]\tvalidation_0-mlogloss:0.18812\n",
      "[253]\tvalidation_0-mlogloss:0.18775\n",
      "[254]\tvalidation_0-mlogloss:0.18744\n",
      "[255]\tvalidation_0-mlogloss:0.18703\n",
      "[256]\tvalidation_0-mlogloss:0.18669\n",
      "[257]\tvalidation_0-mlogloss:0.18629\n",
      "[258]\tvalidation_0-mlogloss:0.18592\n",
      "[259]\tvalidation_0-mlogloss:0.18554\n",
      "[260]\tvalidation_0-mlogloss:0.18522\n",
      "[261]\tvalidation_0-mlogloss:0.18505\n",
      "[262]\tvalidation_0-mlogloss:0.18480\n",
      "[263]\tvalidation_0-mlogloss:0.18455\n",
      "[264]\tvalidation_0-mlogloss:0.18429\n",
      "[265]\tvalidation_0-mlogloss:0.18393\n",
      "[266]\tvalidation_0-mlogloss:0.18354\n",
      "[267]\tvalidation_0-mlogloss:0.18324\n",
      "[268]\tvalidation_0-mlogloss:0.18291\n",
      "[269]\tvalidation_0-mlogloss:0.18272\n",
      "[270]\tvalidation_0-mlogloss:0.18251\n",
      "[271]\tvalidation_0-mlogloss:0.18223\n",
      "[272]\tvalidation_0-mlogloss:0.18188\n",
      "[273]\tvalidation_0-mlogloss:0.18165\n",
      "[274]\tvalidation_0-mlogloss:0.18146\n",
      "[275]\tvalidation_0-mlogloss:0.18118\n",
      "[276]\tvalidation_0-mlogloss:0.18088\n",
      "[277]\tvalidation_0-mlogloss:0.18064\n",
      "[278]\tvalidation_0-mlogloss:0.18045\n",
      "[279]\tvalidation_0-mlogloss:0.18024\n",
      "[280]\tvalidation_0-mlogloss:0.17999\n",
      "[281]\tvalidation_0-mlogloss:0.17972\n",
      "[282]\tvalidation_0-mlogloss:0.17944\n",
      "[283]\tvalidation_0-mlogloss:0.17919\n",
      "[284]\tvalidation_0-mlogloss:0.17894\n",
      "[285]\tvalidation_0-mlogloss:0.17865\n",
      "[286]\tvalidation_0-mlogloss:0.17836\n",
      "[287]\tvalidation_0-mlogloss:0.17813\n",
      "[288]\tvalidation_0-mlogloss:0.17786\n",
      "[289]\tvalidation_0-mlogloss:0.17772\n",
      "[290]\tvalidation_0-mlogloss:0.17744\n",
      "[291]\tvalidation_0-mlogloss:0.17721\n",
      "[292]\tvalidation_0-mlogloss:0.17702\n",
      "[293]\tvalidation_0-mlogloss:0.17674\n",
      "[294]\tvalidation_0-mlogloss:0.17649\n",
      "[295]\tvalidation_0-mlogloss:0.17627\n",
      "[296]\tvalidation_0-mlogloss:0.17605\n",
      "[297]\tvalidation_0-mlogloss:0.17588\n",
      "[298]\tvalidation_0-mlogloss:0.17567\n",
      "[299]\tvalidation_0-mlogloss:0.17547\n",
      "[300]\tvalidation_0-mlogloss:0.17530\n",
      "[301]\tvalidation_0-mlogloss:0.17512\n",
      "[302]\tvalidation_0-mlogloss:0.17492\n",
      "[303]\tvalidation_0-mlogloss:0.17473\n",
      "[304]\tvalidation_0-mlogloss:0.17455\n",
      "[305]\tvalidation_0-mlogloss:0.17434\n",
      "[306]\tvalidation_0-mlogloss:0.17410\n",
      "[307]\tvalidation_0-mlogloss:0.17391\n",
      "[308]\tvalidation_0-mlogloss:0.17362\n",
      "[309]\tvalidation_0-mlogloss:0.17345\n",
      "[310]\tvalidation_0-mlogloss:0.17329\n",
      "[311]\tvalidation_0-mlogloss:0.17309\n",
      "[312]\tvalidation_0-mlogloss:0.17294\n",
      "[313]\tvalidation_0-mlogloss:0.17269\n",
      "[314]\tvalidation_0-mlogloss:0.17256\n",
      "[315]\tvalidation_0-mlogloss:0.17242\n",
      "[316]\tvalidation_0-mlogloss:0.17227\n",
      "[317]\tvalidation_0-mlogloss:0.17213\n",
      "[318]\tvalidation_0-mlogloss:0.17188\n",
      "[319]\tvalidation_0-mlogloss:0.17176\n",
      "[320]\tvalidation_0-mlogloss:0.17157\n",
      "[321]\tvalidation_0-mlogloss:0.17138\n",
      "[322]\tvalidation_0-mlogloss:0.17116\n",
      "[323]\tvalidation_0-mlogloss:0.17095\n",
      "[324]\tvalidation_0-mlogloss:0.17080\n",
      "[325]\tvalidation_0-mlogloss:0.17061\n",
      "[326]\tvalidation_0-mlogloss:0.17037\n",
      "[327]\tvalidation_0-mlogloss:0.17021\n",
      "[328]\tvalidation_0-mlogloss:0.17006\n",
      "[329]\tvalidation_0-mlogloss:0.16986\n",
      "[330]\tvalidation_0-mlogloss:0.16972\n",
      "[331]\tvalidation_0-mlogloss:0.16957\n",
      "[332]\tvalidation_0-mlogloss:0.16940\n",
      "[333]\tvalidation_0-mlogloss:0.16922\n",
      "[334]\tvalidation_0-mlogloss:0.16908\n",
      "[335]\tvalidation_0-mlogloss:0.16890\n",
      "[336]\tvalidation_0-mlogloss:0.16879\n",
      "[337]\tvalidation_0-mlogloss:0.16856\n",
      "[338]\tvalidation_0-mlogloss:0.16841\n",
      "[339]\tvalidation_0-mlogloss:0.16820\n",
      "[340]\tvalidation_0-mlogloss:0.16806\n",
      "[341]\tvalidation_0-mlogloss:0.16790\n",
      "[342]\tvalidation_0-mlogloss:0.16771\n",
      "[343]\tvalidation_0-mlogloss:0.16759\n",
      "[344]\tvalidation_0-mlogloss:0.16747\n",
      "[345]\tvalidation_0-mlogloss:0.16732\n",
      "[346]\tvalidation_0-mlogloss:0.16713\n",
      "[347]\tvalidation_0-mlogloss:0.16694\n",
      "[348]\tvalidation_0-mlogloss:0.16678\n",
      "[349]\tvalidation_0-mlogloss:0.16658\n",
      "[350]\tvalidation_0-mlogloss:0.16645\n",
      "[351]\tvalidation_0-mlogloss:0.16633\n",
      "[352]\tvalidation_0-mlogloss:0.16614\n",
      "[353]\tvalidation_0-mlogloss:0.16599\n",
      "[354]\tvalidation_0-mlogloss:0.16580\n",
      "[355]\tvalidation_0-mlogloss:0.16564\n",
      "[356]\tvalidation_0-mlogloss:0.16546\n",
      "[357]\tvalidation_0-mlogloss:0.16534\n",
      "[358]\tvalidation_0-mlogloss:0.16524\n",
      "[359]\tvalidation_0-mlogloss:0.16507\n",
      "[360]\tvalidation_0-mlogloss:0.16491\n",
      "[361]\tvalidation_0-mlogloss:0.16478\n",
      "[362]\tvalidation_0-mlogloss:0.16466\n",
      "[363]\tvalidation_0-mlogloss:0.16454\n",
      "[364]\tvalidation_0-mlogloss:0.16440\n",
      "[365]\tvalidation_0-mlogloss:0.16424\n",
      "[366]\tvalidation_0-mlogloss:0.16406\n",
      "[367]\tvalidation_0-mlogloss:0.16391\n",
      "[368]\tvalidation_0-mlogloss:0.16377\n",
      "[369]\tvalidation_0-mlogloss:0.16361\n",
      "[370]\tvalidation_0-mlogloss:0.16350\n",
      "[371]\tvalidation_0-mlogloss:0.16338\n",
      "[372]\tvalidation_0-mlogloss:0.16327\n",
      "[373]\tvalidation_0-mlogloss:0.16315\n",
      "[374]\tvalidation_0-mlogloss:0.16300\n",
      "[375]\tvalidation_0-mlogloss:0.16292\n",
      "[376]\tvalidation_0-mlogloss:0.16280\n",
      "[377]\tvalidation_0-mlogloss:0.16267\n",
      "[378]\tvalidation_0-mlogloss:0.16259\n",
      "[379]\tvalidation_0-mlogloss:0.16248\n",
      "[380]\tvalidation_0-mlogloss:0.16237\n",
      "[381]\tvalidation_0-mlogloss:0.16221\n",
      "[382]\tvalidation_0-mlogloss:0.16205\n",
      "[383]\tvalidation_0-mlogloss:0.16192\n",
      "[384]\tvalidation_0-mlogloss:0.16177\n",
      "[385]\tvalidation_0-mlogloss:0.16159\n",
      "[386]\tvalidation_0-mlogloss:0.16148\n",
      "[387]\tvalidation_0-mlogloss:0.16137\n",
      "[388]\tvalidation_0-mlogloss:0.16126\n",
      "[389]\tvalidation_0-mlogloss:0.16109\n",
      "[390]\tvalidation_0-mlogloss:0.16101\n",
      "[391]\tvalidation_0-mlogloss:0.16091\n",
      "[392]\tvalidation_0-mlogloss:0.16078\n",
      "[393]\tvalidation_0-mlogloss:0.16065\n",
      "[394]\tvalidation_0-mlogloss:0.16054\n",
      "[395]\tvalidation_0-mlogloss:0.16040\n",
      "[396]\tvalidation_0-mlogloss:0.16031\n",
      "[397]\tvalidation_0-mlogloss:0.16022\n",
      "[398]\tvalidation_0-mlogloss:0.16011\n",
      "[399]\tvalidation_0-mlogloss:0.15999\n",
      "[400]\tvalidation_0-mlogloss:0.15988\n",
      "[401]\tvalidation_0-mlogloss:0.15976\n",
      "[402]\tvalidation_0-mlogloss:0.15964\n",
      "[403]\tvalidation_0-mlogloss:0.15946\n",
      "[404]\tvalidation_0-mlogloss:0.15932\n",
      "[405]\tvalidation_0-mlogloss:0.15920\n",
      "[406]\tvalidation_0-mlogloss:0.15907\n",
      "[407]\tvalidation_0-mlogloss:0.15894\n",
      "[408]\tvalidation_0-mlogloss:0.15884\n",
      "[409]\tvalidation_0-mlogloss:0.15870\n",
      "[410]\tvalidation_0-mlogloss:0.15857\n",
      "[411]\tvalidation_0-mlogloss:0.15843\n",
      "[412]\tvalidation_0-mlogloss:0.15829\n",
      "[413]\tvalidation_0-mlogloss:0.15819\n",
      "[414]\tvalidation_0-mlogloss:0.15802\n",
      "[415]\tvalidation_0-mlogloss:0.15794\n",
      "[416]\tvalidation_0-mlogloss:0.15781\n",
      "[417]\tvalidation_0-mlogloss:0.15771\n",
      "[418]\tvalidation_0-mlogloss:0.15761\n",
      "[419]\tvalidation_0-mlogloss:0.15754\n",
      "[420]\tvalidation_0-mlogloss:0.15737\n",
      "[421]\tvalidation_0-mlogloss:0.15718\n",
      "[422]\tvalidation_0-mlogloss:0.15708\n",
      "[423]\tvalidation_0-mlogloss:0.15695\n",
      "[424]\tvalidation_0-mlogloss:0.15678\n",
      "[425]\tvalidation_0-mlogloss:0.15661\n",
      "[426]\tvalidation_0-mlogloss:0.15649\n",
      "[427]\tvalidation_0-mlogloss:0.15639\n",
      "[428]\tvalidation_0-mlogloss:0.15630\n",
      "[429]\tvalidation_0-mlogloss:0.15621\n",
      "[430]\tvalidation_0-mlogloss:0.15609\n",
      "[431]\tvalidation_0-mlogloss:0.15600\n",
      "[432]\tvalidation_0-mlogloss:0.15591\n",
      "[433]\tvalidation_0-mlogloss:0.15581\n",
      "[434]\tvalidation_0-mlogloss:0.15574\n",
      "[435]\tvalidation_0-mlogloss:0.15555\n",
      "[436]\tvalidation_0-mlogloss:0.15546\n",
      "[437]\tvalidation_0-mlogloss:0.15535\n",
      "[438]\tvalidation_0-mlogloss:0.15527\n",
      "[439]\tvalidation_0-mlogloss:0.15515\n",
      "[440]\tvalidation_0-mlogloss:0.15507\n",
      "[441]\tvalidation_0-mlogloss:0.15500\n",
      "[442]\tvalidation_0-mlogloss:0.15484\n",
      "[443]\tvalidation_0-mlogloss:0.15473\n",
      "[444]\tvalidation_0-mlogloss:0.15464\n",
      "[445]\tvalidation_0-mlogloss:0.15454\n",
      "[446]\tvalidation_0-mlogloss:0.15443\n",
      "[447]\tvalidation_0-mlogloss:0.15433\n",
      "[448]\tvalidation_0-mlogloss:0.15424\n",
      "[449]\tvalidation_0-mlogloss:0.15416\n",
      "[450]\tvalidation_0-mlogloss:0.15398\n",
      "[451]\tvalidation_0-mlogloss:0.15388\n",
      "[452]\tvalidation_0-mlogloss:0.15377\n",
      "[453]\tvalidation_0-mlogloss:0.15368\n",
      "[454]\tvalidation_0-mlogloss:0.15356\n",
      "[455]\tvalidation_0-mlogloss:0.15346\n",
      "[456]\tvalidation_0-mlogloss:0.15337\n",
      "[457]\tvalidation_0-mlogloss:0.15330\n",
      "[458]\tvalidation_0-mlogloss:0.15315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[459]\tvalidation_0-mlogloss:0.15305\n",
      "[460]\tvalidation_0-mlogloss:0.15296\n",
      "[461]\tvalidation_0-mlogloss:0.15286\n",
      "[462]\tvalidation_0-mlogloss:0.15274\n",
      "[463]\tvalidation_0-mlogloss:0.15267\n",
      "[464]\tvalidation_0-mlogloss:0.15260\n",
      "[465]\tvalidation_0-mlogloss:0.15247\n",
      "[466]\tvalidation_0-mlogloss:0.15241\n",
      "[467]\tvalidation_0-mlogloss:0.15231\n",
      "[468]\tvalidation_0-mlogloss:0.15224\n",
      "[469]\tvalidation_0-mlogloss:0.15217\n",
      "[470]\tvalidation_0-mlogloss:0.15208\n",
      "[471]\tvalidation_0-mlogloss:0.15202\n",
      "[472]\tvalidation_0-mlogloss:0.15196\n",
      "[473]\tvalidation_0-mlogloss:0.15190\n",
      "[474]\tvalidation_0-mlogloss:0.15173\n",
      "[475]\tvalidation_0-mlogloss:0.15157\n",
      "[476]\tvalidation_0-mlogloss:0.15148\n",
      "[477]\tvalidation_0-mlogloss:0.15137\n",
      "[478]\tvalidation_0-mlogloss:0.15129\n",
      "[479]\tvalidation_0-mlogloss:0.15121\n",
      "[480]\tvalidation_0-mlogloss:0.15113\n",
      "[481]\tvalidation_0-mlogloss:0.15102\n",
      "[482]\tvalidation_0-mlogloss:0.15094\n",
      "[483]\tvalidation_0-mlogloss:0.15083\n",
      "[484]\tvalidation_0-mlogloss:0.15072\n",
      "[485]\tvalidation_0-mlogloss:0.15058\n",
      "[486]\tvalidation_0-mlogloss:0.15049\n",
      "[487]\tvalidation_0-mlogloss:0.15041\n",
      "[488]\tvalidation_0-mlogloss:0.15031\n",
      "[489]\tvalidation_0-mlogloss:0.15022\n",
      "[490]\tvalidation_0-mlogloss:0.15010\n",
      "[491]\tvalidation_0-mlogloss:0.15001\n",
      "[492]\tvalidation_0-mlogloss:0.14988\n",
      "[493]\tvalidation_0-mlogloss:0.14981\n",
      "[494]\tvalidation_0-mlogloss:0.14974\n",
      "[495]\tvalidation_0-mlogloss:0.14962\n",
      "[496]\tvalidation_0-mlogloss:0.14956\n",
      "[497]\tvalidation_0-mlogloss:0.14945\n",
      "[498]\tvalidation_0-mlogloss:0.14940\n",
      "[499]\tvalidation_0-mlogloss:0.14934\n",
      "[500]\tvalidation_0-mlogloss:0.14925\n",
      "[501]\tvalidation_0-mlogloss:0.14919\n",
      "[502]\tvalidation_0-mlogloss:0.14911\n",
      "[503]\tvalidation_0-mlogloss:0.14902\n",
      "[504]\tvalidation_0-mlogloss:0.14890\n",
      "[505]\tvalidation_0-mlogloss:0.14879\n",
      "[506]\tvalidation_0-mlogloss:0.14871\n",
      "[507]\tvalidation_0-mlogloss:0.14861\n",
      "[508]\tvalidation_0-mlogloss:0.14854\n",
      "[509]\tvalidation_0-mlogloss:0.14846\n",
      "[510]\tvalidation_0-mlogloss:0.14838\n",
      "[511]\tvalidation_0-mlogloss:0.14828\n",
      "[512]\tvalidation_0-mlogloss:0.14818\n",
      "[513]\tvalidation_0-mlogloss:0.14811\n",
      "[514]\tvalidation_0-mlogloss:0.14800\n",
      "[515]\tvalidation_0-mlogloss:0.14794\n",
      "[516]\tvalidation_0-mlogloss:0.14787\n",
      "[517]\tvalidation_0-mlogloss:0.14777\n",
      "[518]\tvalidation_0-mlogloss:0.14771\n",
      "[519]\tvalidation_0-mlogloss:0.14766\n",
      "[520]\tvalidation_0-mlogloss:0.14758\n",
      "[521]\tvalidation_0-mlogloss:0.14751\n",
      "[522]\tvalidation_0-mlogloss:0.14738\n",
      "[523]\tvalidation_0-mlogloss:0.14725\n",
      "[524]\tvalidation_0-mlogloss:0.14713\n",
      "[525]\tvalidation_0-mlogloss:0.14706\n",
      "[526]\tvalidation_0-mlogloss:0.14696\n",
      "[527]\tvalidation_0-mlogloss:0.14688\n",
      "[528]\tvalidation_0-mlogloss:0.14681\n",
      "[529]\tvalidation_0-mlogloss:0.14669\n",
      "[530]\tvalidation_0-mlogloss:0.14659\n",
      "[531]\tvalidation_0-mlogloss:0.14654\n",
      "[532]\tvalidation_0-mlogloss:0.14638\n",
      "[533]\tvalidation_0-mlogloss:0.14631\n",
      "[534]\tvalidation_0-mlogloss:0.14619\n",
      "[535]\tvalidation_0-mlogloss:0.14612\n",
      "[536]\tvalidation_0-mlogloss:0.14603\n",
      "[537]\tvalidation_0-mlogloss:0.14591\n",
      "[538]\tvalidation_0-mlogloss:0.14583\n",
      "[539]\tvalidation_0-mlogloss:0.14577\n",
      "[540]\tvalidation_0-mlogloss:0.14570\n",
      "[541]\tvalidation_0-mlogloss:0.14561\n",
      "[542]\tvalidation_0-mlogloss:0.14554\n",
      "[543]\tvalidation_0-mlogloss:0.14543\n",
      "[544]\tvalidation_0-mlogloss:0.14536\n",
      "[545]\tvalidation_0-mlogloss:0.14528\n",
      "[546]\tvalidation_0-mlogloss:0.14521\n",
      "[547]\tvalidation_0-mlogloss:0.14512\n",
      "[548]\tvalidation_0-mlogloss:0.14504\n",
      "[549]\tvalidation_0-mlogloss:0.14498\n",
      "[550]\tvalidation_0-mlogloss:0.14490\n",
      "[551]\tvalidation_0-mlogloss:0.14481\n",
      "[552]\tvalidation_0-mlogloss:0.14476\n",
      "[553]\tvalidation_0-mlogloss:0.14469\n",
      "[554]\tvalidation_0-mlogloss:0.14461\n",
      "[555]\tvalidation_0-mlogloss:0.14454\n",
      "[556]\tvalidation_0-mlogloss:0.14449\n",
      "[557]\tvalidation_0-mlogloss:0.14442\n",
      "[558]\tvalidation_0-mlogloss:0.14431\n",
      "[559]\tvalidation_0-mlogloss:0.14423\n",
      "[560]\tvalidation_0-mlogloss:0.14412\n",
      "[561]\tvalidation_0-mlogloss:0.14405\n",
      "[562]\tvalidation_0-mlogloss:0.14394\n",
      "[563]\tvalidation_0-mlogloss:0.14387\n",
      "[564]\tvalidation_0-mlogloss:0.14376\n",
      "[565]\tvalidation_0-mlogloss:0.14370\n",
      "[566]\tvalidation_0-mlogloss:0.14364\n",
      "[567]\tvalidation_0-mlogloss:0.14357\n",
      "[568]\tvalidation_0-mlogloss:0.14349\n",
      "[569]\tvalidation_0-mlogloss:0.14344\n",
      "[570]\tvalidation_0-mlogloss:0.14336\n",
      "[571]\tvalidation_0-mlogloss:0.14329\n",
      "[572]\tvalidation_0-mlogloss:0.14323\n",
      "[573]\tvalidation_0-mlogloss:0.14310\n",
      "[574]\tvalidation_0-mlogloss:0.14303\n",
      "[575]\tvalidation_0-mlogloss:0.14298\n",
      "[576]\tvalidation_0-mlogloss:0.14292\n",
      "[577]\tvalidation_0-mlogloss:0.14284\n",
      "[578]\tvalidation_0-mlogloss:0.14278\n",
      "[579]\tvalidation_0-mlogloss:0.14272\n",
      "[580]\tvalidation_0-mlogloss:0.14265\n",
      "[581]\tvalidation_0-mlogloss:0.14259\n",
      "[582]\tvalidation_0-mlogloss:0.14252\n",
      "[583]\tvalidation_0-mlogloss:0.14245\n",
      "[584]\tvalidation_0-mlogloss:0.14240\n",
      "[585]\tvalidation_0-mlogloss:0.14235\n",
      "[586]\tvalidation_0-mlogloss:0.14227\n",
      "[587]\tvalidation_0-mlogloss:0.14219\n",
      "[588]\tvalidation_0-mlogloss:0.14213\n",
      "[589]\tvalidation_0-mlogloss:0.14206\n",
      "[590]\tvalidation_0-mlogloss:0.14200\n",
      "[591]\tvalidation_0-mlogloss:0.14194\n",
      "[592]\tvalidation_0-mlogloss:0.14188\n",
      "[593]\tvalidation_0-mlogloss:0.14184\n",
      "[594]\tvalidation_0-mlogloss:0.14178\n",
      "[595]\tvalidation_0-mlogloss:0.14173\n",
      "[596]\tvalidation_0-mlogloss:0.14167\n",
      "[597]\tvalidation_0-mlogloss:0.14160\n",
      "[598]\tvalidation_0-mlogloss:0.14155\n",
      "[599]\tvalidation_0-mlogloss:0.14148\n",
      "[600]\tvalidation_0-mlogloss:0.14140\n",
      "[601]\tvalidation_0-mlogloss:0.14134\n",
      "[602]\tvalidation_0-mlogloss:0.14128\n",
      "[603]\tvalidation_0-mlogloss:0.14121\n",
      "[604]\tvalidation_0-mlogloss:0.14115\n",
      "[605]\tvalidation_0-mlogloss:0.14111\n",
      "[606]\tvalidation_0-mlogloss:0.14107\n",
      "[607]\tvalidation_0-mlogloss:0.14099\n",
      "[608]\tvalidation_0-mlogloss:0.14086\n",
      "[609]\tvalidation_0-mlogloss:0.14078\n",
      "[610]\tvalidation_0-mlogloss:0.14072\n",
      "[611]\tvalidation_0-mlogloss:0.14062\n",
      "[612]\tvalidation_0-mlogloss:0.14055\n",
      "[613]\tvalidation_0-mlogloss:0.14049\n",
      "[614]\tvalidation_0-mlogloss:0.14042\n",
      "[615]\tvalidation_0-mlogloss:0.14034\n",
      "[616]\tvalidation_0-mlogloss:0.14029\n",
      "[617]\tvalidation_0-mlogloss:0.14024\n",
      "[618]\tvalidation_0-mlogloss:0.14019\n",
      "[619]\tvalidation_0-mlogloss:0.14012\n",
      "[620]\tvalidation_0-mlogloss:0.14003\n",
      "[621]\tvalidation_0-mlogloss:0.13998\n",
      "[622]\tvalidation_0-mlogloss:0.13994\n",
      "[623]\tvalidation_0-mlogloss:0.13986\n",
      "[624]\tvalidation_0-mlogloss:0.13981\n",
      "[625]\tvalidation_0-mlogloss:0.13973\n",
      "[626]\tvalidation_0-mlogloss:0.13964\n",
      "[627]\tvalidation_0-mlogloss:0.13956\n",
      "[628]\tvalidation_0-mlogloss:0.13951\n",
      "[629]\tvalidation_0-mlogloss:0.13944\n",
      "[630]\tvalidation_0-mlogloss:0.13939\n",
      "[631]\tvalidation_0-mlogloss:0.13934\n",
      "[632]\tvalidation_0-mlogloss:0.13922\n",
      "[633]\tvalidation_0-mlogloss:0.13917\n",
      "[634]\tvalidation_0-mlogloss:0.13912\n",
      "[635]\tvalidation_0-mlogloss:0.13904\n",
      "[636]\tvalidation_0-mlogloss:0.13900\n",
      "[637]\tvalidation_0-mlogloss:0.13895\n",
      "[638]\tvalidation_0-mlogloss:0.13886\n",
      "[639]\tvalidation_0-mlogloss:0.13880\n",
      "[640]\tvalidation_0-mlogloss:0.13872\n",
      "[641]\tvalidation_0-mlogloss:0.13867\n",
      "[642]\tvalidation_0-mlogloss:0.13862\n",
      "[643]\tvalidation_0-mlogloss:0.13856\n",
      "[644]\tvalidation_0-mlogloss:0.13848\n",
      "[645]\tvalidation_0-mlogloss:0.13843\n",
      "[646]\tvalidation_0-mlogloss:0.13838\n",
      "[647]\tvalidation_0-mlogloss:0.13834\n",
      "[648]\tvalidation_0-mlogloss:0.13828\n",
      "[649]\tvalidation_0-mlogloss:0.13821\n",
      "[650]\tvalidation_0-mlogloss:0.13817\n",
      "[651]\tvalidation_0-mlogloss:0.13813\n",
      "[652]\tvalidation_0-mlogloss:0.13807\n",
      "[653]\tvalidation_0-mlogloss:0.13802\n",
      "[654]\tvalidation_0-mlogloss:0.13798\n",
      "[655]\tvalidation_0-mlogloss:0.13793\n",
      "[656]\tvalidation_0-mlogloss:0.13788\n",
      "[657]\tvalidation_0-mlogloss:0.13783\n",
      "[658]\tvalidation_0-mlogloss:0.13773\n",
      "[659]\tvalidation_0-mlogloss:0.13769\n",
      "[660]\tvalidation_0-mlogloss:0.13759\n",
      "[661]\tvalidation_0-mlogloss:0.13753\n",
      "[662]\tvalidation_0-mlogloss:0.13746\n",
      "[663]\tvalidation_0-mlogloss:0.13741\n",
      "[664]\tvalidation_0-mlogloss:0.13736\n",
      "[665]\tvalidation_0-mlogloss:0.13728\n",
      "[666]\tvalidation_0-mlogloss:0.13722\n",
      "[667]\tvalidation_0-mlogloss:0.13716\n",
      "[668]\tvalidation_0-mlogloss:0.13711\n",
      "[669]\tvalidation_0-mlogloss:0.13708\n",
      "[670]\tvalidation_0-mlogloss:0.13701\n",
      "[671]\tvalidation_0-mlogloss:0.13692\n",
      "[672]\tvalidation_0-mlogloss:0.13687\n",
      "[673]\tvalidation_0-mlogloss:0.13683\n",
      "[674]\tvalidation_0-mlogloss:0.13678\n",
      "[675]\tvalidation_0-mlogloss:0.13674\n",
      "[676]\tvalidation_0-mlogloss:0.13671\n",
      "[677]\tvalidation_0-mlogloss:0.13665\n",
      "[678]\tvalidation_0-mlogloss:0.13655\n",
      "[679]\tvalidation_0-mlogloss:0.13650\n",
      "[680]\tvalidation_0-mlogloss:0.13645\n",
      "[681]\tvalidation_0-mlogloss:0.13641\n",
      "[682]\tvalidation_0-mlogloss:0.13637\n",
      "[683]\tvalidation_0-mlogloss:0.13633\n",
      "[684]\tvalidation_0-mlogloss:0.13630\n",
      "[685]\tvalidation_0-mlogloss:0.13622\n",
      "[686]\tvalidation_0-mlogloss:0.13612\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[687]\tvalidation_0-mlogloss:0.13608\n",
      "[688]\tvalidation_0-mlogloss:0.13600\n",
      "[689]\tvalidation_0-mlogloss:0.13595\n",
      "[690]\tvalidation_0-mlogloss:0.13589\n",
      "[691]\tvalidation_0-mlogloss:0.13581\n",
      "[692]\tvalidation_0-mlogloss:0.13574\n",
      "[693]\tvalidation_0-mlogloss:0.13569\n",
      "[694]\tvalidation_0-mlogloss:0.13565\n",
      "[695]\tvalidation_0-mlogloss:0.13559\n",
      "[696]\tvalidation_0-mlogloss:0.13554\n",
      "[697]\tvalidation_0-mlogloss:0.13547\n",
      "[698]\tvalidation_0-mlogloss:0.13543\n",
      "[699]\tvalidation_0-mlogloss:0.13537\n",
      "CPU times: user 1min 11s, sys: 744 ms, total: 1min 12s\n",
      "Wall time: 1min 7s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-80475734-a08c-4d40-ba92-e4dc4baf2519 {color: black;background-color: white;}#sk-80475734-a08c-4d40-ba92-e4dc4baf2519 pre{padding: 0;}#sk-80475734-a08c-4d40-ba92-e4dc4baf2519 div.sk-toggleable {background-color: white;}#sk-80475734-a08c-4d40-ba92-e4dc4baf2519 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-80475734-a08c-4d40-ba92-e4dc4baf2519 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-80475734-a08c-4d40-ba92-e4dc4baf2519 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-80475734-a08c-4d40-ba92-e4dc4baf2519 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-80475734-a08c-4d40-ba92-e4dc4baf2519 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-80475734-a08c-4d40-ba92-e4dc4baf2519 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-80475734-a08c-4d40-ba92-e4dc4baf2519 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-80475734-a08c-4d40-ba92-e4dc4baf2519 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-80475734-a08c-4d40-ba92-e4dc4baf2519 div.sk-estimator:hover {background-color: #d4ebff;}#sk-80475734-a08c-4d40-ba92-e4dc4baf2519 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-80475734-a08c-4d40-ba92-e4dc4baf2519 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-80475734-a08c-4d40-ba92-e4dc4baf2519 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-80475734-a08c-4d40-ba92-e4dc4baf2519 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;}#sk-80475734-a08c-4d40-ba92-e4dc4baf2519 div.sk-item {z-index: 1;}#sk-80475734-a08c-4d40-ba92-e4dc4baf2519 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}#sk-80475734-a08c-4d40-ba92-e4dc4baf2519 div.sk-parallel::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-80475734-a08c-4d40-ba92-e4dc4baf2519 div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}#sk-80475734-a08c-4d40-ba92-e4dc4baf2519 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-80475734-a08c-4d40-ba92-e4dc4baf2519 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-80475734-a08c-4d40-ba92-e4dc4baf2519 div.sk-parallel-item:only-child::after {width: 0;}#sk-80475734-a08c-4d40-ba92-e4dc4baf2519 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;position: relative;}#sk-80475734-a08c-4d40-ba92-e4dc4baf2519 div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}#sk-80475734-a08c-4d40-ba92-e4dc4baf2519 div.sk-label-container {position: relative;z-index: 2;text-align: center;}#sk-80475734-a08c-4d40-ba92-e4dc4baf2519 div.sk-container {display: inline-block;position: relative;}</style><div id=\"sk-80475734-a08c-4d40-ba92-e4dc4baf2519\" class\"sk-top-container\"><div class=\"sk-container\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"397766bd-f5db-44b3-8c9a-9fe8c40ddb83\" type=\"checkbox\" checked><label class=\"sk-toggleable__label\" for=\"397766bd-f5db-44b3-8c9a-9fe8c40ddb83\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.5676906823895052,\n",
       "              enable_categorical=False, gamma=0, gpu_id=0, importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.031717385787086945,\n",
       "              max_delta_step=0, max_depth=4, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=700, n_jobs=8,\n",
       "              num_parallel_tree=1, objective='multi:softprob',\n",
       "              predictor='gpu_predictor', random_state=0,\n",
       "              reg_alpha=0.003802319140125198, reg_lambda=0.0818505295760825,\n",
       "              scale_pos_weight=None, subsample=0.7189482058736735,\n",
       "              tree_method='gpu_hist', use_label_encoder=False,\n",
       "              validate_parameters=1, verbosity=None)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.5676906823895052,\n",
       "              enable_categorical=False, gamma=0, gpu_id=0, importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.031717385787086945,\n",
       "              max_delta_step=0, max_depth=4, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=700, n_jobs=8,\n",
       "              num_parallel_tree=1, objective='multi:softprob',\n",
       "              predictor='gpu_predictor', random_state=0,\n",
       "              reg_alpha=0.003802319140125198, reg_lambda=0.0818505295760825,\n",
       "              scale_pos_weight=None, subsample=0.7189482058736735,\n",
       "              tree_method='gpu_hist', use_label_encoder=False,\n",
       "              validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Now do model training\n",
    "xgb_model.fit(X_train_np, y_train_np,\n",
    "              verbose=True,\n",
    "              #detect & avoid overfitting\n",
    "              eval_set=[(X_valid_np, y_valid_np)],\n",
    "              eval_metric=\"mlogloss\",\n",
    "              early_stopping_rounds=300\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC is : 0.9967271198825289 , log loss is: 0.13537339522625522, while Accuracy is : 0.9489115693026918 \n",
      "CPU times: user 4.87 s, sys: 140 ms, total: 5.01 s\n",
      "Wall time: 2.83 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#predict\n",
    "preds = xgb_model.predict(X_valid_np)\n",
    "preds_probs = xgb_model.predict_proba(X_valid_np)\n",
    "\n",
    "# Metrics\n",
    "auc = roc_auc_score(y_valid_np, preds_probs, multi_class='ovr')\n",
    "acc = accuracy_score(y_valid_np, preds)\n",
    "lg_loss = log_loss(y_valid_np, preds_probs)\n",
    "\n",
    "print(f\"AUC is : {auc} , log loss is: {lg_loss}, while Accuracy is : {acc} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's do Optuna based HyperParameter search to get best params for fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-18 19:12:56,867 INFO Optimization Direction is: maximize\n",
      "\u001b[32m[I 2021-12-18 19:12:57,199]\u001b[0m A new study created in RDB with name: tmlt_autoxgb\u001b[0m\n",
      "2021-12-18 19:12:57,428 INFO final params {'learning_rate': 0.08320384031444016, 'n_estimators': 150, 'reg_lambda': 0.09967427846688841, 'reg_alpha': 2.0919151416672363e-08, 'subsample': 0.9055617386349193, 'colsample_bytree': 0.7918001490881874, 'max_depth': 3, 'tree_method': 'gpu_hist', 'gpu_id': 0, 'predictor': 'gpu_predictor'}\n",
      "2021-12-18 19:12:57,430 INFO Training Started!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:12:58] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"eval_set\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-18 19:13:11,331 INFO Training Ended!\n",
      "2021-12-18 19:13:11,873 INFO accuracy_score: 0.9323116730520434\n",
      "\u001b[32m[I 2021-12-18 19:13:11,919]\u001b[0m Trial 0 finished with value: 0.9323116730520434 and parameters: {'learning_rate': 0.08320384031444016, 'n_estimators': 150, 'reg_lambda': 0.09967427846688841, 'reg_alpha': 2.0919151416672363e-08, 'subsample': 0.9055617386349193, 'colsample_bytree': 0.7918001490881874, 'max_depth': 3, 'early_stopping_rounds': 400}. Best is trial 0 with value: 0.9323116730520434.\u001b[0m\n",
      "2021-12-18 19:13:12,098 INFO final params {'learning_rate': 0.09847921948714214, 'n_estimators': 70, 'reg_lambda': 0.0016673722721207227, 'reg_alpha': 10.72463097499535, 'subsample': 0.7347006549351925, 'colsample_bytree': 0.7877835708218863, 'max_depth': 8, 'tree_method': 'gpu_hist', 'gpu_id': 0, 'predictor': 'gpu_predictor'}\n",
      "2021-12-18 19:13:12,099 INFO Training Started!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:13:13] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"eval_set\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-18 19:13:23,827 INFO Training Ended!\n",
      "2021-12-18 19:13:24,348 INFO accuracy_score: 0.9544852844669721\n",
      "\u001b[32m[I 2021-12-18 19:13:24,398]\u001b[0m Trial 1 finished with value: 0.9544852844669721 and parameters: {'learning_rate': 0.09847921948714214, 'n_estimators': 70, 'reg_lambda': 0.0016673722721207227, 'reg_alpha': 10.72463097499535, 'subsample': 0.7347006549351925, 'colsample_bytree': 0.7877835708218863, 'max_depth': 8, 'early_stopping_rounds': 284}. Best is trial 1 with value: 0.9544852844669721.\u001b[0m\n",
      "2021-12-18 19:13:24,560 INFO final params {'learning_rate': 0.07270263838593004, 'n_estimators': 70, 'reg_lambda': 4.158686107543348, 'reg_alpha': 4.832344216776012e-05, 'subsample': 0.7744254884262353, 'colsample_bytree': 0.5991862306184299, 'max_depth': 4, 'tree_method': 'gpu_hist', 'gpu_id': 0, 'predictor': 'gpu_predictor'}\n",
      "2021-12-18 19:13:24,562 INFO Training Started!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:13:25] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"eval_set\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-18 19:13:32,573 INFO Training Ended!\n",
      "2021-12-18 19:13:33,080 INFO accuracy_score: 0.9171005181217617\n",
      "\u001b[32m[I 2021-12-18 19:13:33,111]\u001b[0m Trial 2 finished with value: 0.9171005181217617 and parameters: {'learning_rate': 0.07270263838593004, 'n_estimators': 70, 'reg_lambda': 4.158686107543348, 'reg_alpha': 4.832344216776012e-05, 'subsample': 0.7744254884262353, 'colsample_bytree': 0.5991862306184299, 'max_depth': 4, 'early_stopping_rounds': 384}. Best is trial 1 with value: 0.9544852844669721.\u001b[0m\n",
      "2021-12-18 19:13:33,291 INFO final params {'learning_rate': 0.060028759871909115, 'n_estimators': 200, 'reg_lambda': 0.02369049033959721, 'reg_alpha': 0.017469890276853566, 'subsample': 0.42167849406820923, 'colsample_bytree': 0.8558199886275242, 'max_depth': 8, 'tree_method': 'gpu_hist', 'gpu_id': 0, 'predictor': 'gpu_predictor'}\n",
      "2021-12-18 19:13:33,292 INFO Training Started!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:13:34] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"eval_set\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-18 19:14:06,388 INFO Training Ended!\n",
      "2021-12-18 19:14:07,042 INFO accuracy_score: 0.9589290066937082\n",
      "\u001b[32m[I 2021-12-18 19:14:07,102]\u001b[0m Trial 3 finished with value: 0.9589290066937082 and parameters: {'learning_rate': 0.060028759871909115, 'n_estimators': 200, 'reg_lambda': 0.02369049033959721, 'reg_alpha': 0.017469890276853566, 'subsample': 0.42167849406820923, 'colsample_bytree': 0.8558199886275242, 'max_depth': 8, 'early_stopping_rounds': 381}. Best is trial 3 with value: 0.9589290066937082.\u001b[0m\n",
      "2021-12-18 19:14:07,277 INFO final params {'learning_rate': 0.22460180743878044, 'n_estimators': 150, 'reg_lambda': 3.144893773482e-05, 'reg_alpha': 0.00023758525471934383, 'subsample': 0.2640308356915845, 'colsample_bytree': 0.7501402977241696, 'max_depth': 7, 'tree_method': 'gpu_hist', 'gpu_id': 0, 'predictor': 'gpu_predictor'}\n",
      "2021-12-18 19:14:07,279 INFO Training Started!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:14:08] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"eval_set\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-18 19:14:29,981 INFO Training Ended!\n",
      "2021-12-18 19:14:30,586 INFO accuracy_score: 0.960716495521903\n",
      "\u001b[32m[I 2021-12-18 19:14:30,611]\u001b[0m Trial 4 finished with value: 0.960716495521903 and parameters: {'learning_rate': 0.22460180743878044, 'n_estimators': 150, 'reg_lambda': 3.144893773482e-05, 'reg_alpha': 0.00023758525471934383, 'subsample': 0.2640308356915845, 'colsample_bytree': 0.7501402977241696, 'max_depth': 7, 'early_stopping_rounds': 384}. Best is trial 4 with value: 0.960716495521903.\u001b[0m\n",
      "2021-12-18 19:14:30,783 INFO final params {'learning_rate': 0.08751704194963776, 'n_estimators': 70, 'reg_lambda': 3.7769028139024638e-06, 'reg_alpha': 0.008098924177584226, 'subsample': 0.5573029584457505, 'colsample_bytree': 0.1442975801358519, 'max_depth': 1, 'tree_method': 'gpu_hist', 'gpu_id': 0, 'predictor': 'gpu_predictor'}\n",
      "2021-12-18 19:14:30,784 INFO Training Started!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:14:31] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"eval_set\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-18 19:14:36,683 INFO Training Ended!\n",
      "2021-12-18 19:14:37,164 INFO accuracy_score: 0.8955606527459203\n",
      "\u001b[32m[I 2021-12-18 19:14:37,187]\u001b[0m Trial 5 finished with value: 0.8955606527459203 and parameters: {'learning_rate': 0.08751704194963776, 'n_estimators': 70, 'reg_lambda': 3.7769028139024638e-06, 'reg_alpha': 0.008098924177584226, 'subsample': 0.5573029584457505, 'colsample_bytree': 0.1442975801358519, 'max_depth': 1, 'early_stopping_rounds': 232}. Best is trial 4 with value: 0.960716495521903.\u001b[0m\n",
      "2021-12-18 19:14:37,377 INFO final params {'learning_rate': 0.1355290970920128, 'n_estimators': 200, 'reg_lambda': 4.718494577681341, 'reg_alpha': 0.00011104324313160557, 'subsample': 0.5895752319252384, 'colsample_bytree': 0.20930792992141864, 'max_depth': 9, 'tree_method': 'gpu_hist', 'gpu_id': 0, 'predictor': 'gpu_predictor'}\n",
      "2021-12-18 19:14:37,378 INFO Training Started!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:14:38] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"eval_set\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-18 19:15:13,576 INFO Training Ended!\n",
      "2021-12-18 19:15:14,330 INFO accuracy_score: 0.9510978056387147\n",
      "\u001b[32m[I 2021-12-18 19:15:14,355]\u001b[0m Trial 6 finished with value: 0.9510978056387147 and parameters: {'learning_rate': 0.1355290970920128, 'n_estimators': 200, 'reg_lambda': 4.718494577681341, 'reg_alpha': 0.00011104324313160557, 'subsample': 0.5895752319252384, 'colsample_bytree': 0.20930792992141864, 'max_depth': 9, 'early_stopping_rounds': 427}. Best is trial 4 with value: 0.960716495521903.\u001b[0m\n",
      "2021-12-18 19:15:14,536 INFO final params {'learning_rate': 0.039131057793411916, 'n_estimators': 200, 'reg_lambda': 0.05898041689402695, 'reg_alpha': 0.18272546849762208, 'subsample': 0.5542545793591697, 'colsample_bytree': 0.37832542391291635, 'max_depth': 7, 'tree_method': 'gpu_hist', 'gpu_id': 0, 'predictor': 'gpu_predictor'}\n",
      "2021-12-18 19:15:14,537 INFO Training Started!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:15:15] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"eval_set\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-18 19:15:42,179 INFO Training Ended!\n",
      "2021-12-18 19:15:42,803 INFO accuracy_score: 0.9403553727789201\n",
      "\u001b[32m[I 2021-12-18 19:15:42,833]\u001b[0m Trial 7 finished with value: 0.9403553727789201 and parameters: {'learning_rate': 0.039131057793411916, 'n_estimators': 200, 'reg_lambda': 0.05898041689402695, 'reg_alpha': 0.18272546849762208, 'subsample': 0.5542545793591697, 'colsample_bytree': 0.37832542391291635, 'max_depth': 7, 'early_stopping_rounds': 397}. Best is trial 4 with value: 0.960716495521903.\u001b[0m\n",
      "2021-12-18 19:15:43,020 INFO final params {'learning_rate': 0.0231794139366893, 'n_estimators': 200, 'reg_lambda': 0.05514868823726771, 'reg_alpha': 1.706506915453636e-06, 'subsample': 0.7763880301240808, 'colsample_bytree': 0.27947864438356645, 'max_depth': 7, 'tree_method': 'gpu_hist', 'gpu_id': 0, 'predictor': 'gpu_predictor'}\n",
      "2021-12-18 19:15:43,020 INFO Training Started!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:15:43] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"eval_set\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-18 19:16:11,649 INFO Training Ended!\n",
      "2021-12-18 19:16:12,289 INFO accuracy_score: 0.9118980506371835\n",
      "\u001b[32m[I 2021-12-18 19:16:12,334]\u001b[0m Trial 8 finished with value: 0.9118980506371835 and parameters: {'learning_rate': 0.0231794139366893, 'n_estimators': 200, 'reg_lambda': 0.05514868823726771, 'reg_alpha': 1.706506915453636e-06, 'subsample': 0.7763880301240808, 'colsample_bytree': 0.27947864438356645, 'max_depth': 7, 'early_stopping_rounds': 222}. Best is trial 4 with value: 0.960716495521903.\u001b[0m\n",
      "2021-12-18 19:16:12,520 INFO final params {'learning_rate': 0.1495673382033785, 'n_estimators': 70, 'reg_lambda': 5.014993116284377e-05, 'reg_alpha': 8.058076988112284e-06, 'subsample': 0.3111559674675738, 'colsample_bytree': 0.29766445478666503, 'max_depth': 6, 'tree_method': 'gpu_hist', 'gpu_id': 0, 'predictor': 'gpu_predictor'}\n",
      "2021-12-18 19:16:12,521 INFO Training Started!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:16:13] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"eval_set\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-18 19:16:23,427 INFO Training Ended!\n",
      "2021-12-18 19:16:23,951 INFO accuracy_score: 0.9349541565365217\n",
      "\u001b[32m[I 2021-12-18 19:16:23,991]\u001b[0m Trial 9 finished with value: 0.9349541565365217 and parameters: {'learning_rate': 0.1495673382033785, 'n_estimators': 70, 'reg_lambda': 5.014993116284377e-05, 'reg_alpha': 8.058076988112284e-06, 'subsample': 0.3111559674675738, 'colsample_bytree': 0.29766445478666503, 'max_depth': 6, 'early_stopping_rounds': 222}. Best is trial 4 with value: 0.960716495521903.\u001b[0m\n",
      "2021-12-18 19:16:24,175 INFO final params {'learning_rate': 0.23192766617210214, 'n_estimators': 150, 'reg_lambda': 4.4357194951413e-08, 'reg_alpha': 3.638560252776617e-08, 'subsample': 0.144390321769515, 'colsample_bytree': 0.9983270521195565, 'max_depth': 4, 'tree_method': 'gpu_hist', 'gpu_id': 0, 'predictor': 'gpu_predictor'}\n",
      "2021-12-18 19:16:24,177 INFO Training Started!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:16:25] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"eval_set\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-18 19:16:39,890 INFO Training Ended!\n",
      "2021-12-18 19:16:40,444 INFO accuracy_score: 0.9558877757014018\n",
      "\u001b[32m[I 2021-12-18 19:16:40,475]\u001b[0m Trial 10 finished with value: 0.9558877757014018 and parameters: {'learning_rate': 0.23192766617210214, 'n_estimators': 150, 'reg_lambda': 4.4357194951413e-08, 'reg_alpha': 3.638560252776617e-08, 'subsample': 0.144390321769515, 'colsample_bytree': 0.9983270521195565, 'max_depth': 4, 'early_stopping_rounds': 108}. Best is trial 4 with value: 0.960716495521903.\u001b[0m\n",
      "2021-12-18 19:16:40,693 INFO final params {'learning_rate': 0.011032665300184525, 'n_estimators': 150, 'reg_lambda': 0.00015238647209723878, 'reg_alpha': 0.030847608009326028, 'subsample': 0.3206318888473396, 'colsample_bytree': 0.7796814725084281, 'max_depth': 9, 'tree_method': 'gpu_hist', 'gpu_id': 0, 'predictor': 'gpu_predictor'}\n",
      "2021-12-18 19:16:40,693 INFO Training Started!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:16:41] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"eval_set\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-18 19:17:14,630 INFO Training Ended!\n",
      "2021-12-18 19:17:15,251 INFO accuracy_score: 0.9407066205836213\n",
      "\u001b[32m[I 2021-12-18 19:17:15,283]\u001b[0m Trial 11 finished with value: 0.9407066205836213 and parameters: {'learning_rate': 0.011032665300184525, 'n_estimators': 150, 'reg_lambda': 0.00015238647209723878, 'reg_alpha': 0.030847608009326028, 'subsample': 0.3206318888473396, 'colsample_bytree': 0.7796814725084281, 'max_depth': 9, 'early_stopping_rounds': 495}. Best is trial 4 with value: 0.960716495521903.\u001b[0m\n",
      "2021-12-18 19:17:15,469 INFO final params {'learning_rate': 0.03509235657461732, 'n_estimators': 200, 'reg_lambda': 1.5429314627735677e-07, 'reg_alpha': 1.9609323751003085, 'subsample': 0.33308819373036525, 'colsample_bytree': 0.9795787157619746, 'max_depth': 6, 'tree_method': 'gpu_hist', 'gpu_id': 0, 'predictor': 'gpu_predictor'}\n",
      "2021-12-18 19:17:15,469 INFO Training Started!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:17:16] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"eval_set\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-18 19:17:38,402 INFO Training Ended!\n",
      "2021-12-18 19:17:39,012 INFO accuracy_score: 0.9481565740214124\n",
      "\u001b[32m[I 2021-12-18 19:17:39,049]\u001b[0m Trial 12 finished with value: 0.9481565740214124 and parameters: {'learning_rate': 0.03509235657461732, 'n_estimators': 200, 'reg_lambda': 1.5429314627735677e-07, 'reg_alpha': 1.9609323751003085, 'subsample': 0.33308819373036525, 'colsample_bytree': 0.9795787157619746, 'max_depth': 6, 'early_stopping_rounds': 335}. Best is trial 4 with value: 0.960716495521903.\u001b[0m\n",
      "2021-12-18 19:17:39,199 INFO final params {'learning_rate': 0.22622805120653375, 'n_estimators': 150, 'reg_lambda': 0.001672271663050091, 'reg_alpha': 0.006946534672337779, 'subsample': 0.17397266793143232, 'colsample_bytree': 0.582982867003998, 'max_depth': 8, 'tree_method': 'gpu_hist', 'gpu_id': 0, 'predictor': 'gpu_predictor'}\n",
      "2021-12-18 19:17:39,200 INFO Training Started!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:17:40] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"eval_set\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-18 19:18:04,393 INFO Training Ended!\n",
      "2021-12-18 19:18:05,010 INFO accuracy_score: 0.9604514971781426\n",
      "\u001b[32m[I 2021-12-18 19:18:05,034]\u001b[0m Trial 13 finished with value: 0.9604514971781426 and parameters: {'learning_rate': 0.22622805120653375, 'n_estimators': 150, 'reg_lambda': 0.001672271663050091, 'reg_alpha': 0.006946534672337779, 'subsample': 0.17397266793143232, 'colsample_bytree': 0.582982867003998, 'max_depth': 8, 'early_stopping_rounds': 326}. Best is trial 4 with value: 0.960716495521903.\u001b[0m\n",
      "2021-12-18 19:18:05,240 INFO final params {'learning_rate': 0.242002833433415, 'n_estimators': 150, 'reg_lambda': 8.897609225819913e-06, 'reg_alpha': 0.00032079679576163105, 'subsample': 0.10316480197057348, 'colsample_bytree': 0.5573988234896001, 'max_depth': 6, 'tree_method': 'gpu_hist', 'gpu_id': 0, 'predictor': 'gpu_predictor'}\n",
      "2021-12-18 19:18:05,240 INFO Training Started!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:18:06] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"eval_set\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-18 19:18:24,709 INFO Training Ended!\n",
      "2021-12-18 19:18:25,315 INFO accuracy_score: 0.9587240079749502\n",
      "\u001b[32m[I 2021-12-18 19:18:25,344]\u001b[0m Trial 14 finished with value: 0.9587240079749502 and parameters: {'learning_rate': 0.242002833433415, 'n_estimators': 150, 'reg_lambda': 8.897609225819913e-06, 'reg_alpha': 0.00032079679576163105, 'subsample': 0.10316480197057348, 'colsample_bytree': 0.5573988234896001, 'max_depth': 6, 'early_stopping_rounds': 308}. Best is trial 4 with value: 0.960716495521903.\u001b[0m\n",
      "2021-12-18 19:18:25,558 INFO final params {'learning_rate': 0.15083320474801157, 'n_estimators': 150, 'reg_lambda': 0.0008864272430670432, 'reg_alpha': 0.0015330465205195625, 'subsample': 0.21439902518585044, 'colsample_bytree': 0.6759549936116134, 'max_depth': 8, 'tree_method': 'gpu_hist', 'gpu_id': 0, 'predictor': 'gpu_predictor'}\n",
      "2021-12-18 19:18:25,560 INFO Training Started!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:18:26] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"eval_set\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-18 19:18:51,351 INFO Training Ended!\n",
      "2021-12-18 19:18:51,952 INFO accuracy_score: 0.9603652477172018\n",
      "\u001b[32m[I 2021-12-18 19:18:51,998]\u001b[0m Trial 15 finished with value: 0.9603652477172018 and parameters: {'learning_rate': 0.15083320474801157, 'n_estimators': 150, 'reg_lambda': 0.0008864272430670432, 'reg_alpha': 0.0015330465205195625, 'subsample': 0.21439902518585044, 'colsample_bytree': 0.6759549936116134, 'max_depth': 8, 'early_stopping_rounds': 471}. Best is trial 4 with value: 0.960716495521903.\u001b[0m\n",
      "2021-12-18 19:18:52,200 INFO final params {'learning_rate': 0.17758705988155682, 'n_estimators': 150, 'reg_lambda': 7.029382609118037e-07, 'reg_alpha': 7.425489034807764e-07, 'subsample': 0.4261127288921614, 'colsample_bytree': 0.5056735481121135, 'max_depth': 5, 'tree_method': 'gpu_hist', 'gpu_id': 0, 'predictor': 'gpu_predictor'}\n",
      "2021-12-18 19:18:52,202 INFO Training Started!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:18:53] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"eval_set\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-18 19:19:10,088 INFO Training Ended!\n",
      "2021-12-18 19:19:10,652 INFO accuracy_score: 0.9553402791232555\n",
      "\u001b[32m[I 2021-12-18 19:19:10,681]\u001b[0m Trial 16 finished with value: 0.9553402791232555 and parameters: {'learning_rate': 0.17758705988155682, 'n_estimators': 150, 'reg_lambda': 7.029382609118037e-07, 'reg_alpha': 7.425489034807764e-07, 'subsample': 0.4261127288921614, 'colsample_bytree': 0.5056735481121135, 'max_depth': 5, 'early_stopping_rounds': 332}. Best is trial 4 with value: 0.960716495521903.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FrozenTrial(number=4, values=[0.960716495521903], datetime_start=datetime.datetime(2021, 12, 18, 19, 14, 7, 108485), datetime_complete=datetime.datetime(2021, 12, 18, 19, 14, 30, 587883), params={'colsample_bytree': 0.7501402977241696, 'early_stopping_rounds': 384, 'learning_rate': 0.22460180743878044, 'max_depth': 7, 'n_estimators': 150, 'reg_alpha': 0.00023758525471934383, 'reg_lambda': 3.144893773482e-05, 'subsample': 0.2640308356915845}, distributions={'colsample_bytree': UniformDistribution(high=1.0, low=0.1), 'early_stopping_rounds': IntUniformDistribution(high=500, low=100, step=1), 'learning_rate': LogUniformDistribution(high=0.25, low=0.01), 'max_depth': IntUniformDistribution(high=9, low=1, step=1), 'n_estimators': CategoricalDistribution(choices=(70, 150, 200)), 'reg_alpha': LogUniformDistribution(high=100.0, low=1e-08), 'reg_lambda': LogUniformDistribution(high=100.0, low=1e-08), 'subsample': UniformDistribution(high=1.0, low=0.1)}, user_attrs={}, system_attrs={}, intermediate_values={}, trial_id=5, state=TrialState.COMPLETE, value=None)\n"
     ]
    }
   ],
   "source": [
    "# **Just make sure to supply an output directory path so hyperparameter search is saved**\n",
    "study = tmlt.do_xgb_optuna_optimization(X_train_np, y_train_np, X_valid_np, y_valid_np, \n",
    "                                        optuna_db_path=OUTPUT_PATH, opt_timeout=360, use_gpu=True, verbose=True)\n",
    "print(study.best_trial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### now update the meta model with best params from study and then update the sklearn pipeline with this new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb_params {'use_label_encoder': False, 'learning_rate': 0.22460180743878044, 'n_estimators': 150, 'reg_lambda': 3.144893773482e-05, 'reg_alpha': 0.00023758525471934383, 'subsample': 0.2640308356915845, 'colsample_bytree': 0.7501402977241696, 'max_depth': 7, 'tree_method': 'gpu_hist', 'gpu_id': 0, 'predictor': 'gpu_predictor', 'early_stopping_rounds': 384}\n"
     ]
    }
   ],
   "source": [
    "xgb_params.update(study.best_trial.params)\n",
    "print(\"xgb_params\", xgb_params)\n",
    "updated_xgb_model = XGBClassifier(**xgb_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's Use K-Fold Training with best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.01 s, sys: 668 ms, total: 3.67 s\n",
      "Wall time: 3.67 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_np, X_test_np = tmlt.pp_fit_transform(tmlt.dfl.X, tmlt.dfl.X_test)\n",
    "\n",
    "#TODO: NEED TO THINK ABOUT IT\n",
    "y_np = tmlt.dfl.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-18 19:19:15,428 INFO Training Started!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:19:16] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-18 19:19:39,192 INFO Training Finished!\n",
      "2021-12-18 19:19:39,193 INFO Predicting Val Probablities!\n",
      "2021-12-18 19:19:39,669 INFO Predicting Val Score!\n",
      "2021-12-18 19:19:40,173 INFO fold: 1 accuracy_score : 0.9600802494984406\n",
      "2021-12-18 19:19:40,173 INFO Predicting Test Probablities!\n",
      "2021-12-18 19:19:41,443 INFO Training Started!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:19:42] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-18 19:20:05,108 INFO Training Finished!\n",
      "2021-12-18 19:20:05,109 INFO Predicting Val Probablities!\n",
      "2021-12-18 19:20:05,590 INFO Predicting Val Score!\n",
      "2021-12-18 19:20:06,101 INFO fold: 2 accuracy_score : 0.960360198199009\n",
      "2021-12-18 19:20:06,102 INFO Predicting Test Probablities!\n",
      "2021-12-18 19:20:07,316 INFO Training Started!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:20:08] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-18 19:20:31,191 INFO Training Finished!\n",
      "2021-12-18 19:20:31,192 INFO Predicting Val Probablities!\n",
      "2021-12-18 19:20:31,668 INFO Predicting Val Score!\n",
      "2021-12-18 19:20:32,171 INFO fold: 3 accuracy_score : 0.9598439507802461\n",
      "2021-12-18 19:20:32,171 INFO Predicting Test Probablities!\n",
      "2021-12-18 19:20:33,417 INFO Training Started!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:20:34] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-18 19:20:57,212 INFO Training Finished!\n",
      "2021-12-18 19:20:57,213 INFO Predicting Val Probablities!\n",
      "2021-12-18 19:20:57,695 INFO Predicting Val Score!\n",
      "2021-12-18 19:20:58,207 INFO fold: 4 accuracy_score : 0.9600051999740001\n",
      "2021-12-18 19:20:58,208 INFO Predicting Test Probablities!\n",
      "2021-12-18 19:20:59,423 INFO Training Started!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:21:00] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-18 19:21:23,212 INFO Training Finished!\n",
      "2021-12-18 19:21:23,213 INFO Predicting Val Probablities!\n",
      "2021-12-18 19:21:23,729 INFO Predicting Val Score!\n",
      "2021-12-18 19:21:24,243 INFO fold: 5 accuracy_score : 0.959718951405243\n",
      "2021-12-18 19:21:24,244 INFO Predicting Test Probablities!\n",
      "2021-12-18 19:21:24,943 INFO  Mean Metrics Results from all Folds are: {'accuracy_score': 0.9600017099713878}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 39s, sys: 3.7 s, total: 2min 43s\n",
      "Wall time: 2min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# k-fold training\n",
    "xgb_model_metrics_score, xgb_model_test_preds = tmlt.do_kfold_training(X_np,\n",
    "                                                                       y_np,\n",
    "                                                                       X_test=X_test_np,\n",
    "                                                                       n_splits=5,\n",
    "                                                                       model=updated_xgb_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000000,)\n"
     ]
    }
   ],
   "source": [
    "# predict on test dataset\n",
    "if xgb_model_test_preds is not None:\n",
    "    print(xgb_model_test_preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # take weighted average of both k-fold models predictions\n",
    "# final_preds = ((0.45 * sci_model_preds) + (0.55* xgb_model_test_preds)) / 2\n",
    "# print(final_preds.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Kaggle Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_np, X_test_np = tmlt.pp_fit_transform(tmlt.dfl.X, tmlt.dfl.X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000000,)\n"
     ]
    }
   ],
   "source": [
    "xgb_model_test_preds = xgb_model.predict(X_test_np)\n",
    "print(xgb_model_test_preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 1 1 1]\n",
      "[1 2 1 2 2 2]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2    489146\n",
       "1    419986\n",
       "3     90167\n",
       "7       674\n",
       "6        20\n",
       "4         7\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(xgb_model_test_preds[343:349])\n",
    "xgb_model_test_preds = xgb_model_test_preds + 1\n",
    "print(xgb_model_test_preds[343:349])\n",
    "print(type(xgb_model_test_preds))\n",
    "pd.Series(xgb_model_test_preds).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thur_dec_18_1924_submission.csv saved!\n"
     ]
    }
   ],
   "source": [
    "submission_file_name = 'thur_dec_18_1924_submission.csv'\n",
    "\n",
    "sub = pd.read_csv(DIRECTORY_PATH + SAMPLE_SUB_FILE)\n",
    "sub['Cover_Type'] = xgb_model_test_preds\n",
    "\n",
    "sub.to_csv(submission_file_name, index=False)\n",
    "print(f\"{submission_file_name} saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nbdev",
   "language": "python",
   "name": "nbdev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
