{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import *\n",
    "from nbdev import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started with Tabular ML Toolkit\n",
    "\n",
    "> A tutorial to getting started with ML Toolkit to jumpstart your Machine Learning Project based on Tabular or Structured data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pip install -U tabular_ml_toolkit`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to Best Use tabular_ml_toolkit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start with your favorite model and then just simply create MLPipeline with one API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*For example, Here we are using RandomForestRegressor from Scikit-Learn, on  [Melbourne Home Sale price data](https://www.kaggle.com/estrotococo/home-data-for-ml-course)*\n",
    "\n",
    "\n",
    "*No need to install scikit-learn as it comes preinstall with Tabular_ML_Toolkit*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabular_ml_toolkit.MLPipeline import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_valid MAE: 17582.46150684932\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# create scikit-learn ml model\n",
    "scikit_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "# createm ml pipeline for scikit-learn model\n",
    "sci_ml_pl = MLPipeline().prepare_data_for_training(train_file_path= \"https://raw.githubusercontent.com/psmathur/tabular_ml_toolkit/master/input/home_data/train.csv\",\n",
    "                                              test_file_path= \"https://raw.githubusercontent.com/psmathur/tabular_ml_toolkit/master/input/home_data/test.csv\",\n",
    "                                              idx_col=\"Id\", target=\"SalePrice\",valid_size=0.2,\n",
    "                                              model=scikit_model, random_state=42)\n",
    "# Now fit and predict\n",
    "sci_ml_pl.pipeline.fit(sci_ml_pl.dataframeloader.X_train, sci_ml_pl.dataframeloader.y_train)\n",
    "preds = sci_ml_pl.pipeline.predict(sci_ml_pl.dataframeloader.X_valid)\n",
    "print('X_valid MAE:', mean_absolute_error(sci_ml_pl.dataframeloader.y_valid, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's do Cross Validation on our pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "estimator should be an estimator implementing 'fit' method, Training Pipeline object with attributes: pl was passed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/yd/85jdd5bx59v81j8xnbhpkb3h0000gq/T/ipykernel_34663/1374819324.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Multiply by -1 since sklearn calculates *negative* MAE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m scores = -1 * cross_val_score(sci_ml_pl,\n\u001b[0m\u001b[1;32m      5\u001b[0m                               \u001b[0msci_ml_pl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataframeloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_full\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                               \u001b[0msci_ml_pl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataframeloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nbdev_env/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    506\u001b[0m     \"\"\"\n\u001b[1;32m    507\u001b[0m     \u001b[0;31m# To ensure multimetric format is not supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 508\u001b[0;31m     \u001b[0mscorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m     cv_results = cross_validate(\n",
      "\u001b[0;32m~/anaconda3/envs/nbdev_env/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\u001b[0m in \u001b[0;36mcheck_scoring\u001b[0;34m(estimator, scoring, allow_none)\u001b[0m\n\u001b[1;32m    446\u001b[0m     \"\"\"\n\u001b[1;32m    447\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fit\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m         raise TypeError(\n\u001b[0m\u001b[1;32m    449\u001b[0m             \u001b[0;34m\"estimator should be an estimator implementing 'fit' method, %r was passed\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m             \u001b[0;34m%\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: estimator should be an estimator implementing 'fit' method, Training Pipeline object with attributes: pl was passed"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Multiply by -1 since sklearn calculates *negative* MAE\n",
    "scores = -1 * cross_val_score(sci_ml_pl,\n",
    "                              sci_ml_pl.dataframeloader.X_full,\n",
    "                              sci_ml_pl.dataframeloader.y,\n",
    "                              cv=5,\n",
    "                              scoring='neg_mean_absolute_error')\n",
    "\n",
    "print(\"MAE scores:\\n\", scores)\n",
    "print(\"Average MAE score (across experiments):\")\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*You can also use MLPipeline with XGBoost model, Just make sure to install XGBooost first depending upon your OS.*\n",
    "\n",
    "*After that all steps remains same. Here is example using XGBRegressor with [Melbourne Home Sale price data](https://www.kaggle.com/estrotococo/home-data-for-ml-course)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_valid MAE: 15801.672262949487\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "# create xgb ml model\n",
    "xgb_model = XGBRegressor(n_estimators=250,learning_rate=0.05, random_state=42)\n",
    "# createm ml pipeline for xgb model\n",
    "xgb_ml_pl = MLPipeline().prepare_data_for_training(train_file_path= \"https://raw.githubusercontent.com/psmathur/tabular_ml_toolkit/master/input/home_data/train.csv\",\n",
    "                                              test_file_path= \"https://raw.githubusercontent.com/psmathur/tabular_ml_toolkit/master/input/home_data/test.csv\",\n",
    "                                              idx_col=\"Id\", target=\"SalePrice\",valid_size=0.2,\n",
    "                                              model=xgb_model, random_state=42)\n",
    "# Now fit and predict\n",
    "xgb_ml_pl.pipeline.fit(xgb_ml_pl.dataframeloader.X_train, xgb_ml_pl.dataframeloader.y_train)\n",
    "preds = xgb_ml_pl.pipeline.predict(xgb_ml_pl.dataframeloader.X_valid)\n",
    "print('X_valid MAE:', mean_absolute_error(xgb_ml_pl.dataframeloader.y_valid, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In background `prepare_data_for_training` method loads your input data into Pandas DataFrame, seprates X(features) and y(target), split X(features) into X_train, y_train, X_valid, y_valid DataFrames. Then it preprocess all numerical and categorical type data found in these DataFrames. Then it bundle preprocessed data with your given model and return an MLPipeline object, so you can call MLPipeline to fit X_train and y_train and predict on X_valid or X_test.\n",
    "\n",
    "Here is detail documentation and source code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_doc(MLPipeline.prepare_data_for_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to customize data and preprocessing steps you can do so by using `DataFrameLoader` and `PreProessor` classes. Check detail documentations for these classes for more options. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_doc(MLPipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
