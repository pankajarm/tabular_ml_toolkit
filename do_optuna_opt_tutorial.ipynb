{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started Tutorial with Tabular ML Toolkit\n",
    "\n",
    "> A tutorial on getting started with Tabular ml toolkit\n",
    "\n",
    "> tabular_ml_toolkit is a superfast helper library to speedup your machine learning project based on Tabular or Structured data.\n",
    "\n",
    "> It comes with model parallelism and cutting edge hyperparameter tuning techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pip install -U tabular_ml_toolkit`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to Best Use tabular_ml_toolkit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start with your favorite model and then just simply create MLPipeline with one API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*For example, Here we are using RandomForestRegressor from Scikit-Learn, on  [Melbourne Home Sale price data](https://www.kaggle.com/estrotococo/home-data-for-ml-course)*\n",
    "\n",
    "\n",
    "*No need to install scikit-learn as it comes preinstall with Tabular_ML_Toolkit*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabular_ml_toolkit.mlpipeline import *\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# for displaying diagram of pipelines \n",
    "from sklearn import set_config\n",
    "set_config(display=\"diagram\")\n",
    "\n",
    "# Just to compare fit times\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset file names and Paths\n",
    "DIRECTORY_PATH = \"https://raw.githubusercontent.com/psmathur/tabular_ml_toolkit/master/input/home_data/\"\n",
    "TRAIN_FILE = \"train.csv\"\n",
    "TEST_FILE = \"test.csv\"\n",
    "SAMPLE_SUB_FILE = \"sample_submission.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "xgb_params = {\n",
    "    'n_estimators':250,\n",
    "    'learning_rate':0.05,\n",
    "    'random_state':42,\n",
    "    # for GPU\n",
    "#     'tree_method': 'gpu_hist',\n",
    "#     'predictor': 'gpu_predictor',\n",
    "}\n",
    "\n",
    "\n",
    "# create xgb ml model\n",
    "xgb_model = XGBRegressor(**xgb_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-15 16:05:39,439 INFO 12 cores found, parallel processing is enabled!\n",
      "2021-11-15 16:05:39,695 INFO DataFrame Memory usage decreased to 0.58 Mb (35.5% reduction)\n",
      "2021-11-15 16:05:39,867 INFO DataFrame Memory usage decreased to 0.58 Mb (34.8% reduction)\n"
     ]
    }
   ],
   "source": [
    "# createm ml pipeline for scikit-learn model\n",
    "tmlt = MLPipeline().prepare_data_for_training(\n",
    "    train_file_path= DIRECTORY_PATH+TRAIN_FILE,\n",
    "    test_file_path= DIRECTORY_PATH+TEST_FILE,\n",
    "    idx_col=\"Id\", target=\"SalePrice\",\n",
    "    model=xgb_model,\n",
    "    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-f71baaa1-15a0-4668-a455-7aa60543c093 {color: black;background-color: white;}#sk-f71baaa1-15a0-4668-a455-7aa60543c093 pre{padding: 0;}#sk-f71baaa1-15a0-4668-a455-7aa60543c093 div.sk-toggleable {background-color: white;}#sk-f71baaa1-15a0-4668-a455-7aa60543c093 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-f71baaa1-15a0-4668-a455-7aa60543c093 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-f71baaa1-15a0-4668-a455-7aa60543c093 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-f71baaa1-15a0-4668-a455-7aa60543c093 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-f71baaa1-15a0-4668-a455-7aa60543c093 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-f71baaa1-15a0-4668-a455-7aa60543c093 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-f71baaa1-15a0-4668-a455-7aa60543c093 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-f71baaa1-15a0-4668-a455-7aa60543c093 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-f71baaa1-15a0-4668-a455-7aa60543c093 div.sk-estimator:hover {background-color: #d4ebff;}#sk-f71baaa1-15a0-4668-a455-7aa60543c093 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-f71baaa1-15a0-4668-a455-7aa60543c093 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-f71baaa1-15a0-4668-a455-7aa60543c093 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-f71baaa1-15a0-4668-a455-7aa60543c093 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;}#sk-f71baaa1-15a0-4668-a455-7aa60543c093 div.sk-item {z-index: 1;}#sk-f71baaa1-15a0-4668-a455-7aa60543c093 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}#sk-f71baaa1-15a0-4668-a455-7aa60543c093 div.sk-parallel::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-f71baaa1-15a0-4668-a455-7aa60543c093 div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}#sk-f71baaa1-15a0-4668-a455-7aa60543c093 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-f71baaa1-15a0-4668-a455-7aa60543c093 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-f71baaa1-15a0-4668-a455-7aa60543c093 div.sk-parallel-item:only-child::after {width: 0;}#sk-f71baaa1-15a0-4668-a455-7aa60543c093 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;position: relative;}#sk-f71baaa1-15a0-4668-a455-7aa60543c093 div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}#sk-f71baaa1-15a0-4668-a455-7aa60543c093 div.sk-label-container {position: relative;z-index: 2;text-align: center;}#sk-f71baaa1-15a0-4668-a455-7aa60543c093 div.sk-container {display: inline-block;position: relative;}</style><div id=\"sk-f71baaa1-15a0-4668-a455-7aa60543c093\" class\"sk-top-container\"><div class=\"sk-container\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"424ae8d9-5da2-4862-802e-051ffdbf1c44\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"424ae8d9-5da2-4862-802e-051ffdbf1c44\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('num_cols',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer(strategy='median')),\n",
       "                                                                  ('scaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  ['MSSubClass', 'LotFrontage',\n",
       "                                                   'LotArea', 'OverallQual',\n",
       "                                                   'OverallCond', 'YearBuilt',\n",
       "                                                   'YearRemodAdd', 'MasVnrArea',\n",
       "                                                   'BsmtFinSF1', 'BsmtFinSF2',\n",
       "                                                   'BsmtUnfSF', 'TotalBsmtSF',\n",
       "                                                   '1stFlrSF', '2ndFlrSF',\n",
       "                                                   'Lo...\n",
       "                              interaction_constraints=None, learning_rate=0.05,\n",
       "                              max_delta_step=None, max_depth=None,\n",
       "                              min_child_weight=None, missing=nan,\n",
       "                              monotone_constraints=None, n_estimators=250,\n",
       "                              n_jobs=11, num_parallel_tree=None, predictor=None,\n",
       "                              random_state=42, reg_alpha=None, reg_lambda=None,\n",
       "                              scale_pos_weight=None, subsample=None,\n",
       "                              tree_method=None, validate_parameters=None,\n",
       "                              verbosity=None))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"9921dd26-4465-44f1-b672-0fd2053a6df3\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"9921dd26-4465-44f1-b672-0fd2053a6df3\">preprocessor: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[('num_cols',\n",
       "                                 Pipeline(steps=[('imputer',\n",
       "                                                  SimpleImputer(strategy='median')),\n",
       "                                                 ('scaler', StandardScaler())]),\n",
       "                                 ['MSSubClass', 'LotFrontage', 'LotArea',\n",
       "                                  'OverallQual', 'OverallCond', 'YearBuilt',\n",
       "                                  'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1',\n",
       "                                  'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF',\n",
       "                                  '1stFlrSF', '2ndFlrSF', 'LowQualFinSF',\n",
       "                                  'GrLivArea', 'BsmtFul...\n",
       "                                 ['MSZoning', 'Street', 'Alley', 'LotShape',\n",
       "                                  'LandContour', 'Utilities', 'LotConfig',\n",
       "                                  'LandSlope', 'Condition1', 'Condition2',\n",
       "                                  'BldgType', 'HouseStyle', 'RoofStyle',\n",
       "                                  'RoofMatl', 'MasVnrType', 'ExterQual',\n",
       "                                  'ExterCond', 'Foundation', 'BsmtQual',\n",
       "                                  'BsmtCond', 'BsmtExposure', 'BsmtFinType1',\n",
       "                                  'BsmtFinType2', 'Heating', 'HeatingQC',\n",
       "                                  'CentralAir', 'Electrical', 'KitchenQual',\n",
       "                                  'Functional', 'FireplaceQu', ...])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"6937ba86-66c0-436b-a21d-edf8469413d4\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"6937ba86-66c0-436b-a21d-edf8469413d4\">num_cols</label><div class=\"sk-toggleable__content\"><pre>['MSSubClass', 'LotFrontage', 'LotArea', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces', 'GarageYrBlt', 'GarageCars', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal', 'MoSold', 'YrSold']</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"d8cf027d-91e2-49c3-bea6-f6711a5e092b\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"d8cf027d-91e2-49c3-bea6-f6711a5e092b\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy='median')</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"ec49bc0a-82fd-42c8-ad76-c70312109bc4\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"ec49bc0a-82fd-42c8-ad76-c70312109bc4\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"605e8b6a-8e78-4b54-ac38-344d159f0ef4\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"605e8b6a-8e78-4b54-ac38-344d159f0ef4\">cat_cols</label><div class=\"sk-toggleable__content\"><pre>['MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'Heating', 'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual', 'Functional', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'PavedDrive', 'PoolQC', 'Fence', 'MiscFeature', 'SaleType', 'SaleCondition', 'Neighborhood', 'Exterior1st', 'Exterior2nd']</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"5112b7dd-3815-42f2-bfd6-e7e21076f531\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"5112b7dd-3815-42f2-bfd6-e7e21076f531\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy='constant')</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"663e7482-bc7c-4d86-9f04-18654c91991e\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"663e7482-bc7c-4d86-9f04-18654c91991e\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown='ignore')</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"53fda9d5-c01b-47db-879d-08adb9e05ead\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"53fda9d5-c01b-47db-879d-08adb9e05ead\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
       "             colsample_bynode=None, colsample_bytree=None,\n",
       "             enable_categorical=False, gamma=None, gpu_id=None,\n",
       "             importance_type=None, interaction_constraints=None,\n",
       "             learning_rate=0.05, max_delta_step=None, max_depth=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=250, n_jobs=11, num_parallel_tree=None,\n",
       "             predictor=None, random_state=42, reg_alpha=None, reg_lambda=None,\n",
       "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
       "             validate_parameters=None, verbosity=None)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('num_cols',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer(strategy='median')),\n",
       "                                                                  ('scaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  ['MSSubClass', 'LotFrontage',\n",
       "                                                   'LotArea', 'OverallQual',\n",
       "                                                   'OverallCond', 'YearBuilt',\n",
       "                                                   'YearRemodAdd', 'MasVnrArea',\n",
       "                                                   'BsmtFinSF1', 'BsmtFinSF2',\n",
       "                                                   'BsmtUnfSF', 'TotalBsmtSF',\n",
       "                                                   '1stFlrSF', '2ndFlrSF',\n",
       "                                                   'Lo...\n",
       "                              interaction_constraints=None, learning_rate=0.05,\n",
       "                              max_delta_step=None, max_depth=None,\n",
       "                              min_child_weight=None, missing=nan,\n",
       "                              monotone_constraints=None, n_estimators=250,\n",
       "                              n_jobs=11, num_parallel_tree=None, predictor=None,\n",
       "                              random_state=42, reg_alpha=None, reg_lambda=None,\n",
       "                              scale_pos_weight=None, subsample=None,\n",
       "                              tree_method=None, validate_parameters=None,\n",
       "                              verbosity=None))])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmlt.spl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit Time: 0.491671085357666\n",
      "X_valid MAE: 15851.009123501712\n"
     ]
    }
   ],
   "source": [
    "# create train, valid split to evaulate model on valid dataset\n",
    "tmlt.dfl.create_train_valid(valid_size=0.2)\n",
    "\n",
    "start = time.time()\n",
    "# Now fit\n",
    "tmlt.spl.fit(tmlt.dfl.X_train, tmlt.dfl.y_train)\n",
    "end = time.time()\n",
    "print(\"Fit Time:\", end - start)\n",
    "\n",
    "#predict\n",
    "preds = tmlt.spl.predict(tmlt.dfl.X_valid)\n",
    "print('X_valid MAE:', mean_absolute_error(tmlt.dfl.y_valid, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To see clear picture, let's do k_fold training on updated scikit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "2021-11-15 16:05:41,276 INFO fold: 1 , mean_absolute_error: 18947.19236943493\n",
      "2021-11-15 16:05:41,852 INFO fold: 2 , mean_absolute_error: 15652.96465646404\n",
      "2021-11-15 16:05:42,449 INFO fold: 3 , mean_absolute_error: 16128.323335830479\n",
      "2021-11-15 16:05:43,028 INFO fold: 4 , mean_absolute_error: 15037.816045055652\n",
      "2021-11-15 16:05:43,580 INFO fold: 5 , mean_absolute_error: 17555.253585188355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean metrics score: 16664.309998394692\n",
      "(1459,)\n"
     ]
    }
   ],
   "source": [
    "# k-fold training\n",
    "xgb_model_metrics_score, xgb_model_preds = tmlt.do_k_fold_training(n_splits=5,\n",
    "                                                                          metrics=mean_absolute_error,\n",
    "                                                                          random_state=42)\n",
    "print(\"mean metrics score:\", np.mean(xgb_model_metrics_score))\n",
    "# predict\n",
    "print(xgb_model_preds.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### *MAE did become slightly bad with K_Fold*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's do HyperParameters Tunning for our entire MLPipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let's see if we can improve our K_Fold score with hyperparams tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-15 16:05:43,728]\u001b[0m Using an existing study with name 'tmlt_autoxgb' instead of creating a new one.\u001b[0m\n",
      "/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:05:43] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1634712680264/work/src/learner.cc:576: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-15 16:05:45,987 INFO fold: 1 , mean_absolute_error: 19246.632772367295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:05:46] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1634712680264/work/src/learner.cc:576: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-15 16:05:48,221 INFO fold: 2 , mean_absolute_error: 15704.935078660103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:05:48] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1634712680264/work/src/learner.cc:576: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-15 16:05:50,502 INFO fold: 3 , mean_absolute_error: 17000.048640839042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:05:50] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1634712680264/work/src/learner.cc:576: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-15 16:05:53,416 INFO fold: 4 , mean_absolute_error: 16007.503625321062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:05:53] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1634712680264/work/src/learner.cc:576: \n",
      "Parameters: { \"colsample_bytree\", \"max_depth\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-15 16:05:55,826 INFO fold: 5 , mean_absolute_error: 18046.178045403467\n",
      "\u001b[32m[I 2021-11-15 16:05:55,858]\u001b[0m Trial 7 finished with value: 17201.059632518194 and parameters: {'learning_rate': 0.02142495766588104, 'reg_lambda': 2.0905054096816745e-05, 'reg_alpha': 36.1202193756502, 'subsample': 0.8332071490092481, 'colsample_bytree': 0.25944468287140465, 'max_depth': 7, 'early_stopping_rounds': 376, 'n_estimators': 7000, 'tree_method': 'hist', 'booster': 'gblinear'}. Best is trial 7 with value: 17201.059632518194.\u001b[0m\n",
      "/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "2021-11-15 16:06:21,046 INFO fold: 1 , mean_absolute_error: 18157.227659460616\n"
     ]
    }
   ],
   "source": [
    "study = tmlt.do_xgb_optuna_optimization(task=\"regression\", xgb_eval_metric=\"mae\",\n",
    "                                        kfold_metrics=mean_absolute_error, output_dir_path=\"output/\")\n",
    "print(study.best_trial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Awesome we found best params with K-fold variations ~ 1 minute!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now let's use best params to update preprocessor and model in our pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_params = tmlt.get_preprocessor_best_params(tune_search)\n",
    "tmlt.update_preprocessor(**pp_params)\n",
    "tmlt.spl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = tmlt.get_model_best_params(tune_search)\n",
    "scikit_model = RandomForestRegressor(**model_params)\n",
    "tmlt.update_model(scikit_model)\n",
    "tmlt.spl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now do cross_validation\n",
    "start = time.time()\n",
    "\n",
    "scores = tmlt.do_cross_validation(cv=5, scoring='neg_mean_absolute_error')\n",
    "end = time.time()\n",
    "print(\"Cross Validation Time:\", end - start)\n",
    "\n",
    "print(\"scores:\", scores)\n",
    "print(\"Average MAE score:\", scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Yup Indeed HyperParams tunning for data preprocessing and model has improved MAE from earlier cross validated model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In background `prepare_data_for_training` method loads your input data into Pandas DataFrame, seprates X(features) and y(target).\n",
    "\n",
    "The `prepare_data_for_training` methods prepare X and y DataFrames, preprocess all numerical and categorical type data found in these DataFrames using scikit-learn pipelines. Then it bundle preprocessed data with your given model and return an MLPipeline object, this class instance has dataframeloader, preprocessor and scikit-lean pipeline instances.\n",
    "\n",
    "The `create_train_valid` method use valid_size to split X(features) into X_train, y_train, X_valid and y_valid DataFrames, so you can call fit methods on X_train and y_train and predict methods on X_valid or X_test.\n",
    "\n",
    "\n",
    "Please check detail documentation and source code for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*NOTE: If you want to customize data and preprocessing steps you can do so by using `DataFrameLoader` and `PreProessor` classes. Check detail documentations for these classes for more options.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's Use XGBosst on MLPipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*You can also use MLPipeline with XGBoost model, Just make sure to install XGBooost first depending upon your OS.*\n",
    "\n",
    "*After that all steps remains same. Here is example using XGBRegressor with [Melbourne Home Sale price data](https://www.kaggle.com/estrotococo/home-data-for-ml-course)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best way to install xgboost if you are on macosx and windows machine is using conda\n",
    "# !conda install -c conda-forge xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "xgb_params = {\n",
    "    'n_estimators':250,\n",
    "    'learning_rate':0.05,\n",
    "    'random_state':42,\n",
    "    # for GPU\n",
    "#     'tree_method': 'gpu_hist',\n",
    "#     'predictor': 'gpu_predictor',\n",
    "}\n",
    "\n",
    "\n",
    "# create xgb ml model\n",
    "xgb_model = XGBRegressor(**xgb_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update pipeline with xgb model\n",
    "tmlt.update_model(xgb_model)\n",
    "tmlt.spl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train, valid split to evaulate model on valid dataset\n",
    "tmlt.dfl.create_train_valid(valid_size=0.2)\n",
    "\n",
    "start = time.time()\n",
    "# Now fit\n",
    "tmlt.spl.fit(tmlt.dfl.X_train, tmlt.dfl.y_train)\n",
    "end = time.time()\n",
    "print(\"Fit Time:\", end - start)\n",
    "\n",
    "#predict\n",
    "preds = tmlt.spl.predict(tmlt.dfl.X_valid)\n",
    "print('X_valid MAE:', mean_absolute_error(tmlt.dfl.y_valid, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, xgboost blown away scikit-model with impressive MAE from out of the box"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's do Cross Validation for XGB Model on our MLPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross_validation\n",
    "scores = tmlt.do_cross_validation(cv=5, scoring='neg_mean_absolute_error')\n",
    "print(\"scores:\", scores)\n",
    "print(\"Average MAE score:\", scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### let's use hyperparam tunning to find best xgb_params using tune grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's tune data preprocessing and model hyperparams\n",
    "param_grid = {\n",
    "#     \"preprocessor__num_cols__scaler\": [StandardScaler(), MinMaxScaler()],\n",
    "#     \"preprocessor__low_card_cat_cols__imputer\": [SimpleImputer(strategy='constant'),\n",
    "#                                                  SimpleImputer(strategy='most_frequent')],\n",
    "#     'model__n_estimators': [500,1000],\n",
    "    'model__learning_rate': [0.02,0.05],\n",
    "    'model__max_depth': [5,10]\n",
    "}\n",
    "\n",
    "start = time.time()\n",
    "# Now do tune grid search\n",
    "tune_search = tmlt.do_tune_grid_search(param_grid=param_grid,\n",
    "                                       cv=5,\n",
    "                                       scoring='neg_mean_absolute_error',\n",
    "                                      early_stopping=False,\n",
    "                                      time_budget_s=60)\n",
    "end = time.time()\n",
    "print(\"Grid Search Time:\", end - start)\n",
    "\n",
    "print(\"Best params:\")\n",
    "print(tune_search.best_params_)\n",
    "\n",
    "print(f\"Internal CV Metrics score: {-1*(tune_search.best_score_):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Amazing our MAE has reduced to 15689.22 by HyperParamss tunning, If we can continue doing hyperparmas tunning, may be we can even do better, take that as challenge!**\n",
    "\n",
    "###### Let's use our newly found params for k-fold training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = tmlt.get_model_best_params(tune_search)\n",
    "xgb_model = XGBRegressor(**xgb_params)\n",
    "tmlt.update_model(xgb_model)\n",
    "tmlt.spl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's Use K-Fold Training for XGB model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-fold training\n",
    "xgb_model_metrics_score, xgb_model_preds = tmlt.do_k_fold_training(n_splits=10, metrics=mean_absolute_error)\n",
    "print(\"mean metrics score:\", np.mean(xgb_model_metrics_score))\n",
    "# predict on test dataset\n",
    "print(xgb_model_preds.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### Let's mix the predictions, using weighted average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = 0.4\n",
    "x2 = 0.6\n",
    "\n",
    "final_preds = ((x1*scikit_model_preds) + (x2*xgb_model_preds)) / 2\n",
    "\n",
    "print(final_preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "# run the script to build \n",
    "\n",
    "from nbdev.export import notebook2script; notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
