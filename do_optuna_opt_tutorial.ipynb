{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started Tutorial with Tabular ML Toolkit\n",
    "\n",
    "> A tutorial on getting started with Tabular ml toolkit\n",
    "\n",
    "> tabular_ml_toolkit is a superfast helper library to speedup your machine learning project based on Tabular or Structured data.\n",
    "\n",
    "> It comes with model parallelism and cutting edge hyperparameter tuning techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pip install -U tabular_ml_toolkit`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to Best Use tabular_ml_toolkit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start with your favorite model and then just simply create MLPipeline with one API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*For example, Here we are using RandomForestRegressor from Scikit-Learn, on  [Melbourne Home Sale price data](https://www.kaggle.com/estrotococo/home-data-for-ml-course)*\n",
    "\n",
    "\n",
    "*No need to install scikit-learn as it comes preinstall with Tabular_ML_Toolkit*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pankajmathur/anaconda3/envs/nbdev_env/lib/python3.9/site-packages/redis/connection.py:77: UserWarning: redis-py works best with hiredis. Please consider installing\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from tabular_ml_toolkit.tmlt import *\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# for displaying diagram of pipelines \n",
    "from sklearn import set_config\n",
    "set_config(display=\"diagram\")\n",
    "\n",
    "# Just to compare fit times\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset file names and Paths\n",
    "DIRECTORY_PATH = \"https://raw.githubusercontent.com/psmathur/tabular_ml_toolkit/master/input/home_data/\"\n",
    "TRAIN_FILE = \"train.csv\"\n",
    "TEST_FILE = \"test.csv\"\n",
    "SAMPLE_SUB_FILE = \"sample_submission.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "xgb_params = {\n",
    "    'n_estimators':250,\n",
    "    'learning_rate':0.05,\n",
    "    'random_state':42,\n",
    "    # for GPU\n",
    "#     'tree_method': 'gpu_hist',\n",
    "#     'predictor': 'gpu_predictor',\n",
    "}\n",
    "\n",
    "\n",
    "# create xgb ml model\n",
    "xgb_model = XGBRegressor(**xgb_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-18 23:18:57,335 INFO 8 cores found, parallel processing is enabled!\n",
      "2021-11-18 23:18:57,736 INFO DataFrame Memory usage decreased to 0.58 Mb (35.5% reduction)\n",
      "2021-11-18 23:18:58,066 INFO DataFrame Memory usage decreased to 0.58 Mb (34.8% reduction)\n",
      "2021-11-18 23:18:58,093 INFO Both Numerical & Categorical columns found, Preprocessing will done accordingly!\n"
     ]
    }
   ],
   "source": [
    "# createm ml pipeline for scikit-learn model\n",
    "tmlt = TMLT().prepare_data_for_training(\n",
    "    train_file_path= DIRECTORY_PATH+TRAIN_FILE,\n",
    "    test_file_path= DIRECTORY_PATH+TEST_FILE,\n",
    "    idx_col=\"Id\", target=\"SalePrice\",\n",
    "    model=xgb_model,\n",
    "    random_state=42,\n",
    "    problem_type=\"regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-53b719e3-1f49-4504-abdd-c840231fecb7 {color: black;background-color: white;}#sk-53b719e3-1f49-4504-abdd-c840231fecb7 pre{padding: 0;}#sk-53b719e3-1f49-4504-abdd-c840231fecb7 div.sk-toggleable {background-color: white;}#sk-53b719e3-1f49-4504-abdd-c840231fecb7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-53b719e3-1f49-4504-abdd-c840231fecb7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-53b719e3-1f49-4504-abdd-c840231fecb7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-53b719e3-1f49-4504-abdd-c840231fecb7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-53b719e3-1f49-4504-abdd-c840231fecb7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-53b719e3-1f49-4504-abdd-c840231fecb7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-53b719e3-1f49-4504-abdd-c840231fecb7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-53b719e3-1f49-4504-abdd-c840231fecb7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-53b719e3-1f49-4504-abdd-c840231fecb7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-53b719e3-1f49-4504-abdd-c840231fecb7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-53b719e3-1f49-4504-abdd-c840231fecb7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-53b719e3-1f49-4504-abdd-c840231fecb7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-53b719e3-1f49-4504-abdd-c840231fecb7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;}#sk-53b719e3-1f49-4504-abdd-c840231fecb7 div.sk-item {z-index: 1;}#sk-53b719e3-1f49-4504-abdd-c840231fecb7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}#sk-53b719e3-1f49-4504-abdd-c840231fecb7 div.sk-parallel::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-53b719e3-1f49-4504-abdd-c840231fecb7 div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}#sk-53b719e3-1f49-4504-abdd-c840231fecb7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-53b719e3-1f49-4504-abdd-c840231fecb7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-53b719e3-1f49-4504-abdd-c840231fecb7 div.sk-parallel-item:only-child::after {width: 0;}#sk-53b719e3-1f49-4504-abdd-c840231fecb7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;position: relative;}#sk-53b719e3-1f49-4504-abdd-c840231fecb7 div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}#sk-53b719e3-1f49-4504-abdd-c840231fecb7 div.sk-label-container {position: relative;z-index: 2;text-align: center;}#sk-53b719e3-1f49-4504-abdd-c840231fecb7 div.sk-container {display: inline-block;position: relative;}</style><div id=\"sk-53b719e3-1f49-4504-abdd-c840231fecb7\" class\"sk-top-container\"><div class=\"sk-container\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"eb17b3dd-a336-410e-836c-650452e15048\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"eb17b3dd-a336-410e-836c-650452e15048\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('num_cols',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer(strategy='median')),\n",
       "                                                                  ('scaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  ['MSSubClass', 'LotFrontage',\n",
       "                                                   'LotArea', 'OverallQual',\n",
       "                                                   'OverallCond', 'YearBuilt',\n",
       "                                                   'YearRemodAdd', 'MasVnrArea',\n",
       "                                                   'BsmtFinSF1', 'BsmtFinSF2',\n",
       "                                                   'BsmtUnfSF', 'TotalBsmtSF',\n",
       "                                                   '1stFlrSF', '2ndFlrSF',\n",
       "                                                   'Lo...\n",
       "                              importance_type='gain',\n",
       "                              interaction_constraints=None, learning_rate=0.05,\n",
       "                              max_delta_step=None, max_depth=None,\n",
       "                              min_child_weight=None, missing=nan,\n",
       "                              monotone_constraints=None, n_estimators=250,\n",
       "                              n_jobs=7, num_parallel_tree=None, random_state=42,\n",
       "                              reg_alpha=None, reg_lambda=None,\n",
       "                              scale_pos_weight=None, subsample=None,\n",
       "                              tree_method=None, validate_parameters=None,\n",
       "                              verbosity=None))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"00a72fe6-5ef8-4a0d-84c6-a1695ace0afb\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"00a72fe6-5ef8-4a0d-84c6-a1695ace0afb\">preprocessor: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[('num_cols',\n",
       "                                 Pipeline(steps=[('imputer',\n",
       "                                                  SimpleImputer(strategy='median')),\n",
       "                                                 ('scaler', StandardScaler())]),\n",
       "                                 ['MSSubClass', 'LotFrontage', 'LotArea',\n",
       "                                  'OverallQual', 'OverallCond', 'YearBuilt',\n",
       "                                  'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1',\n",
       "                                  'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF',\n",
       "                                  '1stFlrSF', '2ndFlrSF', 'LowQualFinSF',\n",
       "                                  'GrLivArea', 'BsmtFul...\n",
       "                                 ['MSZoning', 'Street', 'Alley', 'LotShape',\n",
       "                                  'LandContour', 'Utilities', 'LotConfig',\n",
       "                                  'LandSlope', 'Condition1', 'Condition2',\n",
       "                                  'BldgType', 'HouseStyle', 'RoofStyle',\n",
       "                                  'RoofMatl', 'MasVnrType', 'ExterQual',\n",
       "                                  'ExterCond', 'Foundation', 'BsmtQual',\n",
       "                                  'BsmtCond', 'BsmtExposure', 'BsmtFinType1',\n",
       "                                  'BsmtFinType2', 'Heating', 'HeatingQC',\n",
       "                                  'CentralAir', 'Electrical', 'KitchenQual',\n",
       "                                  'Functional', 'FireplaceQu', ...])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"081dc9e1-916b-4f73-8dcc-98261c28b66b\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"081dc9e1-916b-4f73-8dcc-98261c28b66b\">num_cols</label><div class=\"sk-toggleable__content\"><pre>['MSSubClass', 'LotFrontage', 'LotArea', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces', 'GarageYrBlt', 'GarageCars', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal', 'MoSold', 'YrSold']</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"6e3a43d0-23cc-452b-8c72-eaf36f54393a\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"6e3a43d0-23cc-452b-8c72-eaf36f54393a\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy='median')</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"daf940bc-4c1d-4167-8256-59e2dc5214fa\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"daf940bc-4c1d-4167-8256-59e2dc5214fa\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"b5490ce2-14fc-4847-963d-2650a4603420\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"b5490ce2-14fc-4847-963d-2650a4603420\">cat_cols</label><div class=\"sk-toggleable__content\"><pre>['MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'Heating', 'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual', 'Functional', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'PavedDrive', 'PoolQC', 'Fence', 'MiscFeature', 'SaleType', 'SaleCondition', 'Neighborhood', 'Exterior1st', 'Exterior2nd']</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"bf3d9528-6dd1-4cd6-9afd-c7718c9cefdc\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"bf3d9528-6dd1-4cd6-9afd-c7718c9cefdc\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy='constant')</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"4f289aa5-ab51-454c-994e-574677ca520f\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"4f289aa5-ab51-454c-994e-574677ca520f\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown='ignore')</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"7a766d53-da6d-4438-9c89-3be8b8fb4fd6\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"7a766d53-da6d-4438-9c89-3be8b8fb4fd6\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
       "             colsample_bynode=None, colsample_bytree=None, gamma=None,\n",
       "             gpu_id=None, importance_type='gain', interaction_constraints=None,\n",
       "             learning_rate=0.05, max_delta_step=None, max_depth=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=250, n_jobs=7, num_parallel_tree=None,\n",
       "             random_state=42, reg_alpha=None, reg_lambda=None,\n",
       "             scale_pos_weight=None, subsample=None, tree_method=None,\n",
       "             validate_parameters=None, verbosity=None)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('num_cols',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer(strategy='median')),\n",
       "                                                                  ('scaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  ['MSSubClass', 'LotFrontage',\n",
       "                                                   'LotArea', 'OverallQual',\n",
       "                                                   'OverallCond', 'YearBuilt',\n",
       "                                                   'YearRemodAdd', 'MasVnrArea',\n",
       "                                                   'BsmtFinSF1', 'BsmtFinSF2',\n",
       "                                                   'BsmtUnfSF', 'TotalBsmtSF',\n",
       "                                                   '1stFlrSF', '2ndFlrSF',\n",
       "                                                   'Lo...\n",
       "                              importance_type='gain',\n",
       "                              interaction_constraints=None, learning_rate=0.05,\n",
       "                              max_delta_step=None, max_depth=None,\n",
       "                              min_child_weight=None, missing=nan,\n",
       "                              monotone_constraints=None, n_estimators=250,\n",
       "                              n_jobs=7, num_parallel_tree=None, random_state=42,\n",
       "                              reg_alpha=None, reg_lambda=None,\n",
       "                              scale_pos_weight=None, subsample=None,\n",
       "                              tree_method=None, validate_parameters=None,\n",
       "                              verbosity=None))])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let' see default pipeline\n",
    "tmlt.spl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To see clear picture, let's do k_fold training on updated scikit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # k-fold training\n",
    "# xgb_model_metrics_score, xgb_model_preds = tmlt.do_k_fold_training(n_splits=5,\n",
    "#                                                                           metrics=mean_absolute_error,\n",
    "#                                                                           random_state=42)\n",
    "# print(\"mean metrics score:\", np.mean(xgb_model_metrics_score))\n",
    "# # predict\n",
    "# print(xgb_model_preds.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let's see if we can improve our K_Fold score with hyperparams tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "# from sklearn.impute import SimpleImputer\n",
    "# # from sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-18 23:19:29,926 INFO direction is: minimize\n",
      "\u001b[32m[I 2021-11-18 23:19:29,978]\u001b[0m Using an existing study with name 'tmlt_autoxgb' instead of creating a new one.\u001b[0m\n",
      "/Users/pankajmathur/anaconda3/envs/nbdev_env/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:19:30] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, max_depth, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-18 23:19:33,234 INFO fold: 1 , mean_absolute_error: 20805.823295697774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:19:33] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, max_depth, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-18 23:19:36,177 INFO fold: 2 , mean_absolute_error: 19226.308366331337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:19:36] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, max_depth, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-18 23:19:39,180 INFO fold: 3 , mean_absolute_error: 20080.022802065498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:19:39] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, max_depth, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-18 23:19:42,251 INFO fold: 4 , mean_absolute_error: 18467.855575770547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:19:42] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, max_depth, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-18 23:19:45,392 INFO fold: 5 , mean_absolute_error: 19638.841154751713\n",
      "2021-11-18 23:19:45,392 INFO  mean metrics score: 19643.770238923375\n",
      "\u001b[32m[I 2021-11-18 23:19:45,428]\u001b[0m Trial 7 finished with value: 19643.770238923375 and parameters: {'learning_rate': 0.09553662209579879, 'reg_lambda': 0.6052569845392561, 'reg_alpha': 8.335455567301325e-05, 'subsample': 0.32599069235941713, 'colsample_bytree': 0.7836864633954334, 'max_depth': 5, 'early_stopping_rounds': 398, 'n_estimators': 7000, 'tree_method': 'approx', 'booster': 'gblinear'}. Best is trial 6 with value: 17098.02529831978.\u001b[0m\n",
      "/Users/pankajmathur/anaconda3/envs/nbdev_env/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:19:45] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, max_depth, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-18 23:19:48,707 INFO fold: 1 , mean_absolute_error: 19168.4951171875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:19:48] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, max_depth, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-18 23:19:51,801 INFO fold: 2 , mean_absolute_error: 17245.59119488442\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:19:51] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, max_depth, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-18 23:19:54,933 INFO fold: 3 , mean_absolute_error: 18543.452402611303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:19:54] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, max_depth, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-18 23:19:58,041 INFO fold: 4 , mean_absolute_error: 16902.828874143837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:19:58] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, max_depth, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-18 23:20:01,243 INFO fold: 5 , mean_absolute_error: 17934.75784594392\n",
      "2021-11-18 23:20:01,244 INFO  mean metrics score: 17959.0250869542\n",
      "\u001b[32m[I 2021-11-18 23:20:01,265]\u001b[0m Trial 8 finished with value: 17959.0250869542 and parameters: {'learning_rate': 0.19256200478224605, 'reg_lambda': 0.004356080228500992, 'reg_alpha': 12.200425206909655, 'subsample': 0.31335741793364735, 'colsample_bytree': 0.8363127339177757, 'max_depth': 7, 'early_stopping_rounds': 115, 'n_estimators': 7000, 'tree_method': 'hist', 'booster': 'gblinear'}. Best is trial 6 with value: 17098.02529831978.\u001b[0m\n",
      "/Users/pankajmathur/anaconda3/envs/nbdev_env/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:20:01] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, max_depth, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-18 23:20:04,480 INFO fold: 1 , mean_absolute_error: 19521.103034032534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:20:04] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, max_depth, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-18 23:20:07,871 INFO fold: 2 , mean_absolute_error: 17689.62231779752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:20:07] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, max_depth, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-18 23:20:10,970 INFO fold: 3 , mean_absolute_error: 17897.935894691782\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:20:11] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, max_depth, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-18 23:20:13,955 INFO fold: 4 , mean_absolute_error: 16004.63112692637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:20:14] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, max_depth, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-18 23:20:17,152 INFO fold: 5 , mean_absolute_error: 17576.910664597603\n",
      "2021-11-18 23:20:17,152 INFO  mean metrics score: 17738.04060760916\n",
      "\u001b[32m[I 2021-11-18 23:20:17,175]\u001b[0m Trial 9 finished with value: 17738.04060760916 and parameters: {'learning_rate': 0.01849171116282053, 'reg_lambda': 0.051657995636785164, 'reg_alpha': 0.00010578539845628686, 'subsample': 0.22296944267303037, 'colsample_bytree': 0.3271278971978473, 'max_depth': 6, 'early_stopping_rounds': 499, 'n_estimators': 7000, 'tree_method': 'hist', 'booster': 'gblinear'}. Best is trial 6 with value: 17098.02529831978.\u001b[0m\n",
      "/Users/pankajmathur/anaconda3/envs/nbdev_env/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "2021-11-18 23:21:40,048 INFO fold: 1 , mean_absolute_error: 21102.952723672945\n",
      "2021-11-18 23:23:10,856 INFO fold: 2 , mean_absolute_error: 17694.773103060787\n",
      "2021-11-18 23:24:37,495 INFO fold: 3 , mean_absolute_error: 18632.003411279966\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/yd/85jdd5bx59v81j8xnbhpkb3h0000gq/T/ipykernel_20875/3344473839.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m study = tmlt.do_xgb_optuna_optimization(xgb_eval_metric=\"rmse\",\n\u001b[0m\u001b[1;32m      2\u001b[0m                                         \u001b[0mkfold_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                         output_dir_path=\"output/\")\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_trial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/tabular_ml_toolkit/tabular_ml_toolkit/tmlt.py\u001b[0m in \u001b[0;36mdo_xgb_optuna_optimization\u001b[0;34m(self, xgb_eval_metric, kfold_metrics, output_dir_path, kfold_splits, use_gpu, opt_trials, opt_timeout)\u001b[0m\n\u001b[1;32m    331\u001b[0m             \u001b[0mload_if_exists\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m         )\n\u001b[0;32m--> 333\u001b[0;31m         \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopt_trials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopt_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nbdev_env/lib/python3.9/site-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    398\u001b[0m             )\n\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m         _optimize(\n\u001b[0m\u001b[1;32m    401\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nbdev_env/lib/python3.9/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             _optimize_sequential(\n\u001b[0m\u001b[1;32m     67\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nbdev_env/lib/python3.9/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nbdev_env/lib/python3.9/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/tabular_ml_toolkit/tabular_ml_toolkit/optuna_objective.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, trial)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;31m#         }\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         score, _ = self.tmlt.do_kfold_training(n_splits=self.kfold_splits,\n\u001b[0m\u001b[1;32m     90\u001b[0m                                                 metrics=self.kfold_metrics)\n\u001b[1;32m     91\u001b[0m         \u001b[0mmetrics_mean_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/tabular_ml_toolkit/tabular_ml_toolkit/tmlt.py\u001b[0m in \u001b[0;36mdo_kfold_training\u001b[0;34m(self, n_splits, metrics, random_state)\u001b[0m\n\u001b[1;32m    261\u001b[0m             \u001b[0;31m# fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             \u001b[0;31m#TODO use early_stopping_rounds = True for XGBoost based Sklearn Pipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdfl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdfl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m             \u001b[0;31m#TODO CHANGE HERE FOR multi metrics calculation, i.e. metrics provided in list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nbdev_env/lib/python3.9/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"passthrough\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m                 \u001b[0mfit_params_last_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_params_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nbdev_env/lib/python3.9/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nbdev_env/lib/python3.9/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m    595\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'eval_metric'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0meval_metric\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m         self._Booster = train(params, train_dmatrix,\n\u001b[0m\u001b[1;32m    598\u001b[0m                               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_num_boosting_rounds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m                               \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nbdev_env/lib/python3.9/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[0mBooster\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtrained\u001b[0m \u001b[0mbooster\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m     \"\"\"\n\u001b[0;32m--> 227\u001b[0;31m     bst = _train_internal(params, dtrain,\n\u001b[0m\u001b[1;32m    228\u001b[0m                           \u001b[0mnum_boost_round\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_boost_round\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m                           \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nbdev_env/lib/python3.9/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks, evals_result, maximize, verbose_eval, early_stopping_rounds)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nbdev_env/lib/python3.9/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1275\u001b[0m             raise TypeError('invalid training matrix: {}'.format(\n\u001b[1;32m   1276\u001b[0m                 type(dtrain).__name__))\n\u001b[0;32m-> 1277\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1279\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nbdev_env/lib/python3.9/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36m_validate_features\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   2044\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2045\u001b[0m             \u001b[0;31m# Booster can't accept data with different feature names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2046\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_names\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2047\u001b[0m                 \u001b[0mdat_missing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2048\u001b[0m                 \u001b[0mmy_missing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nbdev_env/lib/python3.9/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mfeature_names\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    800\u001b[0m         \u001b[0mfeature_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfrom_cstr_to_pystr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 802\u001b[0;31m             feature_names = ['f{0}'.format(i)\n\u001b[0m\u001b[1;32m    803\u001b[0m                              for i in range(self.num_col())]\n\u001b[1;32m    804\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nbdev_env/lib/python3.9/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    800\u001b[0m         \u001b[0mfeature_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfrom_cstr_to_pystr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 802\u001b[0;31m             feature_names = ['f{0}'.format(i)\n\u001b[0m\u001b[1;32m    803\u001b[0m                              for i in range(self.num_col())]\n\u001b[1;32m    804\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "study = tmlt.do_xgb_optuna_optimization(xgb_eval_metric=\"rmse\",\n",
    "                                        kfold_metrics=mean_absolute_error,\n",
    "                                        output_dir_path=\"output/\")\n",
    "print(study.best_trial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2021-11-18 22:05:18,152 INFO direction is: minimize\n",
    "[I 2021-11-18 22:05:18,207] Using an existing study with name 'tmlt_autoxgb' instead of creating a new one.\n",
    "/Users/pankajmathur/anaconda3/envs/nbdev_env/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
    "  warnings.warn(\n",
    "2021-11-18 22:05:55,715 INFO fold: 1 , mean_absolute_error: 17737.759805757705\n",
    "2021-11-18 22:06:31,210 INFO fold: 2 , mean_absolute_error: 13937.593455693494\n",
    "2021-11-18 22:07:07,237 INFO fold: 3 , mean_absolute_error: 13931.05033979024\n",
    "2021-11-18 22:07:48,523 INFO fold: 4 , mean_absolute_error: 12936.826492936643\n",
    "2021-11-18 22:08:25,673 INFO fold: 5 , mean_absolute_error: 14848.775216716609\n",
    "[I 2021-11-18 22:08:25,699] Trial 48 finished with value: 14678.401062178938 and parameters: {'learning_rate': 0.010227648390602546, 'reg_lambda': 8.015393563720193e-06, 'reg_alpha': 3.7753443233851705e-06, 'subsample': 0.5799411949016183, 'colsample_bytree': 0.613735233825501, 'max_depth': 4, 'early_stopping_rounds': 200, 'n_estimators': 20000, 'tree_method': 'hist', 'booster': 'gbtree', 'gamma': 0.01783928295659629, 'grow_policy': 'lossguide'}. Best is trial 48 with value: 14678.401062178938.\n",
    "/Users/pankajmathur/anaconda3/envs/nbdev_env/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
    "  warnings.warn(\n",
    "2021-11-18 22:09:02,651 INFO fold: 1 , mean_absolute_error: 17615.194228916953\n",
    "2021-11-18 22:09:40,540 INFO fold: 2 , mean_absolute_error: 14338.525511023116\n",
    "2021-11-18 22:10:18,411 INFO fold: 3 , mean_absolute_error: 13896.110378317637\n",
    "2021-11-18 22:10:56,342 INFO fold: 4 , mean_absolute_error: 13176.088907320205\n",
    "2021-11-18 22:11:35,685 INFO fold: 5 , mean_absolute_error: 14923.216475813357\n",
    "[I 2021-11-18 22:11:35,704] Trial 49 finished with value: 14789.827100278253 and parameters: {'learning_rate': 0.01003614304176459, 'reg_lambda': 1.3143006220261207e-05, 'reg_alpha': 3.3506330151130134e-06, 'subsample': 0.543467363947305, 'colsample_bytree': 0.6249109087231277, 'max_depth': 4, 'early_stopping_rounds': 192, 'n_estimators': 20000, 'tree_method': 'hist', 'booster': 'gbtree', 'gamma': 0.028252682493464184, 'grow_policy': 'lossguide'}. Best is trial 48 with value: 14678.401062178938.\n",
    "FrozenTrial(number=48, values=[14678.401062178938], datetime_start=datetime.datetime(2021, 11, 18, 22, 5, 18, 249529), datetime_complete=datetime.datetime(2021, 11, 18, 22, 8, 25, 674630), params={'booster': 'gbtree', 'colsample_bytree': 0.613735233825501, 'early_stopping_rounds': 200, 'gamma': 0.01783928295659629, 'grow_policy': 'lossguide', 'learning_rate': 0.010227648390602546, 'max_depth': 4, 'n_estimators': 20000, 'reg_alpha': 3.7753443233851705e-06, 'reg_lambda': 8.015393563720193e-06, 'subsample': 0.5799411949016183, 'tree_method': 'hist'}, distributions={'booster': CategoricalDistribution(choices=('gbtree', 'gblinear')), 'colsample_bytree': UniformDistribution(high=1.0, low=0.1), 'early_stopping_rounds': IntUniformDistribution(high=500, low=100, step=1), 'gamma': LogUniformDistribution(high=1.0, low=1e-08), 'grow_policy': CategoricalDistribution(choices=('depthwise', 'lossguide')), 'learning_rate': LogUniformDistribution(high=0.25, low=0.01), 'max_depth': IntUniformDistribution(high=9, low=1, step=1), 'n_estimators': CategoricalDistribution(choices=(7000, 15000, 20000)), 'reg_alpha': LogUniformDistribution(high=100.0, low=1e-08), 'reg_lambda': LogUniformDistribution(high=100.0, low=1e-08), 'subsample': UniformDistribution(high=1.0, low=0.1), 'tree_method': CategoricalDistribution(choices=('exact', 'approx', 'hist'))}, user_attrs={}, system_attrs={}, intermediate_values={}, trial_id=49, state=TrialState.COMPLETE, value=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_trial.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Awesome we found best params with K-fold variations ~ 1 minute!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now let's use best params to update preprocessor and model in our pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoxgb_params = {'learning_rate': 0.016067642810265004,\n",
    "\n",
    "# 'reg_lambda': 0.0005033307729410949,\n",
    "\n",
    "# 'reg_alpha': 1.125131255655592e-06,\n",
    "\n",
    "# 'subsample': 0.43211847297916883,\n",
    "\n",
    "# 'colsample_bytree': 0.4106787563173376,\n",
    "\n",
    "# 'max_depth': 5,\n",
    "\n",
    "# 'early_stopping_rounds': 354,\n",
    "\n",
    "# 'n_estimators': 7000,\n",
    "\n",
    "# 'tree_method': 'approx',\n",
    "\n",
    "# 'booster': 'gbtree',\n",
    "\n",
    "# 'gamma': 0.2870988185671683,\n",
    "\n",
    "# 'grow_policy': 'depthwise'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb_params = autoxgb_params\n",
    "tmlt_xgb_params = study.best_trial.params\n",
    "xgb_params =  tmlt_xgb_params\n",
    "xgb_model = XGBRegressor(**xgb_params)\n",
    "tmlt.update_model(xgb_model)\n",
    "tmlt.spl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-fold training\n",
    "xgb_model_metrics_score, xgb_model_preds = tmlt.do_kfold_training(n_splits=5,\n",
    "                                                                          metrics=mean_absolute_error,\n",
    "                                                                          random_state=42)\n",
    "# predict\n",
    "print(xgb_model_preds.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mean metrics score: 14761.77\n",
    "\n",
    "(1459,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Yup Indeed Optuna tunning xgb model has improved MAE from earlier cross validated model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Amazing our MAE has reduced to 14761.77 by using Optuna based HyperParams search, If we can continue doing hyperparmas tunning, may be we can even do better, take that as challenge!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
