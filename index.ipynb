{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started Tutorial with TMLT (Tabular ML Toolkit)\n",
    "\n",
    "> A tutorial on getting started with TMLT (Tabular ML Toolkit)\n",
    "\n",
    "> tabular_ml_toolkit is a helper library to jumpstart your machine learning project based on Tabular or Structured data.\n",
    "\n",
    "> It comes with model and data parallelism and cutting edge hyperparameter search techniques.\n",
    "\n",
    "> Under the hood TMLT uses modin, optuna, xgboost and scikit-learn pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pip install -U tabular_ml_toolkit`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to Best Use tabular_ml_toolkit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start with your favorite model and then just simply create tmlt with one API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*For example, Here we are using XGBRegressor on  [Melbourne Home Sale price data](https://www.kaggle.com/estrotococo/home-data-for-ml-course)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pankajmathur/anaconda3/envs/nbdev_env/lib/python3.9/site-packages/redis/connection.py:77: UserWarning: redis-py works best with hiredis. Please consider installing\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from tabular_ml_toolkit.tmlt import *\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import numpy as np\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset file names and Paths\n",
    "DIRECTORY_PATH = \"input/home_data/\"\n",
    "TRAIN_FILE = \"train.csv\"\n",
    "TEST_FILE = \"test.csv\"\n",
    "SAMPLE_SUB_FILE = \"sample_submission.csv\"\n",
    "OUTPUT_PATH = \"output/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Just point tmlt in the direction of your data, let it know what are idx and target columns in your tabular data and what kind of problem type you are trying to resolve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-03 23:27:17,467 INFO 8 cores found, model and data parallel processing should worked!\n",
      "2021-12-03 23:27:17,506 INFO DataFrame Memory usage decreased to 0.58 Mb (35.5% reduction)\n",
      "2021-12-03 23:27:17,545 INFO DataFrame Memory usage decreased to 0.58 Mb (34.8% reduction)\n",
      "2021-12-03 23:27:17,570 INFO Both Numerical & Categorical columns found, Preprocessing will done accordingly!\n"
     ]
    }
   ],
   "source": [
    "# tmlt\n",
    "tmlt = TMLT().prepare_data(\n",
    "    train_file_path= DIRECTORY_PATH+TRAIN_FILE,\n",
    "    test_file_path= DIRECTORY_PATH+TEST_FILE,\n",
    "    idx_col=\"Id\", target=\"SalePrice\",\n",
    "    random_state=42,\n",
    "    problem_type=\"regression\")\n",
    "\n",
    "# TMLT currently only supports below problem_type:\n",
    "\n",
    "# \"binary_classification\"\n",
    "# \"multi_label_classification\"\n",
    "# \"multi_class_classification\"\n",
    "# \"regression\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(1460, 79)\n",
      "<class 'numpy.ndarray'>\n",
      "(1460,)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(1459, 79)\n"
     ]
    }
   ],
   "source": [
    "print(type(tmlt.dfl.X))\n",
    "print(tmlt.dfl.X.shape)\n",
    "print(type(tmlt.dfl.y))\n",
    "print(tmlt.dfl.y.shape)\n",
    "print(type(tmlt.dfl.X_test))\n",
    "print(tmlt.dfl.X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>...</th>\n",
       "      <th>GarageCond</th>\n",
       "      <th>PavedDrive</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>Exterior1st</th>\n",
       "      <th>Exterior2nd</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>196.0</td>\n",
       "      <td>706</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>CollgCr</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>VinylSd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Veenker</td>\n",
       "      <td>MetalSd</td>\n",
       "      <td>MetalSd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>162.0</td>\n",
       "      <td>486</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>CollgCr</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>VinylSd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1915</td>\n",
       "      <td>1970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>216</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>Crawfor</td>\n",
       "      <td>Wd Sdng</td>\n",
       "      <td>Wd Shng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>60</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>350.0</td>\n",
       "      <td>655</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>NoRidge</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>VinylSd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>60</td>\n",
       "      <td>62.0</td>\n",
       "      <td>7917</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1999</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Gilbert</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>VinylSd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>20</td>\n",
       "      <td>85.0</td>\n",
       "      <td>13175</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1978</td>\n",
       "      <td>1988</td>\n",
       "      <td>119.0</td>\n",
       "      <td>790</td>\n",
       "      <td>163</td>\n",
       "      <td>...</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>NWAmes</td>\n",
       "      <td>Plywood</td>\n",
       "      <td>Plywood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>70</td>\n",
       "      <td>66.0</td>\n",
       "      <td>9042</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>1941</td>\n",
       "      <td>2006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>275</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GdPrv</td>\n",
       "      <td>Shed</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Crawfor</td>\n",
       "      <td>CemntBd</td>\n",
       "      <td>CmentBd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>20</td>\n",
       "      <td>68.0</td>\n",
       "      <td>9717</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1950</td>\n",
       "      <td>1996</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49</td>\n",
       "      <td>1029</td>\n",
       "      <td>...</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>NAmes</td>\n",
       "      <td>MetalSd</td>\n",
       "      <td>MetalSd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1460</th>\n",
       "      <td>20</td>\n",
       "      <td>75.0</td>\n",
       "      <td>9937</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1965</td>\n",
       "      <td>1965</td>\n",
       "      <td>0.0</td>\n",
       "      <td>830</td>\n",
       "      <td>290</td>\n",
       "      <td>...</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Edwards</td>\n",
       "      <td>HdBoard</td>\n",
       "      <td>HdBoard</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
       "Id                                                                            \n",
       "1             60         65.0     8450            7            5       2003   \n",
       "2             20         80.0     9600            6            8       1976   \n",
       "3             60         68.0    11250            7            5       2001   \n",
       "4             70         60.0     9550            7            5       1915   \n",
       "5             60         84.0    14260            8            5       2000   \n",
       "...          ...          ...      ...          ...          ...        ...   \n",
       "1456          60         62.0     7917            6            5       1999   \n",
       "1457          20         85.0    13175            6            6       1978   \n",
       "1458          70         66.0     9042            7            9       1941   \n",
       "1459          20         68.0     9717            5            6       1950   \n",
       "1460          20         75.0     9937            5            6       1965   \n",
       "\n",
       "      YearRemodAdd  MasVnrArea  BsmtFinSF1  BsmtFinSF2  ...  GarageCond  \\\n",
       "Id                                                      ...               \n",
       "1             2003       196.0         706           0  ...          TA   \n",
       "2             1976         0.0         978           0  ...          TA   \n",
       "3             2002       162.0         486           0  ...          TA   \n",
       "4             1970         0.0         216           0  ...          TA   \n",
       "5             2000       350.0         655           0  ...          TA   \n",
       "...            ...         ...         ...         ...  ...         ...   \n",
       "1456          2000         0.0           0           0  ...          TA   \n",
       "1457          1988       119.0         790         163  ...          TA   \n",
       "1458          2006         0.0         275           0  ...          TA   \n",
       "1459          1996         0.0          49        1029  ...          TA   \n",
       "1460          1965         0.0         830         290  ...          TA   \n",
       "\n",
       "      PavedDrive  PoolQC  Fence  MiscFeature  SaleType  SaleCondition  \\\n",
       "Id                                                                      \n",
       "1              Y     NaN    NaN          NaN        WD         Normal   \n",
       "2              Y     NaN    NaN          NaN        WD         Normal   \n",
       "3              Y     NaN    NaN          NaN        WD         Normal   \n",
       "4              Y     NaN    NaN          NaN        WD        Abnorml   \n",
       "5              Y     NaN    NaN          NaN        WD         Normal   \n",
       "...          ...     ...    ...          ...       ...            ...   \n",
       "1456           Y     NaN    NaN          NaN        WD         Normal   \n",
       "1457           Y     NaN  MnPrv          NaN        WD         Normal   \n",
       "1458           Y     NaN  GdPrv         Shed        WD         Normal   \n",
       "1459           Y     NaN    NaN          NaN        WD         Normal   \n",
       "1460           Y     NaN    NaN          NaN        WD         Normal   \n",
       "\n",
       "      Neighborhood  Exterior1st  Exterior2nd  \n",
       "Id                                            \n",
       "1          CollgCr      VinylSd      VinylSd  \n",
       "2          Veenker      MetalSd      MetalSd  \n",
       "3          CollgCr      VinylSd      VinylSd  \n",
       "4          Crawfor      Wd Sdng      Wd Shng  \n",
       "5          NoRidge      VinylSd      VinylSd  \n",
       "...            ...          ...          ...  \n",
       "1456       Gilbert      VinylSd      VinylSd  \n",
       "1457        NWAmes      Plywood      Plywood  \n",
       "1458       Crawfor      CemntBd      CmentBd  \n",
       "1459         NAmes      MetalSd      MetalSd  \n",
       "1460       Edwards      HdBoard      HdBoard  \n",
       "\n",
       "[1460 rows x 79 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmlt.dfl.X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### create train valid dataframes for quick preprocessing and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.87 ms, sys: 1.49 ms, total: 6.36 ms\n",
      "Wall time: 5.19 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# create train, valid split to evaulate model on valid dataset\n",
    "X_train, X_valid,  y_train, y_valid =  tmlt.dfl.create_train_valid(valid_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1168, 79)\n",
      "(1168,)\n",
      "(292, 79)\n",
      "(292,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_valid.shape)\n",
    "print(y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train.columns.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now PreProcess X_train, X_valid\n",
    "\n",
    "NOTE: Preprocessing gives back numpy arrays for pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_np,  X_valid_np = tmlt.pp_fit_transform(X_train, X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(1168, 302)\n",
      "<class 'numpy.ndarray'>\n",
      "(292, 302)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(X_train_np))\n",
    "print(X_train_np.shape)\n",
    "# print(X_train_np)\n",
    "print(type(X_valid_np))\n",
    "print(X_valid_np.shape)\n",
    "# print(X_valid_np)\n",
    "print(type(y_valid))\n",
    "print(type(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create a base xgb classifier model with your best guess params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "    'learning_rate':0.1,\n",
    "    'use_label_encoder':False,\n",
    "    'eval_metric':'rmse',\n",
    "    'random_state':42,\n",
    "    # for GPU\n",
    "#     'tree_method': 'gpu_hist',\n",
    "#     'predictor': 'gpu_predictor',\n",
    "}\n",
    "# create xgb ml model\n",
    "xgb_model = XGBRegressor(**xgb_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_valid MAE: 15915.75480254709\n"
     ]
    }
   ],
   "source": [
    "# Now do model training\n",
    "xgb_model.fit(X_train_np, y_train,\n",
    "              verbose=False,\n",
    "              #detect & avoid overfitting\n",
    "              eval_set=[(X_train_np, y_train), (X_valid_np, y_valid)],\n",
    "              eval_metric=\"mae\",\n",
    "              early_stopping_rounds=300\n",
    "             )\n",
    "\n",
    "#predict\n",
    "preds = xgb_model.predict(X_valid_np)\n",
    "print('X_valid MAE:', mean_absolute_error(y_valid, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In background `prepare_data` method loads your input data into Pandas DataFrame, seprates X(features) and y(target), preprocess all numerical and categorical type data found in these DataFrames using scikit-learn pipelines. Then it bundle preprocessor and data return a TMLT object, this class instance has dataframeloader, preprocessor instances.\n",
    "\n",
    "The `create_train_valid` method use valid_size to split X(features) into X_train, y_train, X_valid and y_valid DataFrames, so you can call fit methods on X_train and y_train and predict methods on X_valid or X_test.\n",
    "\n",
    "Please check detail documentation and source code for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*NOTE: If you want to customize data and preprocessing steps you can do so by using `DataFrameLoader` and `PreProessor` classes. Check detail documentations for these classes for more options.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### To see more clear picture of model performance, Let's do a quick Cross Validation on our Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Make sure to PreProcess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_np, X_test_np = tmlt.pp_fit_transform(tmlt.dfl.X, tmlt.dfl.X_test)\n",
    "y_np = tmlt.dfl.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: [15733.51983893 16386.18366064 16648.82777718 14571.39875856\n",
      " 17295.16245719]\n",
      "Average MAE score: 16127.018498501711\n"
     ]
    }
   ],
   "source": [
    "# Now do cross_validation\n",
    "scores = tmlt.do_cross_validation(X_np, y_np, xgb_model, scoring='neg_mean_absolute_error', cv=5)\n",
    "\n",
    "print(\"scores:\", scores)\n",
    "print(\"Average MAE score:\", scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*MAE did came out slightly bad with cross validation*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Let's see if we can improve our cross validation score with hyperparams tunning*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We are using optuna based hyperparameter search here!**\n",
    "\n",
    "**TMLT has inbuilt xgb optuna optimization helper method!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-03 23:27:21,635 INFO Optimization Direction is: minimize\n",
      "\u001b[32m[I 2021-12-03 23:27:21,705]\u001b[0m Using an existing study with name 'tmlt_autoxgb' instead of creating a new one.\u001b[0m\n",
      "2021-12-03 23:27:21,889 INFO Training Started!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:27:21] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { early_stopping_rounds, eval_set } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-03 23:27:44,450 INFO Training Ended!\n",
      "2021-12-03 23:27:44,506 INFO mean_absolute_error: 15705.327790560788\n",
      "2021-12-03 23:27:44,506 INFO mean_squared_error: 730519420.0747098\n",
      "2021-12-03 23:27:44,507 INFO r2_score: 0.9047603191386815\n",
      "\u001b[32m[I 2021-12-03 23:27:44,574]\u001b[0m Trial 21 finished with value: 730519420.0747098 and parameters: {'learning_rate': 0.05435272187248115, 'n_estimators': 20000, 'reg_lambda': 0.00370827941660158, 'reg_alpha': 0.45862721196673417, 'subsample': 0.4279676226224459, 'colsample_bytree': 0.13626169760005338, 'max_depth': 4, 'early_stopping_rounds': 291, 'tree_method': 'exact', 'booster': 'gbtree', 'gamma': 0.9923916778361647, 'grow_policy': 'depthwise'}. Best is trial 7 with value: 641154325.9759644.\u001b[0m\n",
      "2021-12-03 23:27:44,725 INFO Training Started!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:27:44] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { early_stopping_rounds, eval_set } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-03 23:28:45,483 INFO Training Ended!\n",
      "2021-12-03 23:28:45,574 INFO mean_absolute_error: 14964.357796446919\n",
      "2021-12-03 23:28:45,574 INFO mean_squared_error: 642176994.0808992\n",
      "2021-12-03 23:28:45,575 INFO r2_score: 0.9162777466388357\n",
      "\u001b[32m[I 2021-12-03 23:28:45,643]\u001b[0m Trial 22 finished with value: 642176994.0808992 and parameters: {'learning_rate': 0.013095709693444705, 'n_estimators': 15000, 'reg_lambda': 15.939521164976025, 'reg_alpha': 6.500430184440403e-06, 'subsample': 0.6654972930243539, 'colsample_bytree': 0.49970267751426295, 'max_depth': 6, 'early_stopping_rounds': 453, 'tree_method': 'approx', 'booster': 'gbtree', 'gamma': 0.000806260966811638, 'grow_policy': 'depthwise'}. Best is trial 7 with value: 641154325.9759644.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FrozenTrial(number=7, values=[641154325.9759644], datetime_start=datetime.datetime(2021, 12, 3, 20, 38, 21, 482153), datetime_complete=datetime.datetime(2021, 12, 3, 20, 39, 30, 395838), params={'booster': 'gbtree', 'colsample_bytree': 0.3466657613679916, 'early_stopping_rounds': 409, 'gamma': 7.315596726371822e-06, 'grow_policy': 'depthwise', 'learning_rate': 0.05781643806086814, 'max_depth': 9, 'n_estimators': 20000, 'reg_alpha': 7.916067802441731e-07, 'reg_lambda': 0.14511799018426277, 'subsample': 0.3166053794978003, 'tree_method': 'approx'}, distributions={'booster': CategoricalDistribution(choices=('gbtree', 'gblinear')), 'colsample_bytree': UniformDistribution(high=1.0, low=0.1), 'early_stopping_rounds': IntUniformDistribution(high=500, low=100, step=1), 'gamma': LogUniformDistribution(high=1.0, low=1e-08), 'grow_policy': CategoricalDistribution(choices=('depthwise', 'lossguide')), 'learning_rate': LogUniformDistribution(high=0.25, low=0.01), 'max_depth': IntUniformDistribution(high=9, low=1, step=1), 'n_estimators': CategoricalDistribution(choices=(7000, 15000, 20000)), 'reg_alpha': LogUniformDistribution(high=100.0, low=1e-08), 'reg_lambda': LogUniformDistribution(high=100.0, low=1e-08), 'subsample': UniformDistribution(high=1.0, low=0.1), 'tree_method': CategoricalDistribution(choices=('exact', 'approx', 'hist'))}, user_attrs={}, system_attrs={}, intermediate_values={}, trial_id=8, state=TrialState.COMPLETE, value=None)\n"
     ]
    }
   ],
   "source": [
    "# **Just make sure to supply an output directory path so hyperparameter search is saved**\n",
    "study = tmlt.do_xgb_optuna_optimization(optuna_db_path=OUTPUT_PATH, opt_timeout=60)\n",
    "print(study.best_trial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's use our newly found best params to update the model on sklearn pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb_params {'learning_rate': 0.05781643806086814, 'use_label_encoder': False, 'eval_metric': 'rmse', 'random_state': 42, 'booster': 'gbtree', 'colsample_bytree': 0.3466657613679916, 'early_stopping_rounds': 409, 'gamma': 7.315596726371822e-06, 'grow_policy': 'depthwise', 'max_depth': 9, 'n_estimators': 20000, 'reg_alpha': 7.916067802441731e-07, 'reg_lambda': 0.14511799018426277, 'subsample': 0.3166053794978003, 'tree_method': 'approx'}\n"
     ]
    }
   ],
   "source": [
    "xgb_params.update(study.best_trial.params)\n",
    "print(\"xgb_params\", xgb_params)\n",
    "xgb_model = XGBRegressor(**xgb_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, Let's use 5 K-Fold Training on this Updated XGB model with best params found from Optuna search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "do_kfold_training() got an unexpected keyword argument 'test_preds_metric'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/yd/85jdd5bx59v81j8xnbhpkb3h0000gq/T/ipykernel_56830/466044868.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# k-fold training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mxgb_model_metrics_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgb_model_test_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmlt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_kfold_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_np\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_np\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_preds_metric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: do_kfold_training() got an unexpected keyword argument 'test_preds_metric'"
     ]
    }
   ],
   "source": [
    "# # k-fold training\n",
    "# xgb_model_metrics_score, xgb_model_test_preds = tmlt.do_kfold_training(X_np, y_np, n_splits=5, model=xgb_model, test_preds_metric=mean_absolute_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-03 23:29:32,035 INFO  model class:<class 'xgboost.sklearn.XGBRegressor'>\n",
      "/Users/pankajmathur/anaconda3/envs/nbdev_env/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:29:32] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { early_stopping_rounds, verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-03 23:30:45,553 INFO Predicting Score!\n",
      "2021-12-03 23:30:45,612 INFO fold: 1 mean_absolute_error : 19005.10041202911\n",
      "2021-12-03 23:30:45,613 INFO fold: 1 mean_squared_error : 2411222555.537417\n",
      "2021-12-03 23:30:45,614 INFO fold: 1 r2_score : 0.5838470238202538\n",
      "2021-12-03 23:30:45,614 WARNING Trying to do Test Predictions but No Test Dataset Provided!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:30:45] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { early_stopping_rounds, verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-03 23:32:01,470 INFO Predicting Score!\n",
      "2021-12-03 23:32:01,534 INFO fold: 2 mean_absolute_error : 15078.704302226028\n",
      "2021-12-03 23:32:01,535 INFO fold: 2 mean_squared_error : 564346640.105124\n",
      "2021-12-03 23:32:01,535 INFO fold: 2 r2_score : 0.8994232141593029\n",
      "2021-12-03 23:32:01,536 WARNING Trying to do Test Predictions but No Test Dataset Provided!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:32:01] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { early_stopping_rounds, verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-03 23:33:18,328 INFO Predicting Score!\n",
      "2021-12-03 23:33:18,390 INFO fold: 3 mean_absolute_error : 14835.53285530822\n",
      "2021-12-03 23:33:18,391 INFO fold: 3 mean_squared_error : 564983892.6053946\n",
      "2021-12-03 23:33:18,392 INFO fold: 3 r2_score : 0.925779088874223\n",
      "2021-12-03 23:33:18,392 WARNING Trying to do Test Predictions but No Test Dataset Provided!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:33:18] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { early_stopping_rounds, verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-03 23:34:36,560 INFO Predicting Score!\n",
      "2021-12-03 23:34:36,631 INFO fold: 4 mean_absolute_error : 14078.252006635274\n",
      "2021-12-03 23:34:36,631 INFO fold: 4 mean_squared_error : 521916667.0363479\n",
      "2021-12-03 23:34:36,632 INFO fold: 4 r2_score : 0.9064357109700444\n",
      "2021-12-03 23:34:36,632 WARNING Trying to do Test Predictions but No Test Dataset Provided!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:34:36] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { early_stopping_rounds, verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-03 23:35:53,506 INFO Predicting Score!\n",
      "2021-12-03 23:35:53,576 INFO fold: 5 mean_absolute_error : 15609.898143193494\n",
      "2021-12-03 23:35:53,577 INFO fold: 5 mean_squared_error : 660176798.8185495\n",
      "2021-12-03 23:35:53,578 INFO fold: 5 r2_score : 0.9037320768471553\n",
      "2021-12-03 23:35:53,578 WARNING Trying to do Test Predictions but No Test Dataset Provided!\n",
      "2021-12-03 23:35:53,579 INFO  Mean Metrics Results from all Folds are: {'mean_absolute_error': 15721.497543878426, 'mean_squared_error': 944529310.8205667, 'r2_score': 0.8438434229341959}\n"
     ]
    }
   ],
   "source": [
    "# k-fold training\n",
    "xgb_model_metrics_score, xgb_model_test_preds = tmlt.do_kfold_training(X_np, y_np, X_test=X_test_np, n_splits=5, model=xgb_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on test dataset\n",
    "if xgb_model_test_preds is not None:\n",
    "    print(xgb_model_test_preds.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### You can even improve metrics score further by running Optuna search for longer time or rerunning the study, check documentation for more details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nbdev_env",
   "language": "python",
   "name": "nbdev_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
