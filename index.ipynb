{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started Tutorial with TMLT (Tabular ML Toolkit)\n",
    "\n",
    "> A tutorial on getting started with TMLT (Tabular ML Toolkit)\n",
    "\n",
    "> tabular_ml_toolkit is a helper library to jumpstart your machine learning project based on Tabular or Structured data.\n",
    "\n",
    "> It comes with model and data parallelism and cutting edge hyperparameter search techniques.\n",
    "\n",
    "> Under the hood TMLT uses modin, optuna, xgboost and scikit-learn pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pip install -U tabular_ml_toolkit`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to Best Use tabular_ml_toolkit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start with your favorite model and then just simply create tmlt with one API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*For example, Here we are using XGBRegressor on  [Melbourne Home Sale price data](https://www.kaggle.com/estrotococo/home-data-for-ml-course)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabular_ml_toolkit.tmlt import *\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "# Just to compare fit times\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset file names and Paths\n",
    "DIRECTORY_PATH = \"input/home_data/\"\n",
    "TRAIN_FILE = \"train.csv\"\n",
    "TEST_FILE = \"test.csv\"\n",
    "SAMPLE_SUB_FILE = \"sample_submission.csv\"\n",
    "OUTPUT_PATH = \"output/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create a base xgb classifier model with your best guess params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "xgb_params = {\n",
    "    'learning_rate':0.1,\n",
    "    'use_label_encoder':False,\n",
    "    'eval_metric':'rmse',\n",
    "    'random_state':42,\n",
    "    # for GPU\n",
    "#     'tree_method': 'gpu_hist',\n",
    "#     'predictor': 'gpu_predictor',\n",
    "}\n",
    "# create xgb ml model\n",
    "xgb_model = XGBRegressor(**xgb_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Just point in the direction of your data, let tmlt know what are idx and target columns in your tabular data and what kind of problem type you are trying to resolve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-27 20:51:24,843 INFO 12 cores found, model and data parallel processing should worked!\n",
      "2021-11-27 20:51:24,896 INFO DataFrame Memory usage decreased to 0.58 Mb (35.5% reduction)\n",
      "2021-11-27 20:51:24,945 INFO DataFrame Memory usage decreased to 0.58 Mb (34.8% reduction)\n",
      "2021-11-27 20:51:24,979 INFO Both Numerical & Categorical columns found, Preprocessing will done accordingly!\n"
     ]
    }
   ],
   "source": [
    "# tmlt\n",
    "tmlt = TMLT().prepare_data_for_training(\n",
    "    train_file_path= DIRECTORY_PATH+TRAIN_FILE,\n",
    "    test_file_path= DIRECTORY_PATH+TEST_FILE,\n",
    "    idx_col=\"Id\", target=\"SalePrice\",\n",
    "    model=xgb_model,\n",
    "    random_state=42,\n",
    "    problem_type=\"regression\")\n",
    "\n",
    "# TMLT currently only supports below problem_type:\n",
    "\n",
    "# \"binary_classification\"\n",
    "# \"multi_label_classification\"\n",
    "# \"multi_class_classification\"\n",
    "# \"regression\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit Time: 0.25485920906066895\n",
      "X_valid MAE: 15936.53249411387\n"
     ]
    }
   ],
   "source": [
    "# create train, valid split to evaulate model on valid dataset\n",
    "tmlt.dfl.create_train_valid(valid_size=0.2)\n",
    "\n",
    "start = time.time()\n",
    "# Now fit\n",
    "tmlt.spl.fit(tmlt.dfl.X_train, tmlt.dfl.y_train)\n",
    "end = time.time()\n",
    "print(\"Fit Time:\", end - start)\n",
    "\n",
    "#predict\n",
    "preds = tmlt.spl.predict(tmlt.dfl.X_valid)\n",
    "print('X_valid MAE:', mean_absolute_error(tmlt.dfl.y_valid, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In background `prepare_data_for_training` method loads your input data into Pandas DataFrame, seprates X(features) and y(target).\n",
    "\n",
    "The `prepare_data_for_training` methods prepare X and y DataFrames, preprocess all numerical and categorical type data found in these DataFrames using scikit-learn pipelines. Then it bundle preprocessed data with your given model and return an MLPipeline object, this class instance has dataframeloader, preprocessor and scikit-lean pipeline instances.\n",
    "\n",
    "The `create_train_valid` method use valid_size to split X(features) into X_train, y_train, X_valid and y_valid DataFrames, so you can call fit methods on X_train and y_train and predict methods on X_valid or X_test.\n",
    "\n",
    "\n",
    "Please check detail documentation and source code for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*NOTE: If you want to customize data and preprocessing steps you can do so by using `DataFrameLoader` and `PreProessor` classes. Check detail documentations for these classes for more options.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### To see more clear picture of model performance, Let's do a quick Cross Validation on our Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Time: 1.2626621723175049\n",
      "scores: [15752.16827643 16405.26146458 16676.95384739 14588.82684075\n",
      " 17320.45218857]\n",
      "Average MAE score: 16148.73252354452\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "# Now do cross_validation\n",
    "scores = tmlt.do_cross_validation(cv=5, scoring='neg_mean_absolute_error')\n",
    "end = time.time()\n",
    "print(\"Cross Validation Time:\", end - start)\n",
    "\n",
    "print(\"scores:\", scores)\n",
    "print(\"Average MAE score:\", scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*MAE did came out slightly bad with cross validation*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Let's see if we can improve our cross validation score with hyperparams tunning*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**we are using optuna based hyperparameter search here, make sure to supply a new directory path so search is saved**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-27 20:52:12,151 INFO Optimization Direction is: minimize\n",
      "\u001b[32m[I 2021-11-27 20:52:12,215]\u001b[0m Using an existing study with name 'tmlt_autoxgb' instead of creating a new one.\u001b[0m\n",
      "2021-11-27 20:52:12,537 INFO Training Started!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:52:12] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1634712680264/work/src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\", \"eval_set\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-27 20:52:16,683 INFO Training Ended!\n",
      "2021-11-27 20:52:16,802 INFO mean_absolute_error: 14961.287657855308\n",
      "2021-11-27 20:52:16,802 INFO mean_squared_error: 710182288.1081377\n",
      "2021-11-27 20:52:16,803 INFO r2_score: 0.9074117229274168\n",
      "\u001b[32m[I 2021-11-27 20:52:16,842]\u001b[0m Trial 31 finished with value: 710182288.1081377 and parameters: {'learning_rate': 0.010287833814049732, 'n_estimators': 7000, 'reg_lambda': 2.2021084672156013, 'reg_alpha': 2.9596676195877394, 'subsample': 0.6027064970124942, 'colsample_bytree': 0.11131537174951261, 'max_depth': 4, 'early_stopping_rounds': 232, 'tree_method': 'hist', 'booster': 'gbtree', 'gamma': 1.2611297024132594e-06, 'grow_policy': 'depthwise'}. Best is trial 23 with value: 604200048.7128911.\u001b[0m\n",
      "2021-11-27 20:52:17,088 INFO Training Started!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:52:17] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1634712680264/work/src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\", \"eval_set\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-27 20:52:26,236 INFO Training Ended!\n",
      "2021-11-27 20:52:26,353 INFO mean_absolute_error: 14896.90144745291\n",
      "2021-11-27 20:52:26,354 INFO mean_squared_error: 607292442.2350011\n",
      "2021-11-27 20:52:26,355 INFO r2_score: 0.9208257346778856\n",
      "\u001b[32m[I 2021-11-27 20:52:26,390]\u001b[0m Trial 32 finished with value: 607292442.2350011 and parameters: {'learning_rate': 0.01600677836151433, 'n_estimators': 7000, 'reg_lambda': 1.9491473446193701, 'reg_alpha': 0.864289638451314, 'subsample': 0.8805539578148631, 'colsample_bytree': 0.3144918754703741, 'max_depth': 4, 'early_stopping_rounds': 241, 'tree_method': 'hist', 'booster': 'gbtree', 'gamma': 4.1194944286516154e-07, 'grow_policy': 'lossguide'}. Best is trial 23 with value: 604200048.7128911.\u001b[0m\n",
      "2021-11-27 20:52:26,630 INFO Training Started!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:52:26] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1634712680264/work/src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\", \"eval_set\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-27 20:52:41,225 INFO Training Ended!\n",
      "2021-11-27 20:52:41,322 INFO mean_absolute_error: 15013.209158283391\n",
      "2021-11-27 20:52:41,323 INFO mean_squared_error: 609257417.2319984\n",
      "2021-11-27 20:52:41,323 INFO r2_score: 0.920569555873501\n",
      "\u001b[32m[I 2021-11-27 20:52:41,343]\u001b[0m Trial 33 finished with value: 609257417.2319984 and parameters: {'learning_rate': 0.0177606536084275, 'n_estimators': 7000, 'reg_lambda': 2.174335552307863, 'reg_alpha': 0.732412893540352, 'subsample': 0.8988757563697343, 'colsample_bytree': 0.5597976047603338, 'max_depth': 4, 'early_stopping_rounds': 178, 'tree_method': 'hist', 'booster': 'gbtree', 'gamma': 6.785043359143624e-07, 'grow_policy': 'lossguide'}. Best is trial 23 with value: 604200048.7128911.\u001b[0m\n",
      "2021-11-27 20:52:41,536 INFO Training Started!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:52:41] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1634712680264/work/src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\", \"eval_set\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-27 20:52:48,508 INFO Training Ended!\n",
      "2021-11-27 20:52:48,579 INFO mean_absolute_error: 15094.149106378425\n",
      "2021-11-27 20:52:48,580 INFO mean_squared_error: 612248651.396432\n",
      "2021-11-27 20:52:48,581 INFO r2_score: 0.9201795810427524\n",
      "\u001b[32m[I 2021-11-27 20:52:48,599]\u001b[0m Trial 34 finished with value: 612248651.396432 and parameters: {'learning_rate': 0.018375921886293854, 'n_estimators': 7000, 'reg_lambda': 27.063132685501202, 'reg_alpha': 0.25625985717334526, 'subsample': 0.8923260077170412, 'colsample_bytree': 0.5461041412290502, 'max_depth': 3, 'early_stopping_rounds': 153, 'tree_method': 'hist', 'booster': 'gbtree', 'gamma': 5.57536980738242e-08, 'grow_policy': 'lossguide'}. Best is trial 23 with value: 604200048.7128911.\u001b[0m\n",
      "2021-11-27 20:52:48,792 INFO Training Started!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:52:48] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1634712680264/work/src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\", \"eval_set\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-27 20:52:53,070 INFO Training Ended!\n",
      "2021-11-27 20:52:53,137 INFO mean_absolute_error: 15612.104465432363\n",
      "2021-11-27 20:52:53,138 INFO mean_squared_error: 642768084.3513441\n",
      "2021-11-27 20:52:53,139 INFO r2_score: 0.9162006846919929\n",
      "\u001b[32m[I 2021-11-27 20:52:53,162]\u001b[0m Trial 35 finished with value: 642768084.3513441 and parameters: {'learning_rate': 0.016822984659983716, 'n_estimators': 7000, 'reg_lambda': 0.686990461824656, 'reg_alpha': 0.005456798619418751, 'subsample': 0.9390935972332031, 'colsample_bytree': 0.6237535008376071, 'max_depth': 2, 'early_stopping_rounds': 188, 'tree_method': 'hist', 'booster': 'gbtree', 'gamma': 1.5334080777849023e-07, 'grow_policy': 'depthwise'}. Best is trial 23 with value: 604200048.7128911.\u001b[0m\n",
      "2021-11-27 20:52:53,356 INFO Training Started!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:52:53] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1634712680264/work/src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\", \"eval_set\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-27 20:53:03,169 INFO Training Ended!\n",
      "2021-11-27 20:53:03,289 INFO mean_absolute_error: 15572.701840753425\n",
      "2021-11-27 20:53:03,290 INFO mean_squared_error: 651125629.7493893\n",
      "2021-11-27 20:53:03,291 INFO r2_score: 0.9151110901725037\n",
      "\u001b[32m[I 2021-11-27 20:53:03,321]\u001b[0m Trial 36 finished with value: 651125629.7493893 and parameters: {'learning_rate': 0.02412163067898655, 'n_estimators': 7000, 'reg_lambda': 75.9045043850116, 'reg_alpha': 0.1420454367576083, 'subsample': 0.8907076548824316, 'colsample_bytree': 0.5588717381660775, 'max_depth': 3, 'early_stopping_rounds': 138, 'tree_method': 'hist', 'booster': 'gbtree', 'gamma': 4.1577349379570457e-08, 'grow_policy': 'lossguide'}. Best is trial 23 with value: 604200048.7128911.\u001b[0m\n",
      "2021-11-27 20:53:03,541 INFO Training Started!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:53:03] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1634712680264/work/src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\", \"eval_set\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-27 20:53:17,175 INFO Training Ended!\n",
      "2021-11-27 20:53:17,265 INFO mean_absolute_error: 15179.852833369006\n",
      "2021-11-27 20:53:17,265 INFO mean_squared_error: 607046563.7856213\n",
      "2021-11-27 20:53:17,266 INFO r2_score: 0.9208577904787392\n",
      "\u001b[32m[I 2021-11-27 20:53:17,285]\u001b[0m Trial 37 finished with value: 607046563.7856213 and parameters: {'learning_rate': 0.01829836967730152, 'n_estimators': 7000, 'reg_lambda': 12.309123534329808, 'reg_alpha': 0.4197927584423797, 'subsample': 0.8957871298167308, 'colsample_bytree': 0.4683807902340768, 'max_depth': 4, 'early_stopping_rounds': 159, 'tree_method': 'hist', 'booster': 'gbtree', 'gamma': 2.6902639749404396e-07, 'grow_policy': 'lossguide'}. Best is trial 23 with value: 604200048.7128911.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FrozenTrial(number=23, values=[604200048.7128911], datetime_start=datetime.datetime(2021, 11, 22, 23, 39, 5, 962582), datetime_complete=datetime.datetime(2021, 11, 22, 23, 39, 41, 252155), params={'booster': 'gbtree', 'colsample_bytree': 0.5960603552824647, 'early_stopping_rounds': 401, 'gamma': 0.0005177750295162097, 'grow_policy': 'lossguide', 'learning_rate': 0.020767130829769383, 'max_depth': 6, 'n_estimators': 7000, 'reg_alpha': 0.0008846136538441224, 'reg_lambda': 0.0023056651712866118, 'subsample': 0.84754637782141, 'tree_method': 'hist'}, distributions={'booster': CategoricalDistribution(choices=('gbtree', 'gblinear')), 'colsample_bytree': UniformDistribution(high=1.0, low=0.1), 'early_stopping_rounds': IntUniformDistribution(high=500, low=100, step=1), 'gamma': LogUniformDistribution(high=1.0, low=1e-08), 'grow_policy': CategoricalDistribution(choices=('depthwise', 'lossguide')), 'learning_rate': LogUniformDistribution(high=0.25, low=0.01), 'max_depth': IntUniformDistribution(high=9, low=1, step=1), 'n_estimators': CategoricalDistribution(choices=(7000, 15000, 20000)), 'reg_alpha': LogUniformDistribution(high=100.0, low=1e-08), 'reg_lambda': LogUniformDistribution(high=100.0, low=1e-08), 'subsample': UniformDistribution(high=1.0, low=0.1), 'tree_method': CategoricalDistribution(choices=('exact', 'approx', 'hist'))}, user_attrs={}, system_attrs={}, intermediate_values={}, trial_id=24, state=TrialState.COMPLETE, value=None)\n"
     ]
    }
   ],
   "source": [
    "study = tmlt.do_xgb_optuna_optimization(optuna_db_path=OUTPUT_PATH, opt_timeout=60)\n",
    "print(study.best_trial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's use our newly found best params to update the model on sklearn pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb_params {'learning_rate': 0.020767130829769383, 'use_label_encoder': False, 'eval_metric': 'rmse', 'random_state': 42, 'booster': 'gbtree', 'colsample_bytree': 0.5960603552824647, 'early_stopping_rounds': 401, 'gamma': 0.0005177750295162097, 'grow_policy': 'lossguide', 'max_depth': 6, 'n_estimators': 7000, 'reg_alpha': 0.0008846136538441224, 'reg_lambda': 0.0023056651712866118, 'subsample': 0.84754637782141, 'tree_method': 'hist'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-63dfaec9-28e8-4354-a1e5-42985e14128e {color: black;background-color: white;}#sk-63dfaec9-28e8-4354-a1e5-42985e14128e pre{padding: 0;}#sk-63dfaec9-28e8-4354-a1e5-42985e14128e div.sk-toggleable {background-color: white;}#sk-63dfaec9-28e8-4354-a1e5-42985e14128e label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-63dfaec9-28e8-4354-a1e5-42985e14128e div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-63dfaec9-28e8-4354-a1e5-42985e14128e div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-63dfaec9-28e8-4354-a1e5-42985e14128e input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-63dfaec9-28e8-4354-a1e5-42985e14128e div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-63dfaec9-28e8-4354-a1e5-42985e14128e div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-63dfaec9-28e8-4354-a1e5-42985e14128e input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-63dfaec9-28e8-4354-a1e5-42985e14128e div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-63dfaec9-28e8-4354-a1e5-42985e14128e div.sk-estimator:hover {background-color: #d4ebff;}#sk-63dfaec9-28e8-4354-a1e5-42985e14128e div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-63dfaec9-28e8-4354-a1e5-42985e14128e div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-63dfaec9-28e8-4354-a1e5-42985e14128e div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-63dfaec9-28e8-4354-a1e5-42985e14128e div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;}#sk-63dfaec9-28e8-4354-a1e5-42985e14128e div.sk-item {z-index: 1;}#sk-63dfaec9-28e8-4354-a1e5-42985e14128e div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}#sk-63dfaec9-28e8-4354-a1e5-42985e14128e div.sk-parallel::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-63dfaec9-28e8-4354-a1e5-42985e14128e div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}#sk-63dfaec9-28e8-4354-a1e5-42985e14128e div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-63dfaec9-28e8-4354-a1e5-42985e14128e div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-63dfaec9-28e8-4354-a1e5-42985e14128e div.sk-parallel-item:only-child::after {width: 0;}#sk-63dfaec9-28e8-4354-a1e5-42985e14128e div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;position: relative;}#sk-63dfaec9-28e8-4354-a1e5-42985e14128e div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}#sk-63dfaec9-28e8-4354-a1e5-42985e14128e div.sk-label-container {position: relative;z-index: 2;text-align: center;}#sk-63dfaec9-28e8-4354-a1e5-42985e14128e div.sk-container {display: inline-block;position: relative;}</style><div id=\"sk-63dfaec9-28e8-4354-a1e5-42985e14128e\" class\"sk-top-container\"><div class=\"sk-container\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"27397510-57eb-4bd4-b27d-cd300a684347\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"27397510-57eb-4bd4-b27d-cd300a684347\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('num_cols',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer(strategy='constant')),\n",
       "                                                                  ('scaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  ['MSSubClass', 'LotFrontage',\n",
       "                                                   'LotArea', 'OverallQual',\n",
       "                                                   'OverallCond', 'YearBuilt',\n",
       "                                                   'YearRemodAdd', 'MasVnrArea',\n",
       "                                                   'BsmtFinSF1', 'BsmtFinSF2',\n",
       "                                                   'BsmtUnfSF', 'TotalBsmtSF',\n",
       "                                                   '1stFlrSF', '2ndFlrSF',\n",
       "                                                   '...\n",
       "                              learning_rate=0.020767130829769383,\n",
       "                              max_delta_step=None, max_depth=6,\n",
       "                              min_child_weight=None, missing=nan,\n",
       "                              monotone_constraints=None, n_estimators=7000,\n",
       "                              n_jobs=None, num_parallel_tree=None,\n",
       "                              predictor=None, random_state=42,\n",
       "                              reg_alpha=0.0008846136538441224,\n",
       "                              reg_lambda=0.0023056651712866118,\n",
       "                              scale_pos_weight=None, subsample=0.84754637782141,\n",
       "                              tree_method='hist', use_label_encoder=False, ...))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"8f029dcb-8407-4b3a-9bc6-a0c81b5979f5\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"8f029dcb-8407-4b3a-9bc6-a0c81b5979f5\">preprocessor: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[('num_cols',\n",
       "                                 Pipeline(steps=[('imputer',\n",
       "                                                  SimpleImputer(strategy='constant')),\n",
       "                                                 ('scaler', StandardScaler())]),\n",
       "                                 ['MSSubClass', 'LotFrontage', 'LotArea',\n",
       "                                  'OverallQual', 'OverallCond', 'YearBuilt',\n",
       "                                  'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1',\n",
       "                                  'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF',\n",
       "                                  '1stFlrSF', '2ndFlrSF', 'LowQualFinSF',\n",
       "                                  'GrLivArea', 'BsmtF...\n",
       "                                 ['MSZoning', 'Street', 'Alley', 'LotShape',\n",
       "                                  'LandContour', 'Utilities', 'LotConfig',\n",
       "                                  'LandSlope', 'Condition1', 'Condition2',\n",
       "                                  'BldgType', 'HouseStyle', 'RoofStyle',\n",
       "                                  'RoofMatl', 'MasVnrType', 'ExterQual',\n",
       "                                  'ExterCond', 'Foundation', 'BsmtQual',\n",
       "                                  'BsmtCond', 'BsmtExposure', 'BsmtFinType1',\n",
       "                                  'BsmtFinType2', 'Heating', 'HeatingQC',\n",
       "                                  'CentralAir', 'Electrical', 'KitchenQual',\n",
       "                                  'Functional', 'FireplaceQu', ...])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"50b9e90d-4e41-4d5f-9633-231b6dd02f96\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"50b9e90d-4e41-4d5f-9633-231b6dd02f96\">num_cols</label><div class=\"sk-toggleable__content\"><pre>['MSSubClass', 'LotFrontage', 'LotArea', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces', 'GarageYrBlt', 'GarageCars', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal', 'MoSold', 'YrSold']</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"23ce61a9-5575-40cc-ba22-1e3cf55767e3\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"23ce61a9-5575-40cc-ba22-1e3cf55767e3\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy='constant')</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"72744daa-4cca-4b49-b6e4-6ef75ac53d9b\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"72744daa-4cca-4b49-b6e4-6ef75ac53d9b\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"0f2eac57-17d9-46a0-8846-4df59836899b\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"0f2eac57-17d9-46a0-8846-4df59836899b\">cat_cols</label><div class=\"sk-toggleable__content\"><pre>['MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'Heating', 'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual', 'Functional', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'PavedDrive', 'PoolQC', 'Fence', 'MiscFeature', 'SaleType', 'SaleCondition', 'Neighborhood', 'Exterior1st', 'Exterior2nd']</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"1f02dd92-d94d-4849-8879-c7d32ef96780\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"1f02dd92-d94d-4849-8879-c7d32ef96780\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy='constant')</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"3c14d8b5-52e9-48e5-9ba7-0cd7a21e55c2\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"3c14d8b5-52e9-48e5-9ba7-0cd7a21e55c2\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown='ignore')</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"2076005e-c210-4c9d-acbc-f479681aa87e\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"2076005e-c210-4c9d-acbc-f479681aa87e\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster='gbtree', colsample_bylevel=None,\n",
       "             colsample_bynode=None, colsample_bytree=0.5960603552824647,\n",
       "             early_stopping_rounds=401, enable_categorical=False,\n",
       "             eval_metric='rmse', gamma=0.0005177750295162097, gpu_id=None,\n",
       "             grow_policy='lossguide', importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.020767130829769383,\n",
       "             max_delta_step=None, max_depth=6, min_child_weight=None,\n",
       "             missing=nan, monotone_constraints=None, n_estimators=7000,\n",
       "             n_jobs=None, num_parallel_tree=None, predictor=None,\n",
       "             random_state=42, reg_alpha=0.0008846136538441224,\n",
       "             reg_lambda=0.0023056651712866118, scale_pos_weight=None,\n",
       "             subsample=0.84754637782141, tree_method='hist',\n",
       "             use_label_encoder=False, ...)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('num_cols',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer(strategy='constant')),\n",
       "                                                                  ('scaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  ['MSSubClass', 'LotFrontage',\n",
       "                                                   'LotArea', 'OverallQual',\n",
       "                                                   'OverallCond', 'YearBuilt',\n",
       "                                                   'YearRemodAdd', 'MasVnrArea',\n",
       "                                                   'BsmtFinSF1', 'BsmtFinSF2',\n",
       "                                                   'BsmtUnfSF', 'TotalBsmtSF',\n",
       "                                                   '1stFlrSF', '2ndFlrSF',\n",
       "                                                   '...\n",
       "                              learning_rate=0.020767130829769383,\n",
       "                              max_delta_step=None, max_depth=6,\n",
       "                              min_child_weight=None, missing=nan,\n",
       "                              monotone_constraints=None, n_estimators=7000,\n",
       "                              n_jobs=None, num_parallel_tree=None,\n",
       "                              predictor=None, random_state=42,\n",
       "                              reg_alpha=0.0008846136538441224,\n",
       "                              reg_lambda=0.0023056651712866118,\n",
       "                              scale_pos_weight=None, subsample=0.84754637782141,\n",
       "                              tree_method='hist', use_label_encoder=False, ...))])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_params.update(study.best_trial.params)\n",
    "print(\"xgb_params\", xgb_params)\n",
    "xgb_model = XGBRegressor(**xgb_params)\n",
    "tmlt.update_model(xgb_model)\n",
    "tmlt.spl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, Let's use 5 K-Fold Training on this Updated XGB model with best params found from Optuna search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-27 20:53:17,396 INFO  model class:<class 'xgboost.sklearn.XGBRegressor'>\n",
      "/Users/pamathur/miniconda3/envs/nbdev_env/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:53:17] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1634712680264/work/src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-27 20:53:51,969 INFO fold: 1 mean_absolute_error : 18068.945660316782\n",
      "2021-11-27 20:53:51,970 INFO fold: 1 mean_squared_error : 1765853576.5144272\n",
      "2021-11-27 20:53:51,970 INFO fold: 1 r2_score : 0.6952312760692718\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:53:52] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1634712680264/work/src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-27 20:54:28,390 INFO fold: 2 mean_absolute_error : 14867.686028467466\n",
      "2021-11-27 20:54:28,391 INFO fold: 2 mean_squared_error : 768162815.6640443\n",
      "2021-11-27 20:54:28,391 INFO fold: 2 r2_score : 0.8630994826381212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:54:28] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1634712680264/work/src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-27 20:54:59,955 INFO fold: 3 mean_absolute_error : 14586.54402557791\n",
      "2021-11-27 20:54:59,956 INFO fold: 3 mean_squared_error : 589412516.5140059\n",
      "2021-11-27 20:54:59,956 INFO fold: 3 r2_score : 0.9225699447768843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:55:00] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1634712680264/work/src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-27 20:55:35,714 INFO fold: 4 mean_absolute_error : 13956.20951947774\n",
      "2021-11-27 20:55:35,715 INFO fold: 4 mean_squared_error : 453154881.61446327\n",
      "2021-11-27 20:55:35,716 INFO fold: 4 r2_score : 0.9187626742033932\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:55:35] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1634712680264/work/src/learner.cc:576: \n",
      "Parameters: { \"early_stopping_rounds\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-27 20:56:16,811 INFO fold: 5 mean_absolute_error : 15341.814881207192\n",
      "2021-11-27 20:56:16,812 INFO fold: 5 mean_squared_error : 654930416.2989283\n",
      "2021-11-27 20:56:16,813 INFO fold: 5 r2_score : 0.9044971118349543\n",
      "2021-11-27 20:56:17,027 INFO  Mean Metrics Results from all Folds are: {'mean_absolute_error': 15364.240023009417, 'mean_squared_error': 846302841.3211738, 'r2_score': 0.860832097904525}\n"
     ]
    }
   ],
   "source": [
    "# k-fold training\n",
    "xgb_model_metrics_score, xgb_model_test_preds = tmlt.do_kfold_training(n_splits=5, test_preds_metric=mean_absolute_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1459,)\n"
     ]
    }
   ],
   "source": [
    "# predict on test dataset\n",
    "if xgb_model_test_preds is not None:\n",
    "    print(xgb_model_test_preds.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### You can even improve metrics score further by running Optuna search for longer time or rerunning the study, check documentation for more details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nbdev_env]",
   "language": "python",
   "name": "conda-env-nbdev_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
